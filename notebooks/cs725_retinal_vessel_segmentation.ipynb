{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPgEM4Dwmol-",
        "outputId": "b0943581-2647-4b28-d05a-2bd004d4531d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive\n",
        "!mkdir CS725_Project_FINAL\n",
        "%cd /content/drive/MyDrive/CS725_Project_FINAL/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyEEyWUdm2rp",
        "outputId": "bf382175-4e3a-4212-fd2f-d774d1716dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/CS725_Project_FINAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/abreorussel/CS725-retinal-vessel-segmentation.git"
      ],
      "metadata": {
        "id": "StBagFKHoAk1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f989454-f70f-4d64-d4c3-f0edb6f46974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CS725-retinal-vessel-segmentation'...\n",
            "remote: Enumerating objects: 87, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 87 (delta 49), reused 62 (delta 24), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (87/87), 27.97 KiB | 2.80 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBhPG62-oAit",
        "outputId": "4ddf5ece-6ee1-4904-fbde-e7deb6969dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd CS725-retinal-vessel-segmentation\n",
        "!mkdir retinal-blood-vessels\n",
        "%cd /content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation/retinal-blood-vessels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHIAdyw6oAg3",
        "outputId": "5eae1581-a947-464a-8cdb-349cb1a7b581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation\n",
            "/content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation/retinal-blood-vessels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "\n",
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"abdallahwagih/retina-blood-vessel\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M-zGl4voAe2",
        "outputId": "9b9d552e-b5f2-49c5-9536-0e8aeb816a40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/abdallahwagih/retina-blood-vessel?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32.9M/32.9M [00:03<00:00, 10.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/abdallahwagih/retina-blood-vessel/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /root/.cache/kagglehub/datasets/abdallahwagih/retina-blood-vessel/versions/1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "780EKSqxpGza",
        "outputId": "2e95d7d6-fdbf-4de6-f66d-c254adf9d00e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/abdallahwagih/retina-blood-vessel/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj4V7UdNoAc4",
        "outputId": "4d071463-6272-4efd-8e0e-af5906fffa94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "\n",
        "def mkdir(*paths):\n",
        "    for path in paths:\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path, exist_ok=True)\n",
        "\n",
        "ROOT_DIR = os.path.dirname(os.path.abspath('__file__'))\n",
        "DATA_DIR = os.path.join(ROOT_DIR, 'retinal-blood-vessels')\n",
        "CKPT_DIR = os.path.join(ROOT_DIR, 'checkpoints')\n",
        "LOG_DIR = os.path.join(ROOT_DIR, 'logs')\n",
        "TRAIN_LOG_DIR = os.path.join(LOG_DIR, 'train')\n",
        "VAL_LOG_DIR = os.path.join(LOG_DIR, 'val')\n",
        "\n",
        "IMGS_DIR = os.path.join(DATA_DIR, 'imgs')\n",
        "LABELS_DIR = os.path.join(DATA_DIR, 'labels')\n",
        "\n",
        "TRAIN_IMGS_DIR = os.path.join(IMGS_DIR, 'train')\n",
        "VAL_IMGS_DIR = os.path.join(IMGS_DIR, 'val')\n",
        "# TEST_IMGS_DIR = os.path.join(IMGS_DIR, 'test')\n",
        "\n",
        "TRAIN_LABELS_DIR = os.path.join(LABELS_DIR, 'train')\n",
        "VAL_LABELS_DIR = os.path.join(LABELS_DIR, 'val')\n",
        "# TEST_LABELS_DIR = os.path.join(LABELS_DIR, 'test')\n",
        "\n",
        "mkdir(\n",
        "    CKPT_DIR, LOG_DIR, TRAIN_LOG_DIR, VAL_LOG_DIR,\n",
        "    IMGS_DIR, LABELS_DIR, TRAIN_IMGS_DIR, VAL_IMGS_DIR,\n",
        "    TRAIN_LABELS_DIR, VAL_LABELS_DIR,\n",
        "    )\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n"
      ],
      "metadata": {
        "id": "AaLzVGRXoAaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_IMGS_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "o5GqlBtPpsOZ",
        "outputId": "0d590fe4-71db-4f4b-b14a-977ee3f184e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation/retinal-blood-vessels/imgs/val'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_DIR = \"/root/.cache/kagglehub/datasets/abdallahwagih/retina-blood-vessel/versions/1/Data\""
      ],
      "metadata": {
        "id": "3sEavUQMoAYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MOVE the TEST Data"
      ],
      "metadata": {
        "id": "mRJNZBg7oAWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "TEST_IMGS = os.path.join(DATASET_DIR , \"test/image\")\n",
        "TEST_IMGS_DIR = os.path.join(DATA_DIR , \"imgs/test\")\n",
        "\n",
        "TEST_LABELS = os.path.join(DATASET_DIR , \"test/mask\")\n",
        "TEST_LABELS_DIR = os.path.join(DATA_DIR , \"labels/test\")\n",
        "\n",
        "shutil.copytree(TEST_IMGS, TEST_IMGS_DIR)\n",
        "shutil.copytree(TEST_LABELS, TEST_LABELS_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qOGi1PXjoAMz",
        "outputId": "bc36e3c3-db93-4278-a8e0-61f5f87686c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation/retinal-blood-vessels/labels/test'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_LABELS = os.path.join(DATASET_DIR , \"train/mask\")\n",
        "TRAIN_DATA_LABELS_DIR = os.path.join(DATA_DIR , \"labels/train-data\")\n",
        "\n",
        "TRAIN_IMGS = os.path.join(DATASET_DIR , \"train/image\")\n",
        "TRAIN_DATA_IMGS_DIR = os.path.join(DATA_DIR , \"imgs/train-data\")\n",
        "\n",
        "shutil.copytree(TRAIN_LABELS, TRAIN_DATA_LABELS_DIR)\n",
        "shutil.copytree(TRAIN_IMGS, TRAIN_DATA_IMGS_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-xvKTmtOocVi",
        "outputId": "59b26a30-9014-4ddd-b892-2fd3520569c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation/retinal-blood-vessels/imgs/train-data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "TRAIN_LABELS_DIR = os.path.join(DATA_DIR , \"labels/train\")\n",
        "TRAIN_IMGS_DIR = os.path.join(DATA_DIR , \"imgs/train\")\n",
        "\n",
        "TRAIN_LABELS_DIR\n",
        "TRAIN_IMGS_DIR\n",
        "\n",
        "train_img_path = TRAIN_DATA_IMGS_DIR\n",
        "train_label_path = TRAIN_DATA_LABELS_DIR\n",
        "\n",
        "image_mask_pairs = list()\n",
        "\n",
        "\n",
        "image_files = sorted(os.listdir(train_img_path))\n",
        "mask_files = sorted(os.listdir(train_label_path))\n",
        "\n",
        "\n",
        "for image_file, mask_file in zip(image_files, mask_files):\n",
        "  image_path = os.path.join(train_img_path, image_file)\n",
        "  mask_path = os.path.join(train_label_path, mask_file)\n",
        "  image_mask_pairs.append((image_path, mask_path))\n",
        "\n",
        "# Shuffle and Split Data\n",
        "random.shuffle(image_mask_pairs)\n",
        "print(len(image_mask_pairs))\n",
        "train_list = image_mask_pairs[:60]\n",
        "val_list = image_mask_pairs[60:]\n",
        "\n",
        "\n",
        "\n",
        "# # Save splitted files\n",
        "\n",
        "for idx, (img_path, label_path) in enumerate(train_list, 1):\n",
        "  img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)  # Load the image\n",
        "  label = cv2.imread(label_path, cv2.IMREAD_UNCHANGED)  # Load the label\n",
        "\n",
        "  if img is None or label is None:\n",
        "      print(f\"Error loading image or label for {img_path} and {label_path}\")\n",
        "      continue\n",
        "\n",
        "  img_dst = os.path.join(TRAIN_IMGS_DIR, f'{idx:02}.png')\n",
        "  label_dst = os.path.join(TRAIN_LABELS_DIR, f'{idx:02}.png')\n",
        "  cv2.imwrite(img_dst, img)\n",
        "  cv2.imwrite(label_dst, label)\n",
        "\n",
        "\n",
        "\n",
        "for idx, (img_path, label_path) in enumerate(val_list, 1):\n",
        "  img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)  # Load the image\n",
        "  label = cv2.imread(label_path, cv2.IMREAD_UNCHANGED)  # Load the label\n",
        "\n",
        "  if img is None or label is None:\n",
        "      print(f\"Error loading image or label for {img_path} and {label_path}\")\n",
        "      continue\n",
        "\n",
        "  img_dst = os.path.join(VAL_IMGS_DIR, f'{idx:02}.png')\n",
        "  label_dst = os.path.join(VAL_LABELS_DIR, f'{idx:02}.png')\n",
        "  cv2.imwrite(img_dst, img)\n",
        "  cv2.imwrite(label_dst, label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBnD4qFsocTj",
        "outputId": "1b7e4a6e-d2e8-4421-f9a5-c4a80d248a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_IMGS_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "pTYuWXaDocPV",
        "outputId": "45b83630-098e-4e28-a982-c2a071bf7b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation/retinal-blood-vessels/imgs/val'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMGS_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "APpoD2lNocNP",
        "outputId": "edd686f4-6ad5-434f-dac2-44d8eabe5256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation/retinal-blood-vessels/imgs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation\n",
        "\n",
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMMOAGnCsUf1",
        "outputId": "ad475af3-db1a-4aaf-b5de-d6278e4d87f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation\n",
            "2024-11-25 10:00:33.324936: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-25 10:00:33.342867: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-25 10:00:33.364613: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-25 10:00:33.371121: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-25 10:00:33.386514: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-25 10:00:34.506750: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "train : /content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation/retinal-blood-vessels/imgs/train\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "* Training from scratch\n",
            "[Train] | Epoch: 0001 / 1000 | Batch: 0001 / 0004 | Loss: 0.8708\n",
            "[Train] | Epoch: 0001 / 1000 | Batch: 0002 / 0004 | Loss: 0.8517\n",
            "[Train] | Epoch: 0001 / 1000 | Batch: 0003 / 0004 | Loss: 0.8439\n",
            "[Train] | Epoch: 0001 / 1000 | Batch: 0004 / 0004 | Loss: 0.8444\n",
            "[Validation] | Epoch: 0001 / 1000 | Batch: 0001 / 0002 | Loss: 0.8696\n",
            "[Validation] | Epoch: 0001 / 1000 | Batch: 0002 / 0002 | Loss: 0.8630\n",
            "[Epoch 0001] Training Avg Loss: 0.8527 | Validation Avg Loss: 0.8663\n",
            "[Train] | Epoch: 0002 / 1000 | Batch: 0001 / 0004 | Loss: 0.8366\n",
            "[Train] | Epoch: 0002 / 1000 | Batch: 0002 / 0004 | Loss: 0.8378\n",
            "[Train] | Epoch: 0002 / 1000 | Batch: 0003 / 0004 | Loss: 0.8248\n",
            "[Train] | Epoch: 0002 / 1000 | Batch: 0004 / 0004 | Loss: 0.8212\n",
            "[Validation] | Epoch: 0002 / 1000 | Batch: 0001 / 0002 | Loss: 0.8723\n",
            "[Validation] | Epoch: 0002 / 1000 | Batch: 0002 / 0002 | Loss: 0.8656\n",
            "[Epoch 0002] Training Avg Loss: 0.8301 | Validation Avg Loss: 0.8690\n",
            "[Train] | Epoch: 0003 / 1000 | Batch: 0001 / 0004 | Loss: 0.8111\n",
            "[Train] | Epoch: 0003 / 1000 | Batch: 0002 / 0004 | Loss: 0.8155\n",
            "[Train] | Epoch: 0003 / 1000 | Batch: 0003 / 0004 | Loss: 0.8189\n",
            "[Train] | Epoch: 0003 / 1000 | Batch: 0004 / 0004 | Loss: 0.8249\n",
            "[Validation] | Epoch: 0003 / 1000 | Batch: 0001 / 0002 | Loss: 0.8476\n",
            "[Validation] | Epoch: 0003 / 1000 | Batch: 0002 / 0002 | Loss: 0.8401\n",
            "[Epoch 0003] Training Avg Loss: 0.8176 | Validation Avg Loss: 0.8438\n",
            "[Train] | Epoch: 0004 / 1000 | Batch: 0001 / 0004 | Loss: 0.8143\n",
            "[Train] | Epoch: 0004 / 1000 | Batch: 0002 / 0004 | Loss: 0.8055\n",
            "[Train] | Epoch: 0004 / 1000 | Batch: 0003 / 0004 | Loss: 0.8093\n",
            "[Train] | Epoch: 0004 / 1000 | Batch: 0004 / 0004 | Loss: 0.7992\n",
            "[Validation] | Epoch: 0004 / 1000 | Batch: 0001 / 0002 | Loss: 0.8505\n",
            "[Validation] | Epoch: 0004 / 1000 | Batch: 0002 / 0002 | Loss: 0.8448\n",
            "[Epoch 0004] Training Avg Loss: 0.8071 | Validation Avg Loss: 0.8476\n",
            "[Train] | Epoch: 0005 / 1000 | Batch: 0001 / 0004 | Loss: 0.8060\n",
            "[Train] | Epoch: 0005 / 1000 | Batch: 0002 / 0004 | Loss: 0.7956\n",
            "[Train] | Epoch: 0005 / 1000 | Batch: 0003 / 0004 | Loss: 0.8050\n",
            "[Train] | Epoch: 0005 / 1000 | Batch: 0004 / 0004 | Loss: 0.7975\n",
            "[Validation] | Epoch: 0005 / 1000 | Batch: 0001 / 0002 | Loss: 0.8489\n",
            "[Validation] | Epoch: 0005 / 1000 | Batch: 0002 / 0002 | Loss: 0.8427\n",
            "[Epoch 0005] Training Avg Loss: 0.8010 | Validation Avg Loss: 0.8458\n",
            "[Train] | Epoch: 0006 / 1000 | Batch: 0001 / 0004 | Loss: 0.7955\n",
            "[Train] | Epoch: 0006 / 1000 | Batch: 0002 / 0004 | Loss: 0.7964\n",
            "[Train] | Epoch: 0006 / 1000 | Batch: 0003 / 0004 | Loss: 0.7911\n",
            "[Train] | Epoch: 0006 / 1000 | Batch: 0004 / 0004 | Loss: 0.7944\n",
            "[Validation] | Epoch: 0006 / 1000 | Batch: 0001 / 0002 | Loss: 0.8369\n",
            "[Validation] | Epoch: 0006 / 1000 | Batch: 0002 / 0002 | Loss: 0.8295\n",
            "[Epoch 0006] Training Avg Loss: 0.7943 | Validation Avg Loss: 0.8332\n",
            "[Train] | Epoch: 0007 / 1000 | Batch: 0001 / 0004 | Loss: 0.7963\n",
            "[Train] | Epoch: 0007 / 1000 | Batch: 0002 / 0004 | Loss: 0.7855\n",
            "[Train] | Epoch: 0007 / 1000 | Batch: 0003 / 0004 | Loss: 0.7873\n",
            "[Train] | Epoch: 0007 / 1000 | Batch: 0004 / 0004 | Loss: 0.7902\n",
            "[Validation] | Epoch: 0007 / 1000 | Batch: 0001 / 0002 | Loss: 0.8283\n",
            "[Validation] | Epoch: 0007 / 1000 | Batch: 0002 / 0002 | Loss: 0.8224\n",
            "[Epoch 0007] Training Avg Loss: 0.7898 | Validation Avg Loss: 0.8254\n",
            "[Train] | Epoch: 0008 / 1000 | Batch: 0001 / 0004 | Loss: 0.7823\n",
            "[Train] | Epoch: 0008 / 1000 | Batch: 0002 / 0004 | Loss: 0.7880\n",
            "[Train] | Epoch: 0008 / 1000 | Batch: 0003 / 0004 | Loss: 0.7845\n",
            "[Train] | Epoch: 0008 / 1000 | Batch: 0004 / 0004 | Loss: 0.7845\n",
            "[Validation] | Epoch: 0008 / 1000 | Batch: 0001 / 0002 | Loss: 0.8266\n",
            "[Validation] | Epoch: 0008 / 1000 | Batch: 0002 / 0002 | Loss: 0.8204\n",
            "[Epoch 0008] Training Avg Loss: 0.7848 | Validation Avg Loss: 0.8235\n",
            "[Train] | Epoch: 0009 / 1000 | Batch: 0001 / 0004 | Loss: 0.7830\n",
            "[Train] | Epoch: 0009 / 1000 | Batch: 0002 / 0004 | Loss: 0.7804\n",
            "[Train] | Epoch: 0009 / 1000 | Batch: 0003 / 0004 | Loss: 0.7852\n",
            "[Train] | Epoch: 0009 / 1000 | Batch: 0004 / 0004 | Loss: 0.7664\n",
            "[Validation] | Epoch: 0009 / 1000 | Batch: 0001 / 0002 | Loss: 0.8138\n",
            "[Validation] | Epoch: 0009 / 1000 | Batch: 0002 / 0002 | Loss: 0.8046\n",
            "[Epoch 0009] Training Avg Loss: 0.7787 | Validation Avg Loss: 0.8092\n",
            "[Train] | Epoch: 0010 / 1000 | Batch: 0001 / 0004 | Loss: 0.7724\n",
            "[Train] | Epoch: 0010 / 1000 | Batch: 0002 / 0004 | Loss: 0.7794\n",
            "[Train] | Epoch: 0010 / 1000 | Batch: 0003 / 0004 | Loss: 0.7752\n",
            "[Train] | Epoch: 0010 / 1000 | Batch: 0004 / 0004 | Loss: 0.7762\n",
            "[Validation] | Epoch: 0010 / 1000 | Batch: 0001 / 0002 | Loss: 0.7973\n",
            "[Validation] | Epoch: 0010 / 1000 | Batch: 0002 / 0002 | Loss: 0.7877\n",
            "[Epoch 0010] Training Avg Loss: 0.7758 | Validation Avg Loss: 0.7925\n",
            "[Train] | Epoch: 0011 / 1000 | Batch: 0001 / 0004 | Loss: 0.7720\n",
            "[Train] | Epoch: 0011 / 1000 | Batch: 0002 / 0004 | Loss: 0.7680\n",
            "[Train] | Epoch: 0011 / 1000 | Batch: 0003 / 0004 | Loss: 0.7783\n",
            "[Train] | Epoch: 0011 / 1000 | Batch: 0004 / 0004 | Loss: 0.7674\n",
            "[Validation] | Epoch: 0011 / 1000 | Batch: 0001 / 0002 | Loss: 0.7964\n",
            "[Validation] | Epoch: 0011 / 1000 | Batch: 0002 / 0002 | Loss: 0.7877\n",
            "[Epoch 0011] Training Avg Loss: 0.7714 | Validation Avg Loss: 0.7921\n",
            "[Train] | Epoch: 0012 / 1000 | Batch: 0001 / 0004 | Loss: 0.7728\n",
            "[Train] | Epoch: 0012 / 1000 | Batch: 0002 / 0004 | Loss: 0.7648\n",
            "[Train] | Epoch: 0012 / 1000 | Batch: 0003 / 0004 | Loss: 0.7641\n",
            "[Train] | Epoch: 0012 / 1000 | Batch: 0004 / 0004 | Loss: 0.7660\n",
            "[Validation] | Epoch: 0012 / 1000 | Batch: 0001 / 0002 | Loss: 0.7860\n",
            "[Validation] | Epoch: 0012 / 1000 | Batch: 0002 / 0002 | Loss: 0.7767\n",
            "[Epoch 0012] Training Avg Loss: 0.7669 | Validation Avg Loss: 0.7814\n",
            "[Train] | Epoch: 0013 / 1000 | Batch: 0001 / 0004 | Loss: 0.7717\n",
            "[Train] | Epoch: 0013 / 1000 | Batch: 0002 / 0004 | Loss: 0.7599\n",
            "[Train] | Epoch: 0013 / 1000 | Batch: 0003 / 0004 | Loss: 0.7585\n",
            "[Train] | Epoch: 0013 / 1000 | Batch: 0004 / 0004 | Loss: 0.7606\n",
            "[Validation] | Epoch: 0013 / 1000 | Batch: 0001 / 0002 | Loss: 0.7787\n",
            "[Validation] | Epoch: 0013 / 1000 | Batch: 0002 / 0002 | Loss: 0.7686\n",
            "[Epoch 0013] Training Avg Loss: 0.7627 | Validation Avg Loss: 0.7737\n",
            "[Train] | Epoch: 0014 / 1000 | Batch: 0001 / 0004 | Loss: 0.7618\n",
            "[Train] | Epoch: 0014 / 1000 | Batch: 0002 / 0004 | Loss: 0.7524\n",
            "[Train] | Epoch: 0014 / 1000 | Batch: 0003 / 0004 | Loss: 0.7555\n",
            "[Train] | Epoch: 0014 / 1000 | Batch: 0004 / 0004 | Loss: 0.7671\n",
            "[Validation] | Epoch: 0014 / 1000 | Batch: 0001 / 0002 | Loss: 0.7697\n",
            "[Validation] | Epoch: 0014 / 1000 | Batch: 0002 / 0002 | Loss: 0.7594\n",
            "[Epoch 0014] Training Avg Loss: 0.7592 | Validation Avg Loss: 0.7645\n",
            "[Train] | Epoch: 0015 / 1000 | Batch: 0001 / 0004 | Loss: 0.7588\n",
            "[Train] | Epoch: 0015 / 1000 | Batch: 0002 / 0004 | Loss: 0.7529\n",
            "[Train] | Epoch: 0015 / 1000 | Batch: 0003 / 0004 | Loss: 0.7584\n",
            "[Train] | Epoch: 0015 / 1000 | Batch: 0004 / 0004 | Loss: 0.7469\n",
            "[Validation] | Epoch: 0015 / 1000 | Batch: 0001 / 0002 | Loss: 0.7663\n",
            "[Validation] | Epoch: 0015 / 1000 | Batch: 0002 / 0002 | Loss: 0.7552\n",
            "[Epoch 0015] Training Avg Loss: 0.7542 | Validation Avg Loss: 0.7608\n",
            "[Train] | Epoch: 0016 / 1000 | Batch: 0001 / 0004 | Loss: 0.7542\n",
            "[Train] | Epoch: 0016 / 1000 | Batch: 0002 / 0004 | Loss: 0.7538\n",
            "[Train] | Epoch: 0016 / 1000 | Batch: 0003 / 0004 | Loss: 0.7497\n",
            "[Train] | Epoch: 0016 / 1000 | Batch: 0004 / 0004 | Loss: 0.7410\n",
            "[Validation] | Epoch: 0016 / 1000 | Batch: 0001 / 0002 | Loss: 0.7590\n",
            "[Validation] | Epoch: 0016 / 1000 | Batch: 0002 / 0002 | Loss: 0.7514\n",
            "[Epoch 0016] Training Avg Loss: 0.7497 | Validation Avg Loss: 0.7552\n",
            "[Train] | Epoch: 0017 / 1000 | Batch: 0001 / 0004 | Loss: 0.7468\n",
            "[Train] | Epoch: 0017 / 1000 | Batch: 0002 / 0004 | Loss: 0.7424\n",
            "[Train] | Epoch: 0017 / 1000 | Batch: 0003 / 0004 | Loss: 0.7526\n",
            "[Train] | Epoch: 0017 / 1000 | Batch: 0004 / 0004 | Loss: 0.7444\n",
            "[Validation] | Epoch: 0017 / 1000 | Batch: 0001 / 0002 | Loss: 0.7368\n",
            "[Validation] | Epoch: 0017 / 1000 | Batch: 0002 / 0002 | Loss: 0.7375\n",
            "[Epoch 0017] Training Avg Loss: 0.7466 | Validation Avg Loss: 0.7371\n",
            "[Train] | Epoch: 0018 / 1000 | Batch: 0001 / 0004 | Loss: 0.7484\n",
            "[Train] | Epoch: 0018 / 1000 | Batch: 0002 / 0004 | Loss: 0.7446\n",
            "[Train] | Epoch: 0018 / 1000 | Batch: 0003 / 0004 | Loss: 0.7614\n",
            "[Train] | Epoch: 0018 / 1000 | Batch: 0004 / 0004 | Loss: 0.7401\n",
            "[Validation] | Epoch: 0018 / 1000 | Batch: 0001 / 0002 | Loss: 0.7568\n",
            "[Validation] | Epoch: 0018 / 1000 | Batch: 0002 / 0002 | Loss: 0.7431\n",
            "[Epoch 0018] Training Avg Loss: 0.7486 | Validation Avg Loss: 0.7500\n",
            "[Train] | Epoch: 0019 / 1000 | Batch: 0001 / 0004 | Loss: 0.7410\n",
            "[Train] | Epoch: 0019 / 1000 | Batch: 0002 / 0004 | Loss: 0.7361\n",
            "[Train] | Epoch: 0019 / 1000 | Batch: 0003 / 0004 | Loss: 0.7344\n",
            "[Train] | Epoch: 0019 / 1000 | Batch: 0004 / 0004 | Loss: 0.7372\n",
            "[Validation] | Epoch: 0019 / 1000 | Batch: 0001 / 0002 | Loss: 0.7449\n",
            "[Validation] | Epoch: 0019 / 1000 | Batch: 0002 / 0002 | Loss: 0.7441\n",
            "[Epoch 0019] Training Avg Loss: 0.7372 | Validation Avg Loss: 0.7445\n",
            "[Train] | Epoch: 0020 / 1000 | Batch: 0001 / 0004 | Loss: 0.7307\n",
            "[Train] | Epoch: 0020 / 1000 | Batch: 0002 / 0004 | Loss: 0.7257\n",
            "[Train] | Epoch: 0020 / 1000 | Batch: 0003 / 0004 | Loss: 0.7271\n",
            "[Train] | Epoch: 0020 / 1000 | Batch: 0004 / 0004 | Loss: 0.7276\n",
            "[Validation] | Epoch: 0020 / 1000 | Batch: 0001 / 0002 | Loss: 0.7500\n",
            "[Validation] | Epoch: 0020 / 1000 | Batch: 0002 / 0002 | Loss: 0.7500\n",
            "[Epoch 0020] Training Avg Loss: 0.7278 | Validation Avg Loss: 0.7500\n",
            "[Train] | Epoch: 0021 / 1000 | Batch: 0001 / 0004 | Loss: 0.7228\n",
            "[Train] | Epoch: 0021 / 1000 | Batch: 0002 / 0004 | Loss: 0.7246\n",
            "[Train] | Epoch: 0021 / 1000 | Batch: 0003 / 0004 | Loss: 0.7114\n",
            "[Train] | Epoch: 0021 / 1000 | Batch: 0004 / 0004 | Loss: 0.7186\n",
            "[Validation] | Epoch: 0021 / 1000 | Batch: 0001 / 0002 | Loss: 0.7364\n",
            "[Validation] | Epoch: 0021 / 1000 | Batch: 0002 / 0002 | Loss: 0.7368\n",
            "[Epoch 0021] Training Avg Loss: 0.7194 | Validation Avg Loss: 0.7366\n",
            "[Train] | Epoch: 0022 / 1000 | Batch: 0001 / 0004 | Loss: 0.7243\n",
            "[Train] | Epoch: 0022 / 1000 | Batch: 0002 / 0004 | Loss: 0.7125\n",
            "[Train] | Epoch: 0022 / 1000 | Batch: 0003 / 0004 | Loss: 0.7150\n",
            "[Train] | Epoch: 0022 / 1000 | Batch: 0004 / 0004 | Loss: 0.6957\n",
            "[Validation] | Epoch: 0022 / 1000 | Batch: 0001 / 0002 | Loss: 0.7316\n",
            "[Validation] | Epoch: 0022 / 1000 | Batch: 0002 / 0002 | Loss: 0.7300\n",
            "[Epoch 0022] Training Avg Loss: 0.7119 | Validation Avg Loss: 0.7308\n",
            "[Train] | Epoch: 0023 / 1000 | Batch: 0001 / 0004 | Loss: 0.7029\n",
            "[Train] | Epoch: 0023 / 1000 | Batch: 0002 / 0004 | Loss: 0.7055\n",
            "[Train] | Epoch: 0023 / 1000 | Batch: 0003 / 0004 | Loss: 0.7015\n",
            "[Train] | Epoch: 0023 / 1000 | Batch: 0004 / 0004 | Loss: 0.7123\n",
            "[Validation] | Epoch: 0023 / 1000 | Batch: 0001 / 0002 | Loss: 0.7155\n",
            "[Validation] | Epoch: 0023 / 1000 | Batch: 0002 / 0002 | Loss: 0.7147\n",
            "[Epoch 0023] Training Avg Loss: 0.7056 | Validation Avg Loss: 0.7151\n",
            "[Train] | Epoch: 0024 / 1000 | Batch: 0001 / 0004 | Loss: 0.7033\n",
            "[Train] | Epoch: 0024 / 1000 | Batch: 0002 / 0004 | Loss: 0.6953\n",
            "[Train] | Epoch: 0024 / 1000 | Batch: 0003 / 0004 | Loss: 0.6931\n",
            "[Train] | Epoch: 0024 / 1000 | Batch: 0004 / 0004 | Loss: 0.7030\n",
            "[Validation] | Epoch: 0024 / 1000 | Batch: 0001 / 0002 | Loss: 0.7371\n",
            "[Validation] | Epoch: 0024 / 1000 | Batch: 0002 / 0002 | Loss: 0.7311\n",
            "[Epoch 0024] Training Avg Loss: 0.6987 | Validation Avg Loss: 0.7341\n",
            "[Train] | Epoch: 0025 / 1000 | Batch: 0001 / 0004 | Loss: 0.7012\n",
            "[Train] | Epoch: 0025 / 1000 | Batch: 0002 / 0004 | Loss: 0.7144\n",
            "[Train] | Epoch: 0025 / 1000 | Batch: 0003 / 0004 | Loss: 0.7034\n",
            "[Train] | Epoch: 0025 / 1000 | Batch: 0004 / 0004 | Loss: 0.6997\n",
            "[Validation] | Epoch: 0025 / 1000 | Batch: 0001 / 0002 | Loss: 0.6987\n",
            "[Validation] | Epoch: 0025 / 1000 | Batch: 0002 / 0002 | Loss: 0.7012\n",
            "[Epoch 0025] Training Avg Loss: 0.7047 | Validation Avg Loss: 0.6999\n",
            "[Train] | Epoch: 0026 / 1000 | Batch: 0001 / 0004 | Loss: 0.6987\n",
            "[Train] | Epoch: 0026 / 1000 | Batch: 0002 / 0004 | Loss: 0.7054\n",
            "[Train] | Epoch: 0026 / 1000 | Batch: 0003 / 0004 | Loss: 0.7054\n",
            "[Train] | Epoch: 0026 / 1000 | Batch: 0004 / 0004 | Loss: 0.6899\n",
            "[Validation] | Epoch: 0026 / 1000 | Batch: 0001 / 0002 | Loss: 0.7054\n",
            "[Validation] | Epoch: 0026 / 1000 | Batch: 0002 / 0002 | Loss: 0.7065\n",
            "[Epoch 0026] Training Avg Loss: 0.6999 | Validation Avg Loss: 0.7060\n",
            "[Train] | Epoch: 0027 / 1000 | Batch: 0001 / 0004 | Loss: 0.7006\n",
            "[Train] | Epoch: 0027 / 1000 | Batch: 0002 / 0004 | Loss: 0.6870\n",
            "[Train] | Epoch: 0027 / 1000 | Batch: 0003 / 0004 | Loss: 0.6976\n",
            "[Train] | Epoch: 0027 / 1000 | Batch: 0004 / 0004 | Loss: 0.6775\n",
            "[Validation] | Epoch: 0027 / 1000 | Batch: 0001 / 0002 | Loss: 0.6977\n",
            "[Validation] | Epoch: 0027 / 1000 | Batch: 0002 / 0002 | Loss: 0.6990\n",
            "[Epoch 0027] Training Avg Loss: 0.6906 | Validation Avg Loss: 0.6984\n",
            "[Train] | Epoch: 0028 / 1000 | Batch: 0001 / 0004 | Loss: 0.6834\n",
            "[Train] | Epoch: 0028 / 1000 | Batch: 0002 / 0004 | Loss: 0.6781\n",
            "[Train] | Epoch: 0028 / 1000 | Batch: 0003 / 0004 | Loss: 0.6870\n",
            "[Train] | Epoch: 0028 / 1000 | Batch: 0004 / 0004 | Loss: 0.6905\n",
            "[Validation] | Epoch: 0028 / 1000 | Batch: 0001 / 0002 | Loss: 0.6949\n",
            "[Validation] | Epoch: 0028 / 1000 | Batch: 0002 / 0002 | Loss: 0.6945\n",
            "[Epoch 0028] Training Avg Loss: 0.6848 | Validation Avg Loss: 0.6947\n",
            "[Train] | Epoch: 0029 / 1000 | Batch: 0001 / 0004 | Loss: 0.6908\n",
            "[Train] | Epoch: 0029 / 1000 | Batch: 0002 / 0004 | Loss: 0.6705\n",
            "[Train] | Epoch: 0029 / 1000 | Batch: 0003 / 0004 | Loss: 0.6722\n",
            "[Train] | Epoch: 0029 / 1000 | Batch: 0004 / 0004 | Loss: 0.6786\n",
            "[Validation] | Epoch: 0029 / 1000 | Batch: 0001 / 0002 | Loss: 0.6905\n",
            "[Validation] | Epoch: 0029 / 1000 | Batch: 0002 / 0002 | Loss: 0.6878\n",
            "[Epoch 0029] Training Avg Loss: 0.6780 | Validation Avg Loss: 0.6891\n",
            "[Train] | Epoch: 0030 / 1000 | Batch: 0001 / 0004 | Loss: 0.6758\n",
            "[Train] | Epoch: 0030 / 1000 | Batch: 0002 / 0004 | Loss: 0.6729\n",
            "[Train] | Epoch: 0030 / 1000 | Batch: 0003 / 0004 | Loss: 0.6659\n",
            "[Train] | Epoch: 0030 / 1000 | Batch: 0004 / 0004 | Loss: 0.6669\n",
            "[Validation] | Epoch: 0030 / 1000 | Batch: 0001 / 0002 | Loss: 0.6947\n",
            "[Validation] | Epoch: 0030 / 1000 | Batch: 0002 / 0002 | Loss: 0.6888\n",
            "[Epoch 0030] Training Avg Loss: 0.6704 | Validation Avg Loss: 0.6918\n",
            "[Train] | Epoch: 0031 / 1000 | Batch: 0001 / 0004 | Loss: 0.6746\n",
            "[Train] | Epoch: 0031 / 1000 | Batch: 0002 / 0004 | Loss: 0.6598\n",
            "[Train] | Epoch: 0031 / 1000 | Batch: 0003 / 0004 | Loss: 0.6543\n",
            "[Train] | Epoch: 0031 / 1000 | Batch: 0004 / 0004 | Loss: 0.6655\n",
            "[Validation] | Epoch: 0031 / 1000 | Batch: 0001 / 0002 | Loss: 0.6753\n",
            "[Validation] | Epoch: 0031 / 1000 | Batch: 0002 / 0002 | Loss: 0.6707\n",
            "[Epoch 0031] Training Avg Loss: 0.6636 | Validation Avg Loss: 0.6730\n",
            "[Train] | Epoch: 0032 / 1000 | Batch: 0001 / 0004 | Loss: 0.6585\n",
            "[Train] | Epoch: 0032 / 1000 | Batch: 0002 / 0004 | Loss: 0.6584\n",
            "[Train] | Epoch: 0032 / 1000 | Batch: 0003 / 0004 | Loss: 0.6637\n",
            "[Train] | Epoch: 0032 / 1000 | Batch: 0004 / 0004 | Loss: 0.6433\n",
            "[Validation] | Epoch: 0032 / 1000 | Batch: 0001 / 0002 | Loss: 0.6729\n",
            "[Validation] | Epoch: 0032 / 1000 | Batch: 0002 / 0002 | Loss: 0.6689\n",
            "[Epoch 0032] Training Avg Loss: 0.6560 | Validation Avg Loss: 0.6709\n",
            "[Train] | Epoch: 0033 / 1000 | Batch: 0001 / 0004 | Loss: 0.6487\n",
            "[Train] | Epoch: 0033 / 1000 | Batch: 0002 / 0004 | Loss: 0.6631\n",
            "[Train] | Epoch: 0033 / 1000 | Batch: 0003 / 0004 | Loss: 0.6477\n",
            "[Train] | Epoch: 0033 / 1000 | Batch: 0004 / 0004 | Loss: 0.6431\n",
            "[Validation] | Epoch: 0033 / 1000 | Batch: 0001 / 0002 | Loss: 0.6552\n",
            "[Validation] | Epoch: 0033 / 1000 | Batch: 0002 / 0002 | Loss: 0.6506\n",
            "[Epoch 0033] Training Avg Loss: 0.6507 | Validation Avg Loss: 0.6529\n",
            "[Train] | Epoch: 0034 / 1000 | Batch: 0001 / 0004 | Loss: 0.6470\n",
            "[Train] | Epoch: 0034 / 1000 | Batch: 0002 / 0004 | Loss: 0.6468\n",
            "[Train] | Epoch: 0034 / 1000 | Batch: 0003 / 0004 | Loss: 0.6388\n",
            "[Train] | Epoch: 0034 / 1000 | Batch: 0004 / 0004 | Loss: 0.6448\n",
            "[Validation] | Epoch: 0034 / 1000 | Batch: 0001 / 0002 | Loss: 0.6539\n",
            "[Validation] | Epoch: 0034 / 1000 | Batch: 0002 / 0002 | Loss: 0.6474\n",
            "[Epoch 0034] Training Avg Loss: 0.6444 | Validation Avg Loss: 0.6506\n",
            "[Train] | Epoch: 0035 / 1000 | Batch: 0001 / 0004 | Loss: 0.6434\n",
            "[Train] | Epoch: 0035 / 1000 | Batch: 0002 / 0004 | Loss: 0.6363\n",
            "[Train] | Epoch: 0035 / 1000 | Batch: 0003 / 0004 | Loss: 0.6474\n",
            "[Train] | Epoch: 0035 / 1000 | Batch: 0004 / 0004 | Loss: 0.6282\n",
            "[Validation] | Epoch: 0035 / 1000 | Batch: 0001 / 0002 | Loss: 0.6429\n",
            "[Validation] | Epoch: 0035 / 1000 | Batch: 0002 / 0002 | Loss: 0.6329\n",
            "[Epoch 0035] Training Avg Loss: 0.6388 | Validation Avg Loss: 0.6379\n",
            "[Train] | Epoch: 0036 / 1000 | Batch: 0001 / 0004 | Loss: 0.6344\n",
            "[Train] | Epoch: 0036 / 1000 | Batch: 0002 / 0004 | Loss: 0.6495\n",
            "[Train] | Epoch: 0036 / 1000 | Batch: 0003 / 0004 | Loss: 0.6278\n",
            "[Train] | Epoch: 0036 / 1000 | Batch: 0004 / 0004 | Loss: 0.6232\n",
            "[Validation] | Epoch: 0036 / 1000 | Batch: 0001 / 0002 | Loss: 0.6540\n",
            "[Validation] | Epoch: 0036 / 1000 | Batch: 0002 / 0002 | Loss: 0.6452\n",
            "[Epoch 0036] Training Avg Loss: 0.6338 | Validation Avg Loss: 0.6496\n",
            "[Train] | Epoch: 0037 / 1000 | Batch: 0001 / 0004 | Loss: 0.6286\n",
            "[Train] | Epoch: 0037 / 1000 | Batch: 0002 / 0004 | Loss: 0.6231\n",
            "[Train] | Epoch: 0037 / 1000 | Batch: 0003 / 0004 | Loss: 0.6337\n",
            "[Train] | Epoch: 0037 / 1000 | Batch: 0004 / 0004 | Loss: 0.6257\n",
            "[Validation] | Epoch: 0037 / 1000 | Batch: 0001 / 0002 | Loss: 0.6331\n",
            "[Validation] | Epoch: 0037 / 1000 | Batch: 0002 / 0002 | Loss: 0.6229\n",
            "[Epoch 0037] Training Avg Loss: 0.6277 | Validation Avg Loss: 0.6280\n",
            "[Train] | Epoch: 0038 / 1000 | Batch: 0001 / 0004 | Loss: 0.6243\n",
            "[Train] | Epoch: 0038 / 1000 | Batch: 0002 / 0004 | Loss: 0.6196\n",
            "[Train] | Epoch: 0038 / 1000 | Batch: 0003 / 0004 | Loss: 0.6282\n",
            "[Train] | Epoch: 0038 / 1000 | Batch: 0004 / 0004 | Loss: 0.6123\n",
            "[Validation] | Epoch: 0038 / 1000 | Batch: 0001 / 0002 | Loss: 0.6350\n",
            "[Validation] | Epoch: 0038 / 1000 | Batch: 0002 / 0002 | Loss: 0.6273\n",
            "[Epoch 0038] Training Avg Loss: 0.6211 | Validation Avg Loss: 0.6312\n",
            "[Train] | Epoch: 0039 / 1000 | Batch: 0001 / 0004 | Loss: 0.6163\n",
            "[Train] | Epoch: 0039 / 1000 | Batch: 0002 / 0004 | Loss: 0.6173\n",
            "[Train] | Epoch: 0039 / 1000 | Batch: 0003 / 0004 | Loss: 0.6151\n",
            "[Train] | Epoch: 0039 / 1000 | Batch: 0004 / 0004 | Loss: 0.6141\n",
            "[Validation] | Epoch: 0039 / 1000 | Batch: 0001 / 0002 | Loss: 0.6355\n",
            "[Validation] | Epoch: 0039 / 1000 | Batch: 0002 / 0002 | Loss: 0.6254\n",
            "[Epoch 0039] Training Avg Loss: 0.6157 | Validation Avg Loss: 0.6304\n",
            "[Train] | Epoch: 0040 / 1000 | Batch: 0001 / 0004 | Loss: 0.6151\n",
            "[Train] | Epoch: 0040 / 1000 | Batch: 0002 / 0004 | Loss: 0.6094\n",
            "[Train] | Epoch: 0040 / 1000 | Batch: 0003 / 0004 | Loss: 0.6199\n",
            "[Train] | Epoch: 0040 / 1000 | Batch: 0004 / 0004 | Loss: 0.6030\n",
            "[Validation] | Epoch: 0040 / 1000 | Batch: 0001 / 0002 | Loss: 0.6605\n",
            "[Validation] | Epoch: 0040 / 1000 | Batch: 0002 / 0002 | Loss: 0.6499\n",
            "[Epoch 0040] Training Avg Loss: 0.6118 | Validation Avg Loss: 0.6552\n",
            "[Train] | Epoch: 0041 / 1000 | Batch: 0001 / 0004 | Loss: 0.6036\n",
            "[Train] | Epoch: 0041 / 1000 | Batch: 0002 / 0004 | Loss: 0.6398\n",
            "[Train] | Epoch: 0041 / 1000 | Batch: 0003 / 0004 | Loss: 0.6078\n",
            "[Train] | Epoch: 0041 / 1000 | Batch: 0004 / 0004 | Loss: 0.6161\n",
            "[Validation] | Epoch: 0041 / 1000 | Batch: 0001 / 0002 | Loss: 0.6324\n",
            "[Validation] | Epoch: 0041 / 1000 | Batch: 0002 / 0002 | Loss: 0.6204\n",
            "[Epoch 0041] Training Avg Loss: 0.6168 | Validation Avg Loss: 0.6264\n",
            "[Train] | Epoch: 0042 / 1000 | Batch: 0001 / 0004 | Loss: 0.6181\n",
            "[Train] | Epoch: 0042 / 1000 | Batch: 0002 / 0004 | Loss: 0.6112\n",
            "[Train] | Epoch: 0042 / 1000 | Batch: 0003 / 0004 | Loss: 0.6102\n",
            "[Train] | Epoch: 0042 / 1000 | Batch: 0004 / 0004 | Loss: 0.5970\n",
            "[Validation] | Epoch: 0042 / 1000 | Batch: 0001 / 0002 | Loss: 0.6522\n",
            "[Validation] | Epoch: 0042 / 1000 | Batch: 0002 / 0002 | Loss: 0.6316\n",
            "[Epoch 0042] Training Avg Loss: 0.6091 | Validation Avg Loss: 0.6419\n",
            "[Train] | Epoch: 0043 / 1000 | Batch: 0001 / 0004 | Loss: 0.6115\n",
            "[Train] | Epoch: 0043 / 1000 | Batch: 0002 / 0004 | Loss: 0.5979\n",
            "[Train] | Epoch: 0043 / 1000 | Batch: 0003 / 0004 | Loss: 0.6096\n",
            "[Train] | Epoch: 0043 / 1000 | Batch: 0004 / 0004 | Loss: 0.6083\n",
            "[Validation] | Epoch: 0043 / 1000 | Batch: 0001 / 0002 | Loss: 0.6120\n",
            "[Validation] | Epoch: 0043 / 1000 | Batch: 0002 / 0002 | Loss: 0.6013\n",
            "[Epoch 0043] Training Avg Loss: 0.6068 | Validation Avg Loss: 0.6067\n",
            "[Train] | Epoch: 0044 / 1000 | Batch: 0001 / 0004 | Loss: 0.6074\n",
            "[Train] | Epoch: 0044 / 1000 | Batch: 0002 / 0004 | Loss: 0.5925\n",
            "[Train] | Epoch: 0044 / 1000 | Batch: 0003 / 0004 | Loss: 0.6022\n",
            "[Train] | Epoch: 0044 / 1000 | Batch: 0004 / 0004 | Loss: 0.6011\n",
            "[Validation] | Epoch: 0044 / 1000 | Batch: 0001 / 0002 | Loss: 0.6246\n",
            "[Validation] | Epoch: 0044 / 1000 | Batch: 0002 / 0002 | Loss: 0.6120\n",
            "[Epoch 0044] Training Avg Loss: 0.6008 | Validation Avg Loss: 0.6183\n",
            "[Train] | Epoch: 0045 / 1000 | Batch: 0001 / 0004 | Loss: 0.5899\n",
            "[Train] | Epoch: 0045 / 1000 | Batch: 0002 / 0004 | Loss: 0.6016\n",
            "[Train] | Epoch: 0045 / 1000 | Batch: 0003 / 0004 | Loss: 0.5963\n",
            "[Train] | Epoch: 0045 / 1000 | Batch: 0004 / 0004 | Loss: 0.5843\n",
            "[Validation] | Epoch: 0045 / 1000 | Batch: 0001 / 0002 | Loss: 0.6046\n",
            "[Validation] | Epoch: 0045 / 1000 | Batch: 0002 / 0002 | Loss: 0.5941\n",
            "[Epoch 0045] Training Avg Loss: 0.5930 | Validation Avg Loss: 0.5993\n",
            "[Train] | Epoch: 0046 / 1000 | Batch: 0001 / 0004 | Loss: 0.5923\n",
            "[Train] | Epoch: 0046 / 1000 | Batch: 0002 / 0004 | Loss: 0.5885\n",
            "[Train] | Epoch: 0046 / 1000 | Batch: 0003 / 0004 | Loss: 0.5924\n",
            "[Train] | Epoch: 0046 / 1000 | Batch: 0004 / 0004 | Loss: 0.5692\n",
            "[Validation] | Epoch: 0046 / 1000 | Batch: 0001 / 0002 | Loss: 0.5944\n",
            "[Validation] | Epoch: 0046 / 1000 | Batch: 0002 / 0002 | Loss: 0.5773\n",
            "[Epoch 0046] Training Avg Loss: 0.5856 | Validation Avg Loss: 0.5859\n",
            "[Train] | Epoch: 0047 / 1000 | Batch: 0001 / 0004 | Loss: 0.5963\n",
            "[Train] | Epoch: 0047 / 1000 | Batch: 0002 / 0004 | Loss: 0.5779\n",
            "[Train] | Epoch: 0047 / 1000 | Batch: 0003 / 0004 | Loss: 0.5743\n",
            "[Train] | Epoch: 0047 / 1000 | Batch: 0004 / 0004 | Loss: 0.5937\n",
            "[Validation] | Epoch: 0047 / 1000 | Batch: 0001 / 0002 | Loss: 0.5974\n",
            "[Validation] | Epoch: 0047 / 1000 | Batch: 0002 / 0002 | Loss: 0.5799\n",
            "[Epoch 0047] Training Avg Loss: 0.5856 | Validation Avg Loss: 0.5887\n",
            "[Train] | Epoch: 0048 / 1000 | Batch: 0001 / 0004 | Loss: 0.5793\n",
            "[Train] | Epoch: 0048 / 1000 | Batch: 0002 / 0004 | Loss: 0.5718\n",
            "[Train] | Epoch: 0048 / 1000 | Batch: 0003 / 0004 | Loss: 0.5832\n",
            "[Train] | Epoch: 0048 / 1000 | Batch: 0004 / 0004 | Loss: 0.5760\n",
            "[Validation] | Epoch: 0048 / 1000 | Batch: 0001 / 0002 | Loss: 0.6012\n",
            "[Validation] | Epoch: 0048 / 1000 | Batch: 0002 / 0002 | Loss: 0.5832\n",
            "[Epoch 0048] Training Avg Loss: 0.5776 | Validation Avg Loss: 0.5922\n",
            "[Train] | Epoch: 0049 / 1000 | Batch: 0001 / 0004 | Loss: 0.5847\n",
            "[Train] | Epoch: 0049 / 1000 | Batch: 0002 / 0004 | Loss: 0.5702\n",
            "[Train] | Epoch: 0049 / 1000 | Batch: 0003 / 0004 | Loss: 0.5563\n",
            "[Train] | Epoch: 0049 / 1000 | Batch: 0004 / 0004 | Loss: 0.5772\n",
            "[Validation] | Epoch: 0049 / 1000 | Batch: 0001 / 0002 | Loss: 0.5876\n",
            "[Validation] | Epoch: 0049 / 1000 | Batch: 0002 / 0002 | Loss: 0.5660\n",
            "[Epoch 0049] Training Avg Loss: 0.5721 | Validation Avg Loss: 0.5768\n",
            "[Train] | Epoch: 0050 / 1000 | Batch: 0001 / 0004 | Loss: 0.5690\n",
            "[Train] | Epoch: 0050 / 1000 | Batch: 0002 / 0004 | Loss: 0.5746\n",
            "[Train] | Epoch: 0050 / 1000 | Batch: 0003 / 0004 | Loss: 0.5595\n",
            "[Train] | Epoch: 0050 / 1000 | Batch: 0004 / 0004 | Loss: 0.5556\n",
            "[Validation] | Epoch: 0050 / 1000 | Batch: 0001 / 0002 | Loss: 0.5896\n",
            "[Validation] | Epoch: 0050 / 1000 | Batch: 0002 / 0002 | Loss: 0.5699\n",
            "[Epoch 0050] Training Avg Loss: 0.5647 | Validation Avg Loss: 0.5797\n",
            "[Train] | Epoch: 0051 / 1000 | Batch: 0001 / 0004 | Loss: 0.5686\n",
            "[Train] | Epoch: 0051 / 1000 | Batch: 0002 / 0004 | Loss: 0.5617\n",
            "[Train] | Epoch: 0051 / 1000 | Batch: 0003 / 0004 | Loss: 0.5559\n",
            "[Train] | Epoch: 0051 / 1000 | Batch: 0004 / 0004 | Loss: 0.5643\n",
            "[Validation] | Epoch: 0051 / 1000 | Batch: 0001 / 0002 | Loss: 0.5706\n",
            "[Validation] | Epoch: 0051 / 1000 | Batch: 0002 / 0002 | Loss: 0.5509\n",
            "[Epoch 0051] Training Avg Loss: 0.5626 | Validation Avg Loss: 0.5607\n",
            "[Train] | Epoch: 0052 / 1000 | Batch: 0001 / 0004 | Loss: 0.5593\n",
            "[Train] | Epoch: 0052 / 1000 | Batch: 0002 / 0004 | Loss: 0.5680\n",
            "[Train] | Epoch: 0052 / 1000 | Batch: 0003 / 0004 | Loss: 0.5597\n",
            "[Train] | Epoch: 0052 / 1000 | Batch: 0004 / 0004 | Loss: 0.5663\n",
            "[Validation] | Epoch: 0052 / 1000 | Batch: 0001 / 0002 | Loss: 0.5824\n",
            "[Validation] | Epoch: 0052 / 1000 | Batch: 0002 / 0002 | Loss: 0.5642\n",
            "[Epoch 0052] Training Avg Loss: 0.5633 | Validation Avg Loss: 0.5733\n",
            "[Train] | Epoch: 0053 / 1000 | Batch: 0001 / 0004 | Loss: 0.5608\n",
            "[Train] | Epoch: 0053 / 1000 | Batch: 0002 / 0004 | Loss: 0.5682\n",
            "[Train] | Epoch: 0053 / 1000 | Batch: 0003 / 0004 | Loss: 0.5578\n",
            "[Train] | Epoch: 0053 / 1000 | Batch: 0004 / 0004 | Loss: 0.5487\n",
            "[Validation] | Epoch: 0053 / 1000 | Batch: 0001 / 0002 | Loss: 0.5630\n",
            "[Validation] | Epoch: 0053 / 1000 | Batch: 0002 / 0002 | Loss: 0.5450\n",
            "[Epoch 0053] Training Avg Loss: 0.5589 | Validation Avg Loss: 0.5540\n",
            "[Train] | Epoch: 0054 / 1000 | Batch: 0001 / 0004 | Loss: 0.5580\n",
            "[Train] | Epoch: 0054 / 1000 | Batch: 0002 / 0004 | Loss: 0.5469\n",
            "[Train] | Epoch: 0054 / 1000 | Batch: 0003 / 0004 | Loss: 0.5499\n",
            "[Train] | Epoch: 0054 / 1000 | Batch: 0004 / 0004 | Loss: 0.5636\n",
            "[Validation] | Epoch: 0054 / 1000 | Batch: 0001 / 0002 | Loss: 0.5570\n",
            "[Validation] | Epoch: 0054 / 1000 | Batch: 0002 / 0002 | Loss: 0.5366\n",
            "[Epoch 0054] Training Avg Loss: 0.5546 | Validation Avg Loss: 0.5468\n",
            "[Train] | Epoch: 0055 / 1000 | Batch: 0001 / 0004 | Loss: 0.5468\n",
            "[Train] | Epoch: 0055 / 1000 | Batch: 0002 / 0004 | Loss: 0.5572\n",
            "[Train] | Epoch: 0055 / 1000 | Batch: 0003 / 0004 | Loss: 0.5592\n",
            "[Train] | Epoch: 0055 / 1000 | Batch: 0004 / 0004 | Loss: 0.5376\n",
            "[Validation] | Epoch: 0055 / 1000 | Batch: 0001 / 0002 | Loss: 0.5620\n",
            "[Validation] | Epoch: 0055 / 1000 | Batch: 0002 / 0002 | Loss: 0.5429\n",
            "[Epoch 0055] Training Avg Loss: 0.5502 | Validation Avg Loss: 0.5525\n",
            "[Train] | Epoch: 0056 / 1000 | Batch: 0001 / 0004 | Loss: 0.5481\n",
            "[Train] | Epoch: 0056 / 1000 | Batch: 0002 / 0004 | Loss: 0.5440\n",
            "[Train] | Epoch: 0056 / 1000 | Batch: 0003 / 0004 | Loss: 0.5466\n",
            "[Train] | Epoch: 0056 / 1000 | Batch: 0004 / 0004 | Loss: 0.5472\n",
            "[Validation] | Epoch: 0056 / 1000 | Batch: 0001 / 0002 | Loss: 0.5678\n",
            "[Validation] | Epoch: 0056 / 1000 | Batch: 0002 / 0002 | Loss: 0.5461\n",
            "[Epoch 0056] Training Avg Loss: 0.5465 | Validation Avg Loss: 0.5569\n",
            "[Train] | Epoch: 0057 / 1000 | Batch: 0001 / 0004 | Loss: 0.5415\n",
            "[Train] | Epoch: 0057 / 1000 | Batch: 0002 / 0004 | Loss: 0.5481\n",
            "[Train] | Epoch: 0057 / 1000 | Batch: 0003 / 0004 | Loss: 0.5393\n",
            "[Train] | Epoch: 0057 / 1000 | Batch: 0004 / 0004 | Loss: 0.5457\n",
            "[Validation] | Epoch: 0057 / 1000 | Batch: 0001 / 0002 | Loss: 0.5565\n",
            "[Validation] | Epoch: 0057 / 1000 | Batch: 0002 / 0002 | Loss: 0.5333\n",
            "[Epoch 0057] Training Avg Loss: 0.5437 | Validation Avg Loss: 0.5449\n",
            "[Train] | Epoch: 0058 / 1000 | Batch: 0001 / 0004 | Loss: 0.5375\n",
            "[Train] | Epoch: 0058 / 1000 | Batch: 0002 / 0004 | Loss: 0.5411\n",
            "[Train] | Epoch: 0058 / 1000 | Batch: 0003 / 0004 | Loss: 0.5372\n",
            "[Train] | Epoch: 0058 / 1000 | Batch: 0004 / 0004 | Loss: 0.5326\n",
            "[Validation] | Epoch: 0058 / 1000 | Batch: 0001 / 0002 | Loss: 0.5479\n",
            "[Validation] | Epoch: 0058 / 1000 | Batch: 0002 / 0002 | Loss: 0.5276\n",
            "[Epoch 0058] Training Avg Loss: 0.5371 | Validation Avg Loss: 0.5377\n",
            "[Train] | Epoch: 0059 / 1000 | Batch: 0001 / 0004 | Loss: 0.5342\n",
            "[Train] | Epoch: 0059 / 1000 | Batch: 0002 / 0004 | Loss: 0.5342\n",
            "[Train] | Epoch: 0059 / 1000 | Batch: 0003 / 0004 | Loss: 0.5270\n",
            "[Train] | Epoch: 0059 / 1000 | Batch: 0004 / 0004 | Loss: 0.5351\n",
            "[Validation] | Epoch: 0059 / 1000 | Batch: 0001 / 0002 | Loss: 0.5390\n",
            "[Validation] | Epoch: 0059 / 1000 | Batch: 0002 / 0002 | Loss: 0.5172\n",
            "[Epoch 0059] Training Avg Loss: 0.5326 | Validation Avg Loss: 0.5281\n",
            "[Train] | Epoch: 0060 / 1000 | Batch: 0001 / 0004 | Loss: 0.5280\n",
            "[Train] | Epoch: 0060 / 1000 | Batch: 0002 / 0004 | Loss: 0.5256\n",
            "[Train] | Epoch: 0060 / 1000 | Batch: 0003 / 0004 | Loss: 0.5333\n",
            "[Train] | Epoch: 0060 / 1000 | Batch: 0004 / 0004 | Loss: 0.5331\n",
            "[Validation] | Epoch: 0060 / 1000 | Batch: 0001 / 0002 | Loss: 0.5421\n",
            "[Validation] | Epoch: 0060 / 1000 | Batch: 0002 / 0002 | Loss: 0.5197\n",
            "[Epoch 0060] Training Avg Loss: 0.5300 | Validation Avg Loss: 0.5309\n",
            "[Train] | Epoch: 0061 / 1000 | Batch: 0001 / 0004 | Loss: 0.5252\n",
            "[Train] | Epoch: 0061 / 1000 | Batch: 0002 / 0004 | Loss: 0.5321\n",
            "[Train] | Epoch: 0061 / 1000 | Batch: 0003 / 0004 | Loss: 0.5273\n",
            "[Train] | Epoch: 0061 / 1000 | Batch: 0004 / 0004 | Loss: 0.5181\n",
            "[Validation] | Epoch: 0061 / 1000 | Batch: 0001 / 0002 | Loss: 0.5426\n",
            "[Validation] | Epoch: 0061 / 1000 | Batch: 0002 / 0002 | Loss: 0.5211\n",
            "[Epoch 0061] Training Avg Loss: 0.5257 | Validation Avg Loss: 0.5318\n",
            "[Train] | Epoch: 0062 / 1000 | Batch: 0001 / 0004 | Loss: 0.5310\n",
            "[Train] | Epoch: 0062 / 1000 | Batch: 0002 / 0004 | Loss: 0.5248\n",
            "[Train] | Epoch: 0062 / 1000 | Batch: 0003 / 0004 | Loss: 0.5157\n",
            "[Train] | Epoch: 0062 / 1000 | Batch: 0004 / 0004 | Loss: 0.5183\n",
            "[Validation] | Epoch: 0062 / 1000 | Batch: 0001 / 0002 | Loss: 0.5358\n",
            "[Validation] | Epoch: 0062 / 1000 | Batch: 0002 / 0002 | Loss: 0.5144\n",
            "[Epoch 0062] Training Avg Loss: 0.5224 | Validation Avg Loss: 0.5251\n",
            "[Train] | Epoch: 0063 / 1000 | Batch: 0001 / 0004 | Loss: 0.5272\n",
            "[Train] | Epoch: 0063 / 1000 | Batch: 0002 / 0004 | Loss: 0.5218\n",
            "[Train] | Epoch: 0063 / 1000 | Batch: 0003 / 0004 | Loss: 0.5122\n",
            "[Train] | Epoch: 0063 / 1000 | Batch: 0004 / 0004 | Loss: 0.5164\n",
            "[Validation] | Epoch: 0063 / 1000 | Batch: 0001 / 0002 | Loss: 0.5385\n",
            "[Validation] | Epoch: 0063 / 1000 | Batch: 0002 / 0002 | Loss: 0.5134\n",
            "[Epoch 0063] Training Avg Loss: 0.5194 | Validation Avg Loss: 0.5259\n",
            "[Train] | Epoch: 0064 / 1000 | Batch: 0001 / 0004 | Loss: 0.5095\n",
            "[Train] | Epoch: 0064 / 1000 | Batch: 0002 / 0004 | Loss: 0.5195\n",
            "[Train] | Epoch: 0064 / 1000 | Batch: 0003 / 0004 | Loss: 0.5125\n",
            "[Train] | Epoch: 0064 / 1000 | Batch: 0004 / 0004 | Loss: 0.5249\n",
            "[Validation] | Epoch: 0064 / 1000 | Batch: 0001 / 0002 | Loss: 0.5222\n",
            "[Validation] | Epoch: 0064 / 1000 | Batch: 0002 / 0002 | Loss: 0.5012\n",
            "[Epoch 0064] Training Avg Loss: 0.5166 | Validation Avg Loss: 0.5117\n",
            "[Train] | Epoch: 0065 / 1000 | Batch: 0001 / 0004 | Loss: 0.5098\n",
            "[Train] | Epoch: 0065 / 1000 | Batch: 0002 / 0004 | Loss: 0.5086\n",
            "[Train] | Epoch: 0065 / 1000 | Batch: 0003 / 0004 | Loss: 0.5216\n",
            "[Train] | Epoch: 0065 / 1000 | Batch: 0004 / 0004 | Loss: 0.5124\n",
            "[Validation] | Epoch: 0065 / 1000 | Batch: 0001 / 0002 | Loss: 0.5285\n",
            "[Validation] | Epoch: 0065 / 1000 | Batch: 0002 / 0002 | Loss: 0.5101\n",
            "[Epoch 0065] Training Avg Loss: 0.5131 | Validation Avg Loss: 0.5193\n",
            "[Train] | Epoch: 0066 / 1000 | Batch: 0001 / 0004 | Loss: 0.5031\n",
            "[Train] | Epoch: 0066 / 1000 | Batch: 0002 / 0004 | Loss: 0.5240\n",
            "[Train] | Epoch: 0066 / 1000 | Batch: 0003 / 0004 | Loss: 0.5103\n",
            "[Train] | Epoch: 0066 / 1000 | Batch: 0004 / 0004 | Loss: 0.5103\n",
            "[Validation] | Epoch: 0066 / 1000 | Batch: 0001 / 0002 | Loss: 0.5205\n",
            "[Validation] | Epoch: 0066 / 1000 | Batch: 0002 / 0002 | Loss: 0.5031\n",
            "[Epoch 0066] Training Avg Loss: 0.5119 | Validation Avg Loss: 0.5118\n",
            "[Train] | Epoch: 0067 / 1000 | Batch: 0001 / 0004 | Loss: 0.5039\n",
            "[Train] | Epoch: 0067 / 1000 | Batch: 0002 / 0004 | Loss: 0.5022\n",
            "[Train] | Epoch: 0067 / 1000 | Batch: 0003 / 0004 | Loss: 0.5235\n",
            "[Train] | Epoch: 0067 / 1000 | Batch: 0004 / 0004 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0067 / 1000 | Batch: 0001 / 0002 | Loss: 0.5144\n",
            "[Validation] | Epoch: 0067 / 1000 | Batch: 0002 / 0002 | Loss: 0.4942\n",
            "[Epoch 0067] Training Avg Loss: 0.5093 | Validation Avg Loss: 0.5043\n",
            "[Train] | Epoch: 0068 / 1000 | Batch: 0001 / 0004 | Loss: 0.5121\n",
            "[Train] | Epoch: 0068 / 1000 | Batch: 0002 / 0004 | Loss: 0.5029\n",
            "[Train] | Epoch: 0068 / 1000 | Batch: 0003 / 0004 | Loss: 0.5004\n",
            "[Train] | Epoch: 0068 / 1000 | Batch: 0004 / 0004 | Loss: 0.5116\n",
            "[Validation] | Epoch: 0068 / 1000 | Batch: 0001 / 0002 | Loss: 0.5141\n",
            "[Validation] | Epoch: 0068 / 1000 | Batch: 0002 / 0002 | Loss: 0.4929\n",
            "[Epoch 0068] Training Avg Loss: 0.5067 | Validation Avg Loss: 0.5035\n",
            "[Train] | Epoch: 0069 / 1000 | Batch: 0001 / 0004 | Loss: 0.5039\n",
            "[Train] | Epoch: 0069 / 1000 | Batch: 0002 / 0004 | Loss: 0.5017\n",
            "[Train] | Epoch: 0069 / 1000 | Batch: 0003 / 0004 | Loss: 0.5020\n",
            "[Train] | Epoch: 0069 / 1000 | Batch: 0004 / 0004 | Loss: 0.5029\n",
            "[Validation] | Epoch: 0069 / 1000 | Batch: 0001 / 0002 | Loss: 0.5139\n",
            "[Validation] | Epoch: 0069 / 1000 | Batch: 0002 / 0002 | Loss: 0.4995\n",
            "[Epoch 0069] Training Avg Loss: 0.5026 | Validation Avg Loss: 0.5067\n",
            "[Train] | Epoch: 0070 / 1000 | Batch: 0001 / 0004 | Loss: 0.4960\n",
            "[Train] | Epoch: 0070 / 1000 | Batch: 0002 / 0004 | Loss: 0.5007\n",
            "[Train] | Epoch: 0070 / 1000 | Batch: 0003 / 0004 | Loss: 0.5026\n",
            "[Train] | Epoch: 0070 / 1000 | Batch: 0004 / 0004 | Loss: 0.5002\n",
            "[Validation] | Epoch: 0070 / 1000 | Batch: 0001 / 0002 | Loss: 0.5058\n",
            "[Validation] | Epoch: 0070 / 1000 | Batch: 0002 / 0002 | Loss: 0.4881\n",
            "[Epoch 0070] Training Avg Loss: 0.4999 | Validation Avg Loss: 0.4970\n",
            "[Train] | Epoch: 0071 / 1000 | Batch: 0001 / 0004 | Loss: 0.4962\n",
            "[Train] | Epoch: 0071 / 1000 | Batch: 0002 / 0004 | Loss: 0.5015\n",
            "[Train] | Epoch: 0071 / 1000 | Batch: 0003 / 0004 | Loss: 0.4921\n",
            "[Train] | Epoch: 0071 / 1000 | Batch: 0004 / 0004 | Loss: 0.5107\n",
            "[Validation] | Epoch: 0071 / 1000 | Batch: 0001 / 0002 | Loss: 0.5653\n",
            "[Validation] | Epoch: 0071 / 1000 | Batch: 0002 / 0002 | Loss: 0.5583\n",
            "[Epoch 0071] Training Avg Loss: 0.5001 | Validation Avg Loss: 0.5618\n",
            "[Train] | Epoch: 0072 / 1000 | Batch: 0001 / 0004 | Loss: 0.5426\n",
            "[Train] | Epoch: 0072 / 1000 | Batch: 0002 / 0004 | Loss: 0.5360\n",
            "[Train] | Epoch: 0072 / 1000 | Batch: 0003 / 0004 | Loss: 0.5203\n",
            "[Train] | Epoch: 0072 / 1000 | Batch: 0004 / 0004 | Loss: 0.5353\n",
            "[Validation] | Epoch: 0072 / 1000 | Batch: 0001 / 0002 | Loss: 0.5939\n",
            "[Validation] | Epoch: 0072 / 1000 | Batch: 0002 / 0002 | Loss: 0.5488\n",
            "[Epoch 0072] Training Avg Loss: 0.5336 | Validation Avg Loss: 0.5713\n",
            "[Train] | Epoch: 0073 / 1000 | Batch: 0001 / 0004 | Loss: 0.5257\n",
            "[Train] | Epoch: 0073 / 1000 | Batch: 0002 / 0004 | Loss: 0.5251\n",
            "[Train] | Epoch: 0073 / 1000 | Batch: 0003 / 0004 | Loss: 0.5198\n",
            "[Train] | Epoch: 0073 / 1000 | Batch: 0004 / 0004 | Loss: 0.5287\n",
            "[Validation] | Epoch: 0073 / 1000 | Batch: 0001 / 0002 | Loss: 0.5277\n",
            "[Validation] | Epoch: 0073 / 1000 | Batch: 0002 / 0002 | Loss: 0.5043\n",
            "[Epoch 0073] Training Avg Loss: 0.5248 | Validation Avg Loss: 0.5160\n",
            "[Train] | Epoch: 0074 / 1000 | Batch: 0001 / 0004 | Loss: 0.5139\n",
            "[Train] | Epoch: 0074 / 1000 | Batch: 0002 / 0004 | Loss: 0.5179\n",
            "[Train] | Epoch: 0074 / 1000 | Batch: 0003 / 0004 | Loss: 0.5180\n",
            "[Train] | Epoch: 0074 / 1000 | Batch: 0004 / 0004 | Loss: 0.5171\n",
            "[Validation] | Epoch: 0074 / 1000 | Batch: 0001 / 0002 | Loss: 0.5273\n",
            "[Validation] | Epoch: 0074 / 1000 | Batch: 0002 / 0002 | Loss: 0.5137\n",
            "[Epoch 0074] Training Avg Loss: 0.5167 | Validation Avg Loss: 0.5205\n",
            "[Train] | Epoch: 0075 / 1000 | Batch: 0001 / 0004 | Loss: 0.5273\n",
            "[Train] | Epoch: 0075 / 1000 | Batch: 0002 / 0004 | Loss: 0.5041\n",
            "[Train] | Epoch: 0075 / 1000 | Batch: 0003 / 0004 | Loss: 0.5268\n",
            "[Train] | Epoch: 0075 / 1000 | Batch: 0004 / 0004 | Loss: 0.5172\n",
            "[Validation] | Epoch: 0075 / 1000 | Batch: 0001 / 0002 | Loss: 0.6487\n",
            "[Validation] | Epoch: 0075 / 1000 | Batch: 0002 / 0002 | Loss: 0.6296\n",
            "[Epoch 0075] Training Avg Loss: 0.5188 | Validation Avg Loss: 0.6391\n",
            "[Train] | Epoch: 0076 / 1000 | Batch: 0001 / 0004 | Loss: 0.5066\n",
            "[Train] | Epoch: 0076 / 1000 | Batch: 0002 / 0004 | Loss: 0.5219\n",
            "[Train] | Epoch: 0076 / 1000 | Batch: 0003 / 0004 | Loss: 0.5085\n",
            "[Train] | Epoch: 0076 / 1000 | Batch: 0004 / 0004 | Loss: 0.5106\n",
            "[Validation] | Epoch: 0076 / 1000 | Batch: 0001 / 0002 | Loss: 0.5255\n",
            "[Validation] | Epoch: 0076 / 1000 | Batch: 0002 / 0002 | Loss: 0.5042\n",
            "[Epoch 0076] Training Avg Loss: 0.5119 | Validation Avg Loss: 0.5149\n",
            "[Train] | Epoch: 0077 / 1000 | Batch: 0001 / 0004 | Loss: 0.5082\n",
            "[Train] | Epoch: 0077 / 1000 | Batch: 0002 / 0004 | Loss: 0.4987\n",
            "[Train] | Epoch: 0077 / 1000 | Batch: 0003 / 0004 | Loss: 0.5166\n",
            "[Train] | Epoch: 0077 / 1000 | Batch: 0004 / 0004 | Loss: 0.4987\n",
            "[Validation] | Epoch: 0077 / 1000 | Batch: 0001 / 0002 | Loss: 0.5173\n",
            "[Validation] | Epoch: 0077 / 1000 | Batch: 0002 / 0002 | Loss: 0.4973\n",
            "[Epoch 0077] Training Avg Loss: 0.5055 | Validation Avg Loss: 0.5073\n",
            "[Train] | Epoch: 0078 / 1000 | Batch: 0001 / 0004 | Loss: 0.4959\n",
            "[Train] | Epoch: 0078 / 1000 | Batch: 0002 / 0004 | Loss: 0.5056\n",
            "[Train] | Epoch: 0078 / 1000 | Batch: 0003 / 0004 | Loss: 0.5081\n",
            "[Train] | Epoch: 0078 / 1000 | Batch: 0004 / 0004 | Loss: 0.5056\n",
            "[Validation] | Epoch: 0078 / 1000 | Batch: 0001 / 0002 | Loss: 0.5141\n",
            "[Validation] | Epoch: 0078 / 1000 | Batch: 0002 / 0002 | Loss: 0.4946\n",
            "[Epoch 0078] Training Avg Loss: 0.5038 | Validation Avg Loss: 0.5043\n",
            "[Train] | Epoch: 0079 / 1000 | Batch: 0001 / 0004 | Loss: 0.4956\n",
            "[Train] | Epoch: 0079 / 1000 | Batch: 0002 / 0004 | Loss: 0.5192\n",
            "[Train] | Epoch: 0079 / 1000 | Batch: 0003 / 0004 | Loss: 0.4943\n",
            "[Train] | Epoch: 0079 / 1000 | Batch: 0004 / 0004 | Loss: 0.4962\n",
            "[Validation] | Epoch: 0079 / 1000 | Batch: 0001 / 0002 | Loss: 0.5127\n",
            "[Validation] | Epoch: 0079 / 1000 | Batch: 0002 / 0002 | Loss: 0.4923\n",
            "[Epoch 0079] Training Avg Loss: 0.5013 | Validation Avg Loss: 0.5025\n",
            "[Train] | Epoch: 0080 / 1000 | Batch: 0001 / 0004 | Loss: 0.4988\n",
            "[Train] | Epoch: 0080 / 1000 | Batch: 0002 / 0004 | Loss: 0.5048\n",
            "[Train] | Epoch: 0080 / 1000 | Batch: 0003 / 0004 | Loss: 0.4966\n",
            "[Train] | Epoch: 0080 / 1000 | Batch: 0004 / 0004 | Loss: 0.4979\n",
            "[Validation] | Epoch: 0080 / 1000 | Batch: 0001 / 0002 | Loss: 0.5126\n",
            "[Validation] | Epoch: 0080 / 1000 | Batch: 0002 / 0002 | Loss: 0.4910\n",
            "[Epoch 0080] Training Avg Loss: 0.4995 | Validation Avg Loss: 0.5018\n",
            "[Train] | Epoch: 0081 / 1000 | Batch: 0001 / 0004 | Loss: 0.5146\n",
            "[Train] | Epoch: 0081 / 1000 | Batch: 0002 / 0004 | Loss: 0.4992\n",
            "[Train] | Epoch: 0081 / 1000 | Batch: 0003 / 0004 | Loss: 0.4895\n",
            "[Train] | Epoch: 0081 / 1000 | Batch: 0004 / 0004 | Loss: 0.4894\n",
            "[Validation] | Epoch: 0081 / 1000 | Batch: 0001 / 0002 | Loss: 0.5104\n",
            "[Validation] | Epoch: 0081 / 1000 | Batch: 0002 / 0002 | Loss: 0.4887\n",
            "[Epoch 0081] Training Avg Loss: 0.4981 | Validation Avg Loss: 0.4995\n",
            "[Train] | Epoch: 0082 / 1000 | Batch: 0001 / 0004 | Loss: 0.4997\n",
            "[Train] | Epoch: 0082 / 1000 | Batch: 0002 / 0004 | Loss: 0.4991\n",
            "[Train] | Epoch: 0082 / 1000 | Batch: 0003 / 0004 | Loss: 0.4934\n",
            "[Train] | Epoch: 0082 / 1000 | Batch: 0004 / 0004 | Loss: 0.4974\n",
            "[Validation] | Epoch: 0082 / 1000 | Batch: 0001 / 0002 | Loss: 0.5082\n",
            "[Validation] | Epoch: 0082 / 1000 | Batch: 0002 / 0002 | Loss: 0.4868\n",
            "[Epoch 0082] Training Avg Loss: 0.4974 | Validation Avg Loss: 0.4975\n",
            "[Train] | Epoch: 0083 / 1000 | Batch: 0001 / 0004 | Loss: 0.4870\n",
            "[Train] | Epoch: 0083 / 1000 | Batch: 0002 / 0004 | Loss: 0.5097\n",
            "[Train] | Epoch: 0083 / 1000 | Batch: 0003 / 0004 | Loss: 0.4950\n",
            "[Train] | Epoch: 0083 / 1000 | Batch: 0004 / 0004 | Loss: 0.4946\n",
            "[Validation] | Epoch: 0083 / 1000 | Batch: 0001 / 0002 | Loss: 0.5080\n",
            "[Validation] | Epoch: 0083 / 1000 | Batch: 0002 / 0002 | Loss: 0.4864\n",
            "[Epoch 0083] Training Avg Loss: 0.4966 | Validation Avg Loss: 0.4972\n",
            "[Train] | Epoch: 0084 / 1000 | Batch: 0001 / 0004 | Loss: 0.4975\n",
            "[Train] | Epoch: 0084 / 1000 | Batch: 0002 / 0004 | Loss: 0.4914\n",
            "[Train] | Epoch: 0084 / 1000 | Batch: 0003 / 0004 | Loss: 0.4987\n",
            "[Train] | Epoch: 0084 / 1000 | Batch: 0004 / 0004 | Loss: 0.5010\n",
            "[Validation] | Epoch: 0084 / 1000 | Batch: 0001 / 0002 | Loss: 0.5079\n",
            "[Validation] | Epoch: 0084 / 1000 | Batch: 0002 / 0002 | Loss: 0.4863\n",
            "[Epoch 0084] Training Avg Loss: 0.4972 | Validation Avg Loss: 0.4971\n",
            "[Train] | Epoch: 0085 / 1000 | Batch: 0001 / 0004 | Loss: 0.4901\n",
            "[Train] | Epoch: 0085 / 1000 | Batch: 0002 / 0004 | Loss: 0.4998\n",
            "[Train] | Epoch: 0085 / 1000 | Batch: 0003 / 0004 | Loss: 0.5033\n",
            "[Train] | Epoch: 0085 / 1000 | Batch: 0004 / 0004 | Loss: 0.4946\n",
            "[Validation] | Epoch: 0085 / 1000 | Batch: 0001 / 0002 | Loss: 0.5080\n",
            "[Validation] | Epoch: 0085 / 1000 | Batch: 0002 / 0002 | Loss: 0.4864\n",
            "[Epoch 0085] Training Avg Loss: 0.4970 | Validation Avg Loss: 0.4972\n",
            "[Train] | Epoch: 0086 / 1000 | Batch: 0001 / 0004 | Loss: 0.4977\n",
            "[Train] | Epoch: 0086 / 1000 | Batch: 0002 / 0004 | Loss: 0.4878\n",
            "[Train] | Epoch: 0086 / 1000 | Batch: 0003 / 0004 | Loss: 0.5019\n",
            "[Train] | Epoch: 0086 / 1000 | Batch: 0004 / 0004 | Loss: 0.4984\n",
            "[Validation] | Epoch: 0086 / 1000 | Batch: 0001 / 0002 | Loss: 0.5078\n",
            "[Validation] | Epoch: 0086 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0086] Training Avg Loss: 0.4965 | Validation Avg Loss: 0.4970\n",
            "[Train] | Epoch: 0087 / 1000 | Batch: 0001 / 0004 | Loss: 0.4987\n",
            "[Train] | Epoch: 0087 / 1000 | Batch: 0002 / 0004 | Loss: 0.5005\n",
            "[Train] | Epoch: 0087 / 1000 | Batch: 0003 / 0004 | Loss: 0.4883\n",
            "[Train] | Epoch: 0087 / 1000 | Batch: 0004 / 0004 | Loss: 0.5018\n",
            "[Validation] | Epoch: 0087 / 1000 | Batch: 0001 / 0002 | Loss: 0.5077\n",
            "[Validation] | Epoch: 0087 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0087] Training Avg Loss: 0.4973 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0088 / 1000 | Batch: 0001 / 0004 | Loss: 0.4973\n",
            "[Train] | Epoch: 0088 / 1000 | Batch: 0002 / 0004 | Loss: 0.4938\n",
            "[Train] | Epoch: 0088 / 1000 | Batch: 0003 / 0004 | Loss: 0.4973\n",
            "[Train] | Epoch: 0088 / 1000 | Batch: 0004 / 0004 | Loss: 0.4950\n",
            "[Validation] | Epoch: 0088 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0088 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0088] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0089 / 1000 | Batch: 0001 / 0004 | Loss: 0.4910\n",
            "[Train] | Epoch: 0089 / 1000 | Batch: 0002 / 0004 | Loss: 0.4960\n",
            "[Train] | Epoch: 0089 / 1000 | Batch: 0003 / 0004 | Loss: 0.5036\n",
            "[Train] | Epoch: 0089 / 1000 | Batch: 0004 / 0004 | Loss: 0.4948\n",
            "[Validation] | Epoch: 0089 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0089 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0089] Training Avg Loss: 0.4964 | Validation Avg Loss: 0.4969\n",
            "[Train] | Epoch: 0090 / 1000 | Batch: 0001 / 0004 | Loss: 0.5102\n",
            "[Train] | Epoch: 0090 / 1000 | Batch: 0002 / 0004 | Loss: 0.4884\n",
            "[Train] | Epoch: 0090 / 1000 | Batch: 0003 / 0004 | Loss: 0.4955\n",
            "[Train] | Epoch: 0090 / 1000 | Batch: 0004 / 0004 | Loss: 0.4881\n",
            "[Validation] | Epoch: 0090 / 1000 | Batch: 0001 / 0002 | Loss: 0.5078\n",
            "[Validation] | Epoch: 0090 / 1000 | Batch: 0002 / 0002 | Loss: 0.4865\n",
            "[Epoch 0090] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4971\n",
            "[Train] | Epoch: 0091 / 1000 | Batch: 0001 / 0004 | Loss: 0.4978\n",
            "[Train] | Epoch: 0091 / 1000 | Batch: 0002 / 0004 | Loss: 0.4990\n",
            "[Train] | Epoch: 0091 / 1000 | Batch: 0003 / 0004 | Loss: 0.4926\n",
            "[Train] | Epoch: 0091 / 1000 | Batch: 0004 / 0004 | Loss: 0.4957\n",
            "[Validation] | Epoch: 0091 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0091 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0091] Training Avg Loss: 0.4963 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0092 / 1000 | Batch: 0001 / 0004 | Loss: 0.5021\n",
            "[Train] | Epoch: 0092 / 1000 | Batch: 0002 / 0004 | Loss: 0.5007\n",
            "[Train] | Epoch: 0092 / 1000 | Batch: 0003 / 0004 | Loss: 0.4900\n",
            "[Train] | Epoch: 0092 / 1000 | Batch: 0004 / 0004 | Loss: 0.4896\n",
            "[Validation] | Epoch: 0092 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0092 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0092] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0093 / 1000 | Batch: 0001 / 0004 | Loss: 0.4893\n",
            "[Train] | Epoch: 0093 / 1000 | Batch: 0002 / 0004 | Loss: 0.4927\n",
            "[Train] | Epoch: 0093 / 1000 | Batch: 0003 / 0004 | Loss: 0.4996\n",
            "[Train] | Epoch: 0093 / 1000 | Batch: 0004 / 0004 | Loss: 0.5035\n",
            "[Validation] | Epoch: 0093 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0093 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0093] Training Avg Loss: 0.4963 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0094 / 1000 | Batch: 0001 / 0004 | Loss: 0.4931\n",
            "[Train] | Epoch: 0094 / 1000 | Batch: 0002 / 0004 | Loss: 0.4881\n",
            "[Train] | Epoch: 0094 / 1000 | Batch: 0003 / 0004 | Loss: 0.5089\n",
            "[Train] | Epoch: 0094 / 1000 | Batch: 0004 / 0004 | Loss: 0.4909\n",
            "[Validation] | Epoch: 0094 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0094 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0094] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0095 / 1000 | Batch: 0001 / 0004 | Loss: 0.4865\n",
            "[Train] | Epoch: 0095 / 1000 | Batch: 0002 / 0004 | Loss: 0.4975\n",
            "[Train] | Epoch: 0095 / 1000 | Batch: 0003 / 0004 | Loss: 0.5075\n",
            "[Train] | Epoch: 0095 / 1000 | Batch: 0004 / 0004 | Loss: 0.4921\n",
            "[Validation] | Epoch: 0095 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0095 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0095] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0096 / 1000 | Batch: 0001 / 0004 | Loss: 0.4903\n",
            "[Train] | Epoch: 0096 / 1000 | Batch: 0002 / 0004 | Loss: 0.5061\n",
            "[Train] | Epoch: 0096 / 1000 | Batch: 0003 / 0004 | Loss: 0.4873\n",
            "[Train] | Epoch: 0096 / 1000 | Batch: 0004 / 0004 | Loss: 0.4984\n",
            "[Validation] | Epoch: 0096 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0096 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0096] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0097 / 1000 | Batch: 0001 / 0004 | Loss: 0.5015\n",
            "[Train] | Epoch: 0097 / 1000 | Batch: 0002 / 0004 | Loss: 0.4928\n",
            "[Train] | Epoch: 0097 / 1000 | Batch: 0003 / 0004 | Loss: 0.4885\n",
            "[Train] | Epoch: 0097 / 1000 | Batch: 0004 / 0004 | Loss: 0.5014\n",
            "[Validation] | Epoch: 0097 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0097 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0097] Training Avg Loss: 0.4961 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0098 / 1000 | Batch: 0001 / 0004 | Loss: 0.4948\n",
            "[Train] | Epoch: 0098 / 1000 | Batch: 0002 / 0004 | Loss: 0.5000\n",
            "[Train] | Epoch: 0098 / 1000 | Batch: 0003 / 0004 | Loss: 0.4883\n",
            "[Train] | Epoch: 0098 / 1000 | Batch: 0004 / 0004 | Loss: 0.5015\n",
            "[Validation] | Epoch: 0098 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0098 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0098] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0099 / 1000 | Batch: 0001 / 0004 | Loss: 0.5009\n",
            "[Train] | Epoch: 0099 / 1000 | Batch: 0002 / 0004 | Loss: 0.4962\n",
            "[Train] | Epoch: 0099 / 1000 | Batch: 0003 / 0004 | Loss: 0.4905\n",
            "[Train] | Epoch: 0099 / 1000 | Batch: 0004 / 0004 | Loss: 0.4956\n",
            "[Validation] | Epoch: 0099 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0099 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0099] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0100 / 1000 | Batch: 0001 / 0004 | Loss: 0.5003\n",
            "[Train] | Epoch: 0100 / 1000 | Batch: 0002 / 0004 | Loss: 0.4885\n",
            "[Train] | Epoch: 0100 / 1000 | Batch: 0003 / 0004 | Loss: 0.5032\n",
            "[Train] | Epoch: 0100 / 1000 | Batch: 0004 / 0004 | Loss: 0.4873\n",
            "[Validation] | Epoch: 0100 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0100 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0100] Training Avg Loss: 0.4948 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0101 / 1000 | Batch: 0001 / 0004 | Loss: 0.4959\n",
            "[Train] | Epoch: 0101 / 1000 | Batch: 0002 / 0004 | Loss: 0.4952\n",
            "[Train] | Epoch: 0101 / 1000 | Batch: 0003 / 0004 | Loss: 0.4929\n",
            "[Train] | Epoch: 0101 / 1000 | Batch: 0004 / 0004 | Loss: 0.5006\n",
            "[Validation] | Epoch: 0101 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0101 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0101] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0102 / 1000 | Batch: 0001 / 0004 | Loss: 0.4870\n",
            "[Train] | Epoch: 0102 / 1000 | Batch: 0002 / 0004 | Loss: 0.4988\n",
            "[Train] | Epoch: 0102 / 1000 | Batch: 0003 / 0004 | Loss: 0.5009\n",
            "[Train] | Epoch: 0102 / 1000 | Batch: 0004 / 0004 | Loss: 0.4953\n",
            "[Validation] | Epoch: 0102 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0102 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0102] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0103 / 1000 | Batch: 0001 / 0004 | Loss: 0.5033\n",
            "[Train] | Epoch: 0103 / 1000 | Batch: 0002 / 0004 | Loss: 0.4960\n",
            "[Train] | Epoch: 0103 / 1000 | Batch: 0003 / 0004 | Loss: 0.4882\n",
            "[Train] | Epoch: 0103 / 1000 | Batch: 0004 / 0004 | Loss: 0.4930\n",
            "[Validation] | Epoch: 0103 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0103 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0103] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0104 / 1000 | Batch: 0001 / 0004 | Loss: 0.4910\n",
            "[Train] | Epoch: 0104 / 1000 | Batch: 0002 / 0004 | Loss: 0.4987\n",
            "[Train] | Epoch: 0104 / 1000 | Batch: 0003 / 0004 | Loss: 0.4935\n",
            "[Train] | Epoch: 0104 / 1000 | Batch: 0004 / 0004 | Loss: 0.5041\n",
            "[Validation] | Epoch: 0104 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0104 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0104] Training Avg Loss: 0.4968 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0105 / 1000 | Batch: 0001 / 0004 | Loss: 0.4979\n",
            "[Train] | Epoch: 0105 / 1000 | Batch: 0002 / 0004 | Loss: 0.5002\n",
            "[Train] | Epoch: 0105 / 1000 | Batch: 0003 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0105 / 1000 | Batch: 0004 / 0004 | Loss: 0.4882\n",
            "[Validation] | Epoch: 0105 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0105 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0105] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0106 / 1000 | Batch: 0001 / 0004 | Loss: 0.4959\n",
            "[Train] | Epoch: 0106 / 1000 | Batch: 0002 / 0004 | Loss: 0.4884\n",
            "[Train] | Epoch: 0106 / 1000 | Batch: 0003 / 0004 | Loss: 0.4980\n",
            "[Train] | Epoch: 0106 / 1000 | Batch: 0004 / 0004 | Loss: 0.5025\n",
            "[Validation] | Epoch: 0106 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0106 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0106] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0107 / 1000 | Batch: 0001 / 0004 | Loss: 0.4942\n",
            "[Train] | Epoch: 0107 / 1000 | Batch: 0002 / 0004 | Loss: 0.5074\n",
            "[Train] | Epoch: 0107 / 1000 | Batch: 0003 / 0004 | Loss: 0.4879\n",
            "[Train] | Epoch: 0107 / 1000 | Batch: 0004 / 0004 | Loss: 0.4914\n",
            "[Validation] | Epoch: 0107 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0107 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0107] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0108 / 1000 | Batch: 0001 / 0004 | Loss: 0.4968\n",
            "[Train] | Epoch: 0108 / 1000 | Batch: 0002 / 0004 | Loss: 0.4877\n",
            "[Train] | Epoch: 0108 / 1000 | Batch: 0003 / 0004 | Loss: 0.5037\n",
            "[Train] | Epoch: 0108 / 1000 | Batch: 0004 / 0004 | Loss: 0.4940\n",
            "[Validation] | Epoch: 0108 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0108 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0108] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0109 / 1000 | Batch: 0001 / 0004 | Loss: 0.4950\n",
            "[Train] | Epoch: 0109 / 1000 | Batch: 0002 / 0004 | Loss: 0.4934\n",
            "[Train] | Epoch: 0109 / 1000 | Batch: 0003 / 0004 | Loss: 0.4917\n",
            "[Train] | Epoch: 0109 / 1000 | Batch: 0004 / 0004 | Loss: 0.5048\n",
            "[Validation] | Epoch: 0109 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0109 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0109] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0110 / 1000 | Batch: 0001 / 0004 | Loss: 0.4946\n",
            "[Train] | Epoch: 0110 / 1000 | Batch: 0002 / 0004 | Loss: 0.4852\n",
            "[Train] | Epoch: 0110 / 1000 | Batch: 0003 / 0004 | Loss: 0.4939\n",
            "[Train] | Epoch: 0110 / 1000 | Batch: 0004 / 0004 | Loss: 0.5137\n",
            "[Validation] | Epoch: 0110 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0110 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0110] Training Avg Loss: 0.4968 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0111 / 1000 | Batch: 0001 / 0004 | Loss: 0.4924\n",
            "[Train] | Epoch: 0111 / 1000 | Batch: 0002 / 0004 | Loss: 0.4915\n",
            "[Train] | Epoch: 0111 / 1000 | Batch: 0003 / 0004 | Loss: 0.4990\n",
            "[Train] | Epoch: 0111 / 1000 | Batch: 0004 / 0004 | Loss: 0.4998\n",
            "[Validation] | Epoch: 0111 / 1000 | Batch: 0001 / 0002 | Loss: 0.5071\n",
            "[Validation] | Epoch: 0111 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0111] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0112 / 1000 | Batch: 0001 / 0004 | Loss: 0.4888\n",
            "[Train] | Epoch: 0112 / 1000 | Batch: 0002 / 0004 | Loss: 0.5043\n",
            "[Train] | Epoch: 0112 / 1000 | Batch: 0003 / 0004 | Loss: 0.4952\n",
            "[Train] | Epoch: 0112 / 1000 | Batch: 0004 / 0004 | Loss: 0.4944\n",
            "[Validation] | Epoch: 0112 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0112 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0112] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0113 / 1000 | Batch: 0001 / 0004 | Loss: 0.4889\n",
            "[Train] | Epoch: 0113 / 1000 | Batch: 0002 / 0004 | Loss: 0.4906\n",
            "[Train] | Epoch: 0113 / 1000 | Batch: 0003 / 0004 | Loss: 0.5014\n",
            "[Train] | Epoch: 0113 / 1000 | Batch: 0004 / 0004 | Loss: 0.5028\n",
            "[Validation] | Epoch: 0113 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0113 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0113] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0114 / 1000 | Batch: 0001 / 0004 | Loss: 0.4976\n",
            "[Train] | Epoch: 0114 / 1000 | Batch: 0002 / 0004 | Loss: 0.4937\n",
            "[Train] | Epoch: 0114 / 1000 | Batch: 0003 / 0004 | Loss: 0.4905\n",
            "[Train] | Epoch: 0114 / 1000 | Batch: 0004 / 0004 | Loss: 0.5019\n",
            "[Validation] | Epoch: 0114 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0114 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0114] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0115 / 1000 | Batch: 0001 / 0004 | Loss: 0.4945\n",
            "[Train] | Epoch: 0115 / 1000 | Batch: 0002 / 0004 | Loss: 0.4989\n",
            "[Train] | Epoch: 0115 / 1000 | Batch: 0003 / 0004 | Loss: 0.4954\n",
            "[Train] | Epoch: 0115 / 1000 | Batch: 0004 / 0004 | Loss: 0.4943\n",
            "[Validation] | Epoch: 0115 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0115 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0115] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0116 / 1000 | Batch: 0001 / 0004 | Loss: 0.4927\n",
            "[Train] | Epoch: 0116 / 1000 | Batch: 0002 / 0004 | Loss: 0.4929\n",
            "[Train] | Epoch: 0116 / 1000 | Batch: 0003 / 0004 | Loss: 0.4978\n",
            "[Train] | Epoch: 0116 / 1000 | Batch: 0004 / 0004 | Loss: 0.5001\n",
            "[Validation] | Epoch: 0116 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0116 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0116] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0117 / 1000 | Batch: 0001 / 0004 | Loss: 0.5000\n",
            "[Train] | Epoch: 0117 / 1000 | Batch: 0002 / 0004 | Loss: 0.4907\n",
            "[Train] | Epoch: 0117 / 1000 | Batch: 0003 / 0004 | Loss: 0.4974\n",
            "[Train] | Epoch: 0117 / 1000 | Batch: 0004 / 0004 | Loss: 0.4939\n",
            "[Validation] | Epoch: 0117 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0117 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0117] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0118 / 1000 | Batch: 0001 / 0004 | Loss: 0.4984\n",
            "[Train] | Epoch: 0118 / 1000 | Batch: 0002 / 0004 | Loss: 0.4995\n",
            "[Train] | Epoch: 0118 / 1000 | Batch: 0003 / 0004 | Loss: 0.4934\n",
            "[Train] | Epoch: 0118 / 1000 | Batch: 0004 / 0004 | Loss: 0.4906\n",
            "[Validation] | Epoch: 0118 / 1000 | Batch: 0001 / 0002 | Loss: 0.5077\n",
            "[Validation] | Epoch: 0118 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0118] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4969\n",
            "[Train] | Epoch: 0119 / 1000 | Batch: 0001 / 0004 | Loss: 0.4942\n",
            "[Train] | Epoch: 0119 / 1000 | Batch: 0002 / 0004 | Loss: 0.4988\n",
            "[Train] | Epoch: 0119 / 1000 | Batch: 0003 / 0004 | Loss: 0.4987\n",
            "[Train] | Epoch: 0119 / 1000 | Batch: 0004 / 0004 | Loss: 0.4894\n",
            "[Validation] | Epoch: 0119 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0119 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0119] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4969\n",
            "[Train] | Epoch: 0120 / 1000 | Batch: 0001 / 0004 | Loss: 0.4987\n",
            "[Train] | Epoch: 0120 / 1000 | Batch: 0002 / 0004 | Loss: 0.4930\n",
            "[Train] | Epoch: 0120 / 1000 | Batch: 0003 / 0004 | Loss: 0.4888\n",
            "[Train] | Epoch: 0120 / 1000 | Batch: 0004 / 0004 | Loss: 0.5041\n",
            "[Validation] | Epoch: 0120 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0120 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0120] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0121 / 1000 | Batch: 0001 / 0004 | Loss: 0.4980\n",
            "[Train] | Epoch: 0121 / 1000 | Batch: 0002 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0121 / 1000 | Batch: 0003 / 0004 | Loss: 0.5009\n",
            "[Train] | Epoch: 0121 / 1000 | Batch: 0004 / 0004 | Loss: 0.4870\n",
            "[Validation] | Epoch: 0121 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0121 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0121] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0122 / 1000 | Batch: 0001 / 0004 | Loss: 0.4969\n",
            "[Train] | Epoch: 0122 / 1000 | Batch: 0002 / 0004 | Loss: 0.5117\n",
            "[Train] | Epoch: 0122 / 1000 | Batch: 0003 / 0004 | Loss: 0.4891\n",
            "[Train] | Epoch: 0122 / 1000 | Batch: 0004 / 0004 | Loss: 0.4825\n",
            "[Validation] | Epoch: 0122 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0122 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0122] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0123 / 1000 | Batch: 0001 / 0004 | Loss: 0.4843\n",
            "[Train] | Epoch: 0123 / 1000 | Batch: 0002 / 0004 | Loss: 0.4945\n",
            "[Train] | Epoch: 0123 / 1000 | Batch: 0003 / 0004 | Loss: 0.5086\n",
            "[Train] | Epoch: 0123 / 1000 | Batch: 0004 / 0004 | Loss: 0.4942\n",
            "[Validation] | Epoch: 0123 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0123 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0123] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0124 / 1000 | Batch: 0001 / 0004 | Loss: 0.4934\n",
            "[Train] | Epoch: 0124 / 1000 | Batch: 0002 / 0004 | Loss: 0.5006\n",
            "[Train] | Epoch: 0124 / 1000 | Batch: 0003 / 0004 | Loss: 0.4955\n",
            "[Train] | Epoch: 0124 / 1000 | Batch: 0004 / 0004 | Loss: 0.4917\n",
            "[Validation] | Epoch: 0124 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0124 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0124] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0125 / 1000 | Batch: 0001 / 0004 | Loss: 0.5020\n",
            "[Train] | Epoch: 0125 / 1000 | Batch: 0002 / 0004 | Loss: 0.4856\n",
            "[Train] | Epoch: 0125 / 1000 | Batch: 0003 / 0004 | Loss: 0.4955\n",
            "[Train] | Epoch: 0125 / 1000 | Batch: 0004 / 0004 | Loss: 0.4987\n",
            "[Validation] | Epoch: 0125 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0125 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0125] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0126 / 1000 | Batch: 0001 / 0004 | Loss: 0.4975\n",
            "[Train] | Epoch: 0126 / 1000 | Batch: 0002 / 0004 | Loss: 0.4941\n",
            "[Train] | Epoch: 0126 / 1000 | Batch: 0003 / 0004 | Loss: 0.4959\n",
            "[Train] | Epoch: 0126 / 1000 | Batch: 0004 / 0004 | Loss: 0.4968\n",
            "[Validation] | Epoch: 0126 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0126 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0126] Training Avg Loss: 0.4961 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0127 / 1000 | Batch: 0001 / 0004 | Loss: 0.5002\n",
            "[Train] | Epoch: 0127 / 1000 | Batch: 0002 / 0004 | Loss: 0.5010\n",
            "[Train] | Epoch: 0127 / 1000 | Batch: 0003 / 0004 | Loss: 0.4846\n",
            "[Train] | Epoch: 0127 / 1000 | Batch: 0004 / 0004 | Loss: 0.4960\n",
            "[Validation] | Epoch: 0127 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0127 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0127] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0128 / 1000 | Batch: 0001 / 0004 | Loss: 0.4859\n",
            "[Train] | Epoch: 0128 / 1000 | Batch: 0002 / 0004 | Loss: 0.4991\n",
            "[Train] | Epoch: 0128 / 1000 | Batch: 0003 / 0004 | Loss: 0.4986\n",
            "[Train] | Epoch: 0128 / 1000 | Batch: 0004 / 0004 | Loss: 0.5008\n",
            "[Validation] | Epoch: 0128 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0128 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0128] Training Avg Loss: 0.4961 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0129 / 1000 | Batch: 0001 / 0004 | Loss: 0.4978\n",
            "[Train] | Epoch: 0129 / 1000 | Batch: 0002 / 0004 | Loss: 0.5017\n",
            "[Train] | Epoch: 0129 / 1000 | Batch: 0003 / 0004 | Loss: 0.4867\n",
            "[Train] | Epoch: 0129 / 1000 | Batch: 0004 / 0004 | Loss: 0.4959\n",
            "[Validation] | Epoch: 0129 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0129 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0129] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0130 / 1000 | Batch: 0001 / 0004 | Loss: 0.4972\n",
            "[Train] | Epoch: 0130 / 1000 | Batch: 0002 / 0004 | Loss: 0.4939\n",
            "[Train] | Epoch: 0130 / 1000 | Batch: 0003 / 0004 | Loss: 0.4924\n",
            "[Train] | Epoch: 0130 / 1000 | Batch: 0004 / 0004 | Loss: 0.4996\n",
            "[Validation] | Epoch: 0130 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0130 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0130] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0131 / 1000 | Batch: 0001 / 0004 | Loss: 0.4997\n",
            "[Train] | Epoch: 0131 / 1000 | Batch: 0002 / 0004 | Loss: 0.5014\n",
            "[Train] | Epoch: 0131 / 1000 | Batch: 0003 / 0004 | Loss: 0.4907\n",
            "[Train] | Epoch: 0131 / 1000 | Batch: 0004 / 0004 | Loss: 0.4911\n",
            "[Validation] | Epoch: 0131 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0131 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0131] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0132 / 1000 | Batch: 0001 / 0004 | Loss: 0.5004\n",
            "[Train] | Epoch: 0132 / 1000 | Batch: 0002 / 0004 | Loss: 0.4950\n",
            "[Train] | Epoch: 0132 / 1000 | Batch: 0003 / 0004 | Loss: 0.4936\n",
            "[Train] | Epoch: 0132 / 1000 | Batch: 0004 / 0004 | Loss: 0.4928\n",
            "[Validation] | Epoch: 0132 / 1000 | Batch: 0001 / 0002 | Loss: 0.5078\n",
            "[Validation] | Epoch: 0132 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0132] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4970\n",
            "[Train] | Epoch: 0133 / 1000 | Batch: 0001 / 0004 | Loss: 0.5009\n",
            "[Train] | Epoch: 0133 / 1000 | Batch: 0002 / 0004 | Loss: 0.4933\n",
            "[Train] | Epoch: 0133 / 1000 | Batch: 0003 / 0004 | Loss: 0.4860\n",
            "[Train] | Epoch: 0133 / 1000 | Batch: 0004 / 0004 | Loss: 0.5049\n",
            "[Validation] | Epoch: 0133 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0133 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0133] Training Avg Loss: 0.4963 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0134 / 1000 | Batch: 0001 / 0004 | Loss: 0.4911\n",
            "[Train] | Epoch: 0134 / 1000 | Batch: 0002 / 0004 | Loss: 0.4931\n",
            "[Train] | Epoch: 0134 / 1000 | Batch: 0003 / 0004 | Loss: 0.5038\n",
            "[Train] | Epoch: 0134 / 1000 | Batch: 0004 / 0004 | Loss: 0.4903\n",
            "[Validation] | Epoch: 0134 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0134 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0134] Training Avg Loss: 0.4946 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0135 / 1000 | Batch: 0001 / 0004 | Loss: 0.4978\n",
            "[Train] | Epoch: 0135 / 1000 | Batch: 0002 / 0004 | Loss: 0.4888\n",
            "[Train] | Epoch: 0135 / 1000 | Batch: 0003 / 0004 | Loss: 0.4982\n",
            "[Train] | Epoch: 0135 / 1000 | Batch: 0004 / 0004 | Loss: 0.4993\n",
            "[Validation] | Epoch: 0135 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0135 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0135] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0136 / 1000 | Batch: 0001 / 0004 | Loss: 0.4904\n",
            "[Train] | Epoch: 0136 / 1000 | Batch: 0002 / 0004 | Loss: 0.4974\n",
            "[Train] | Epoch: 0136 / 1000 | Batch: 0003 / 0004 | Loss: 0.4932\n",
            "[Train] | Epoch: 0136 / 1000 | Batch: 0004 / 0004 | Loss: 0.5028\n",
            "[Validation] | Epoch: 0136 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0136 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0136] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0137 / 1000 | Batch: 0001 / 0004 | Loss: 0.4914\n",
            "[Train] | Epoch: 0137 / 1000 | Batch: 0002 / 0004 | Loss: 0.4923\n",
            "[Train] | Epoch: 0137 / 1000 | Batch: 0003 / 0004 | Loss: 0.4941\n",
            "[Train] | Epoch: 0137 / 1000 | Batch: 0004 / 0004 | Loss: 0.5081\n",
            "[Validation] | Epoch: 0137 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0137 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0137] Training Avg Loss: 0.4965 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0138 / 1000 | Batch: 0001 / 0004 | Loss: 0.4887\n",
            "[Train] | Epoch: 0138 / 1000 | Batch: 0002 / 0004 | Loss: 0.4995\n",
            "[Train] | Epoch: 0138 / 1000 | Batch: 0003 / 0004 | Loss: 0.5044\n",
            "[Train] | Epoch: 0138 / 1000 | Batch: 0004 / 0004 | Loss: 0.4870\n",
            "[Validation] | Epoch: 0138 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0138 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0138] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0139 / 1000 | Batch: 0001 / 0004 | Loss: 0.4844\n",
            "[Train] | Epoch: 0139 / 1000 | Batch: 0002 / 0004 | Loss: 0.4994\n",
            "[Train] | Epoch: 0139 / 1000 | Batch: 0003 / 0004 | Loss: 0.5075\n",
            "[Train] | Epoch: 0139 / 1000 | Batch: 0004 / 0004 | Loss: 0.4904\n",
            "[Validation] | Epoch: 0139 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0139 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0139] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0140 / 1000 | Batch: 0001 / 0004 | Loss: 0.4946\n",
            "[Train] | Epoch: 0140 / 1000 | Batch: 0002 / 0004 | Loss: 0.4930\n",
            "[Train] | Epoch: 0140 / 1000 | Batch: 0003 / 0004 | Loss: 0.5028\n",
            "[Train] | Epoch: 0140 / 1000 | Batch: 0004 / 0004 | Loss: 0.4908\n",
            "[Validation] | Epoch: 0140 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0140 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0140] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0141 / 1000 | Batch: 0001 / 0004 | Loss: 0.4922\n",
            "[Train] | Epoch: 0141 / 1000 | Batch: 0002 / 0004 | Loss: 0.4930\n",
            "[Train] | Epoch: 0141 / 1000 | Batch: 0003 / 0004 | Loss: 0.4943\n",
            "[Train] | Epoch: 0141 / 1000 | Batch: 0004 / 0004 | Loss: 0.5034\n",
            "[Validation] | Epoch: 0141 / 1000 | Batch: 0001 / 0002 | Loss: 0.5071\n",
            "[Validation] | Epoch: 0141 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0141] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0142 / 1000 | Batch: 0001 / 0004 | Loss: 0.4932\n",
            "[Train] | Epoch: 0142 / 1000 | Batch: 0002 / 0004 | Loss: 0.4908\n",
            "[Train] | Epoch: 0142 / 1000 | Batch: 0003 / 0004 | Loss: 0.5012\n",
            "[Train] | Epoch: 0142 / 1000 | Batch: 0004 / 0004 | Loss: 0.4976\n",
            "[Validation] | Epoch: 0142 / 1000 | Batch: 0001 / 0002 | Loss: 0.5071\n",
            "[Validation] | Epoch: 0142 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0142] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0143 / 1000 | Batch: 0001 / 0004 | Loss: 0.5003\n",
            "[Train] | Epoch: 0143 / 1000 | Batch: 0002 / 0004 | Loss: 0.4846\n",
            "[Train] | Epoch: 0143 / 1000 | Batch: 0003 / 0004 | Loss: 0.4989\n",
            "[Train] | Epoch: 0143 / 1000 | Batch: 0004 / 0004 | Loss: 0.5031\n",
            "[Validation] | Epoch: 0143 / 1000 | Batch: 0001 / 0002 | Loss: 0.5070\n",
            "[Validation] | Epoch: 0143 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0143] Training Avg Loss: 0.4967 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0144 / 1000 | Batch: 0001 / 0004 | Loss: 0.4899\n",
            "[Train] | Epoch: 0144 / 1000 | Batch: 0002 / 0004 | Loss: 0.4968\n",
            "[Train] | Epoch: 0144 / 1000 | Batch: 0003 / 0004 | Loss: 0.4995\n",
            "[Train] | Epoch: 0144 / 1000 | Batch: 0004 / 0004 | Loss: 0.4946\n",
            "[Validation] | Epoch: 0144 / 1000 | Batch: 0001 / 0002 | Loss: 0.5071\n",
            "[Validation] | Epoch: 0144 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0144] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0145 / 1000 | Batch: 0001 / 0004 | Loss: 0.4868\n",
            "[Train] | Epoch: 0145 / 1000 | Batch: 0002 / 0004 | Loss: 0.5096\n",
            "[Train] | Epoch: 0145 / 1000 | Batch: 0003 / 0004 | Loss: 0.4921\n",
            "[Train] | Epoch: 0145 / 1000 | Batch: 0004 / 0004 | Loss: 0.4963\n",
            "[Validation] | Epoch: 0145 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0145 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0145] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0146 / 1000 | Batch: 0001 / 0004 | Loss: 0.4938\n",
            "[Train] | Epoch: 0146 / 1000 | Batch: 0002 / 0004 | Loss: 0.4902\n",
            "[Train] | Epoch: 0146 / 1000 | Batch: 0003 / 0004 | Loss: 0.4923\n",
            "[Train] | Epoch: 0146 / 1000 | Batch: 0004 / 0004 | Loss: 0.5104\n",
            "[Validation] | Epoch: 0146 / 1000 | Batch: 0001 / 0002 | Loss: 0.5071\n",
            "[Validation] | Epoch: 0146 / 1000 | Batch: 0002 / 0002 | Loss: 0.4852\n",
            "[Epoch 0146] Training Avg Loss: 0.4967 | Validation Avg Loss: 0.4961\n",
            "[Train] | Epoch: 0147 / 1000 | Batch: 0001 / 0004 | Loss: 0.4900\n",
            "[Train] | Epoch: 0147 / 1000 | Batch: 0002 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0147 / 1000 | Batch: 0003 / 0004 | Loss: 0.5051\n",
            "[Train] | Epoch: 0147 / 1000 | Batch: 0004 / 0004 | Loss: 0.4914\n",
            "[Validation] | Epoch: 0147 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0147 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0147] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0148 / 1000 | Batch: 0001 / 0004 | Loss: 0.5010\n",
            "[Train] | Epoch: 0148 / 1000 | Batch: 0002 / 0004 | Loss: 0.4959\n",
            "[Train] | Epoch: 0148 / 1000 | Batch: 0003 / 0004 | Loss: 0.4950\n",
            "[Train] | Epoch: 0148 / 1000 | Batch: 0004 / 0004 | Loss: 0.4911\n",
            "[Validation] | Epoch: 0148 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0148 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0148] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0149 / 1000 | Batch: 0001 / 0004 | Loss: 0.4996\n",
            "[Train] | Epoch: 0149 / 1000 | Batch: 0002 / 0004 | Loss: 0.4899\n",
            "[Train] | Epoch: 0149 / 1000 | Batch: 0003 / 0004 | Loss: 0.4962\n",
            "[Train] | Epoch: 0149 / 1000 | Batch: 0004 / 0004 | Loss: 0.4977\n",
            "[Validation] | Epoch: 0149 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0149 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0149] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0150 / 1000 | Batch: 0001 / 0004 | Loss: 0.4876\n",
            "[Train] | Epoch: 0150 / 1000 | Batch: 0002 / 0004 | Loss: 0.4989\n",
            "[Train] | Epoch: 0150 / 1000 | Batch: 0003 / 0004 | Loss: 0.5026\n",
            "[Train] | Epoch: 0150 / 1000 | Batch: 0004 / 0004 | Loss: 0.4926\n",
            "[Validation] | Epoch: 0150 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0150 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0150] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0151 / 1000 | Batch: 0001 / 0004 | Loss: 0.4959\n",
            "[Train] | Epoch: 0151 / 1000 | Batch: 0002 / 0004 | Loss: 0.4876\n",
            "[Train] | Epoch: 0151 / 1000 | Batch: 0003 / 0004 | Loss: 0.5034\n",
            "[Train] | Epoch: 0151 / 1000 | Batch: 0004 / 0004 | Loss: 0.4955\n",
            "[Validation] | Epoch: 0151 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0151 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0151] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0152 / 1000 | Batch: 0001 / 0004 | Loss: 0.4934\n",
            "[Train] | Epoch: 0152 / 1000 | Batch: 0002 / 0004 | Loss: 0.4966\n",
            "[Train] | Epoch: 0152 / 1000 | Batch: 0003 / 0004 | Loss: 0.4943\n",
            "[Train] | Epoch: 0152 / 1000 | Batch: 0004 / 0004 | Loss: 0.4979\n",
            "[Validation] | Epoch: 0152 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0152 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0152] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0153 / 1000 | Batch: 0001 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0153 / 1000 | Batch: 0002 / 0004 | Loss: 0.5002\n",
            "[Train] | Epoch: 0153 / 1000 | Batch: 0003 / 0004 | Loss: 0.4897\n",
            "[Train] | Epoch: 0153 / 1000 | Batch: 0004 / 0004 | Loss: 0.4964\n",
            "[Validation] | Epoch: 0153 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0153 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0153] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0154 / 1000 | Batch: 0001 / 0004 | Loss: 0.5009\n",
            "[Train] | Epoch: 0154 / 1000 | Batch: 0002 / 0004 | Loss: 0.4942\n",
            "[Train] | Epoch: 0154 / 1000 | Batch: 0003 / 0004 | Loss: 0.4901\n",
            "[Train] | Epoch: 0154 / 1000 | Batch: 0004 / 0004 | Loss: 0.4989\n",
            "[Validation] | Epoch: 0154 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0154 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0154] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0155 / 1000 | Batch: 0001 / 0004 | Loss: 0.5000\n",
            "[Train] | Epoch: 0155 / 1000 | Batch: 0002 / 0004 | Loss: 0.4922\n",
            "[Train] | Epoch: 0155 / 1000 | Batch: 0003 / 0004 | Loss: 0.4989\n",
            "[Train] | Epoch: 0155 / 1000 | Batch: 0004 / 0004 | Loss: 0.4924\n",
            "[Validation] | Epoch: 0155 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0155 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0155] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4969\n",
            "[Train] | Epoch: 0156 / 1000 | Batch: 0001 / 0004 | Loss: 0.4940\n",
            "[Train] | Epoch: 0156 / 1000 | Batch: 0002 / 0004 | Loss: 0.5041\n",
            "[Train] | Epoch: 0156 / 1000 | Batch: 0003 / 0004 | Loss: 0.4830\n",
            "[Train] | Epoch: 0156 / 1000 | Batch: 0004 / 0004 | Loss: 0.5014\n",
            "[Validation] | Epoch: 0156 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0156 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0156] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0157 / 1000 | Batch: 0001 / 0004 | Loss: 0.4958\n",
            "[Train] | Epoch: 0157 / 1000 | Batch: 0002 / 0004 | Loss: 0.5059\n",
            "[Train] | Epoch: 0157 / 1000 | Batch: 0003 / 0004 | Loss: 0.4853\n",
            "[Train] | Epoch: 0157 / 1000 | Batch: 0004 / 0004 | Loss: 0.4943\n",
            "[Validation] | Epoch: 0157 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0157 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0157] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0158 / 1000 | Batch: 0001 / 0004 | Loss: 0.4995\n",
            "[Train] | Epoch: 0158 / 1000 | Batch: 0002 / 0004 | Loss: 0.4967\n",
            "[Train] | Epoch: 0158 / 1000 | Batch: 0003 / 0004 | Loss: 0.4907\n",
            "[Train] | Epoch: 0158 / 1000 | Batch: 0004 / 0004 | Loss: 0.4957\n",
            "[Validation] | Epoch: 0158 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0158 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0158] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0159 / 1000 | Batch: 0001 / 0004 | Loss: 0.4969\n",
            "[Train] | Epoch: 0159 / 1000 | Batch: 0002 / 0004 | Loss: 0.5040\n",
            "[Train] | Epoch: 0159 / 1000 | Batch: 0003 / 0004 | Loss: 0.4918\n",
            "[Train] | Epoch: 0159 / 1000 | Batch: 0004 / 0004 | Loss: 0.4889\n",
            "[Validation] | Epoch: 0159 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0159 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0159] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0160 / 1000 | Batch: 0001 / 0004 | Loss: 0.4871\n",
            "[Train] | Epoch: 0160 / 1000 | Batch: 0002 / 0004 | Loss: 0.4882\n",
            "[Train] | Epoch: 0160 / 1000 | Batch: 0003 / 0004 | Loss: 0.5040\n",
            "[Train] | Epoch: 0160 / 1000 | Batch: 0004 / 0004 | Loss: 0.5066\n",
            "[Validation] | Epoch: 0160 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0160 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0160] Training Avg Loss: 0.4965 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0161 / 1000 | Batch: 0001 / 0004 | Loss: 0.5003\n",
            "[Train] | Epoch: 0161 / 1000 | Batch: 0002 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0161 / 1000 | Batch: 0003 / 0004 | Loss: 0.4919\n",
            "[Train] | Epoch: 0161 / 1000 | Batch: 0004 / 0004 | Loss: 0.4932\n",
            "[Validation] | Epoch: 0161 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0161 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0161] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0162 / 1000 | Batch: 0001 / 0004 | Loss: 0.4919\n",
            "[Train] | Epoch: 0162 / 1000 | Batch: 0002 / 0004 | Loss: 0.4976\n",
            "[Train] | Epoch: 0162 / 1000 | Batch: 0003 / 0004 | Loss: 0.4990\n",
            "[Train] | Epoch: 0162 / 1000 | Batch: 0004 / 0004 | Loss: 0.4937\n",
            "[Validation] | Epoch: 0162 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0162 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0162] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0163 / 1000 | Batch: 0001 / 0004 | Loss: 0.5042\n",
            "[Train] | Epoch: 0163 / 1000 | Batch: 0002 / 0004 | Loss: 0.4945\n",
            "[Train] | Epoch: 0163 / 1000 | Batch: 0003 / 0004 | Loss: 0.4900\n",
            "[Train] | Epoch: 0163 / 1000 | Batch: 0004 / 0004 | Loss: 0.4914\n",
            "[Validation] | Epoch: 0163 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0163 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0163] Training Avg Loss: 0.4950 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0164 / 1000 | Batch: 0001 / 0004 | Loss: 0.4968\n",
            "[Train] | Epoch: 0164 / 1000 | Batch: 0002 / 0004 | Loss: 0.4969\n",
            "[Train] | Epoch: 0164 / 1000 | Batch: 0003 / 0004 | Loss: 0.4958\n",
            "[Train] | Epoch: 0164 / 1000 | Batch: 0004 / 0004 | Loss: 0.4922\n",
            "[Validation] | Epoch: 0164 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0164 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0164] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0165 / 1000 | Batch: 0001 / 0004 | Loss: 0.4942\n",
            "[Train] | Epoch: 0165 / 1000 | Batch: 0002 / 0004 | Loss: 0.4933\n",
            "[Train] | Epoch: 0165 / 1000 | Batch: 0003 / 0004 | Loss: 0.4981\n",
            "[Train] | Epoch: 0165 / 1000 | Batch: 0004 / 0004 | Loss: 0.4985\n",
            "[Validation] | Epoch: 0165 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0165 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0165] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0166 / 1000 | Batch: 0001 / 0004 | Loss: 0.5018\n",
            "[Train] | Epoch: 0166 / 1000 | Batch: 0002 / 0004 | Loss: 0.4936\n",
            "[Train] | Epoch: 0166 / 1000 | Batch: 0003 / 0004 | Loss: 0.4956\n",
            "[Train] | Epoch: 0166 / 1000 | Batch: 0004 / 0004 | Loss: 0.4915\n",
            "[Validation] | Epoch: 0166 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0166 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0166] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0167 / 1000 | Batch: 0001 / 0004 | Loss: 0.4997\n",
            "[Train] | Epoch: 0167 / 1000 | Batch: 0002 / 0004 | Loss: 0.4889\n",
            "[Train] | Epoch: 0167 / 1000 | Batch: 0003 / 0004 | Loss: 0.4967\n",
            "[Train] | Epoch: 0167 / 1000 | Batch: 0004 / 0004 | Loss: 0.4975\n",
            "[Validation] | Epoch: 0167 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0167 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0167] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0168 / 1000 | Batch: 0001 / 0004 | Loss: 0.4945\n",
            "[Train] | Epoch: 0168 / 1000 | Batch: 0002 / 0004 | Loss: 0.4960\n",
            "[Train] | Epoch: 0168 / 1000 | Batch: 0003 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0168 / 1000 | Batch: 0004 / 0004 | Loss: 0.4991\n",
            "[Validation] | Epoch: 0168 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0168 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0168] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0169 / 1000 | Batch: 0001 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0169 / 1000 | Batch: 0002 / 0004 | Loss: 0.4979\n",
            "[Train] | Epoch: 0169 / 1000 | Batch: 0003 / 0004 | Loss: 0.4975\n",
            "[Train] | Epoch: 0169 / 1000 | Batch: 0004 / 0004 | Loss: 0.4903\n",
            "[Validation] | Epoch: 0169 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0169 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0169] Training Avg Loss: 0.4950 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0170 / 1000 | Batch: 0001 / 0004 | Loss: 0.4920\n",
            "[Train] | Epoch: 0170 / 1000 | Batch: 0002 / 0004 | Loss: 0.5010\n",
            "[Train] | Epoch: 0170 / 1000 | Batch: 0003 / 0004 | Loss: 0.4928\n",
            "[Train] | Epoch: 0170 / 1000 | Batch: 0004 / 0004 | Loss: 0.4983\n",
            "[Validation] | Epoch: 0170 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0170 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0170] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0171 / 1000 | Batch: 0001 / 0004 | Loss: 0.4981\n",
            "[Train] | Epoch: 0171 / 1000 | Batch: 0002 / 0004 | Loss: 0.4918\n",
            "[Train] | Epoch: 0171 / 1000 | Batch: 0003 / 0004 | Loss: 0.4967\n",
            "[Train] | Epoch: 0171 / 1000 | Batch: 0004 / 0004 | Loss: 0.4988\n",
            "[Validation] | Epoch: 0171 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0171 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0171] Training Avg Loss: 0.4964 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0172 / 1000 | Batch: 0001 / 0004 | Loss: 0.5022\n",
            "[Train] | Epoch: 0172 / 1000 | Batch: 0002 / 0004 | Loss: 0.4881\n",
            "[Train] | Epoch: 0172 / 1000 | Batch: 0003 / 0004 | Loss: 0.4929\n",
            "[Train] | Epoch: 0172 / 1000 | Batch: 0004 / 0004 | Loss: 0.5037\n",
            "[Validation] | Epoch: 0172 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0172 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0172] Training Avg Loss: 0.4967 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0173 / 1000 | Batch: 0001 / 0004 | Loss: 0.4986\n",
            "[Train] | Epoch: 0173 / 1000 | Batch: 0002 / 0004 | Loss: 0.4979\n",
            "[Train] | Epoch: 0173 / 1000 | Batch: 0003 / 0004 | Loss: 0.4904\n",
            "[Train] | Epoch: 0173 / 1000 | Batch: 0004 / 0004 | Loss: 0.4948\n",
            "[Validation] | Epoch: 0173 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0173 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0173] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0174 / 1000 | Batch: 0001 / 0004 | Loss: 0.4858\n",
            "[Train] | Epoch: 0174 / 1000 | Batch: 0002 / 0004 | Loss: 0.5049\n",
            "[Train] | Epoch: 0174 / 1000 | Batch: 0003 / 0004 | Loss: 0.4943\n",
            "[Train] | Epoch: 0174 / 1000 | Batch: 0004 / 0004 | Loss: 0.4981\n",
            "[Validation] | Epoch: 0174 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0174 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0174] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0175 / 1000 | Batch: 0001 / 0004 | Loss: 0.5024\n",
            "[Train] | Epoch: 0175 / 1000 | Batch: 0002 / 0004 | Loss: 0.4957\n",
            "[Train] | Epoch: 0175 / 1000 | Batch: 0003 / 0004 | Loss: 0.4914\n",
            "[Train] | Epoch: 0175 / 1000 | Batch: 0004 / 0004 | Loss: 0.4901\n",
            "[Validation] | Epoch: 0175 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0175 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0175] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0176 / 1000 | Batch: 0001 / 0004 | Loss: 0.4909\n",
            "[Train] | Epoch: 0176 / 1000 | Batch: 0002 / 0004 | Loss: 0.4872\n",
            "[Train] | Epoch: 0176 / 1000 | Batch: 0003 / 0004 | Loss: 0.5061\n",
            "[Train] | Epoch: 0176 / 1000 | Batch: 0004 / 0004 | Loss: 0.4980\n",
            "[Validation] | Epoch: 0176 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0176 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0176] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0177 / 1000 | Batch: 0001 / 0004 | Loss: 0.5012\n",
            "[Train] | Epoch: 0177 / 1000 | Batch: 0002 / 0004 | Loss: 0.4847\n",
            "[Train] | Epoch: 0177 / 1000 | Batch: 0003 / 0004 | Loss: 0.5074\n",
            "[Train] | Epoch: 0177 / 1000 | Batch: 0004 / 0004 | Loss: 0.4871\n",
            "[Validation] | Epoch: 0177 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0177 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0177] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0178 / 1000 | Batch: 0001 / 0004 | Loss: 0.4936\n",
            "[Train] | Epoch: 0178 / 1000 | Batch: 0002 / 0004 | Loss: 0.4982\n",
            "[Train] | Epoch: 0178 / 1000 | Batch: 0003 / 0004 | Loss: 0.5003\n",
            "[Train] | Epoch: 0178 / 1000 | Batch: 0004 / 0004 | Loss: 0.4882\n",
            "[Validation] | Epoch: 0178 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0178 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0178] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0179 / 1000 | Batch: 0001 / 0004 | Loss: 0.4943\n",
            "[Train] | Epoch: 0179 / 1000 | Batch: 0002 / 0004 | Loss: 0.4938\n",
            "[Train] | Epoch: 0179 / 1000 | Batch: 0003 / 0004 | Loss: 0.4937\n",
            "[Train] | Epoch: 0179 / 1000 | Batch: 0004 / 0004 | Loss: 0.5052\n",
            "[Validation] | Epoch: 0179 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0179 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0179] Training Avg Loss: 0.4967 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0180 / 1000 | Batch: 0001 / 0004 | Loss: 0.4941\n",
            "[Train] | Epoch: 0180 / 1000 | Batch: 0002 / 0004 | Loss: 0.4948\n",
            "[Train] | Epoch: 0180 / 1000 | Batch: 0003 / 0004 | Loss: 0.5017\n",
            "[Train] | Epoch: 0180 / 1000 | Batch: 0004 / 0004 | Loss: 0.4914\n",
            "[Validation] | Epoch: 0180 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0180 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0180] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0181 / 1000 | Batch: 0001 / 0004 | Loss: 0.4928\n",
            "[Train] | Epoch: 0181 / 1000 | Batch: 0002 / 0004 | Loss: 0.4933\n",
            "[Train] | Epoch: 0181 / 1000 | Batch: 0003 / 0004 | Loss: 0.4989\n",
            "[Train] | Epoch: 0181 / 1000 | Batch: 0004 / 0004 | Loss: 0.4968\n",
            "[Validation] | Epoch: 0181 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0181 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0181] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0182 / 1000 | Batch: 0001 / 0004 | Loss: 0.4939\n",
            "[Train] | Epoch: 0182 / 1000 | Batch: 0002 / 0004 | Loss: 0.5001\n",
            "[Train] | Epoch: 0182 / 1000 | Batch: 0003 / 0004 | Loss: 0.4912\n",
            "[Train] | Epoch: 0182 / 1000 | Batch: 0004 / 0004 | Loss: 0.4982\n",
            "[Validation] | Epoch: 0182 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0182 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0182] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0183 / 1000 | Batch: 0001 / 0004 | Loss: 0.5010\n",
            "[Train] | Epoch: 0183 / 1000 | Batch: 0002 / 0004 | Loss: 0.4955\n",
            "[Train] | Epoch: 0183 / 1000 | Batch: 0003 / 0004 | Loss: 0.4971\n",
            "[Train] | Epoch: 0183 / 1000 | Batch: 0004 / 0004 | Loss: 0.4874\n",
            "[Validation] | Epoch: 0183 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0183 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0183] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0184 / 1000 | Batch: 0001 / 0004 | Loss: 0.4894\n",
            "[Train] | Epoch: 0184 / 1000 | Batch: 0002 / 0004 | Loss: 0.5019\n",
            "[Train] | Epoch: 0184 / 1000 | Batch: 0003 / 0004 | Loss: 0.4918\n",
            "[Train] | Epoch: 0184 / 1000 | Batch: 0004 / 0004 | Loss: 0.5021\n",
            "[Validation] | Epoch: 0184 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0184 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0184] Training Avg Loss: 0.4963 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0185 / 1000 | Batch: 0001 / 0004 | Loss: 0.4899\n",
            "[Train] | Epoch: 0185 / 1000 | Batch: 0002 / 0004 | Loss: 0.5014\n",
            "[Train] | Epoch: 0185 / 1000 | Batch: 0003 / 0004 | Loss: 0.4948\n",
            "[Train] | Epoch: 0185 / 1000 | Batch: 0004 / 0004 | Loss: 0.4962\n",
            "[Validation] | Epoch: 0185 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0185 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0185] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0186 / 1000 | Batch: 0001 / 0004 | Loss: 0.4992\n",
            "[Train] | Epoch: 0186 / 1000 | Batch: 0002 / 0004 | Loss: 0.4980\n",
            "[Train] | Epoch: 0186 / 1000 | Batch: 0003 / 0004 | Loss: 0.4890\n",
            "[Train] | Epoch: 0186 / 1000 | Batch: 0004 / 0004 | Loss: 0.4959\n",
            "[Validation] | Epoch: 0186 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0186 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0186] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0187 / 1000 | Batch: 0001 / 0004 | Loss: 0.4945\n",
            "[Train] | Epoch: 0187 / 1000 | Batch: 0002 / 0004 | Loss: 0.4918\n",
            "[Train] | Epoch: 0187 / 1000 | Batch: 0003 / 0004 | Loss: 0.4947\n",
            "[Train] | Epoch: 0187 / 1000 | Batch: 0004 / 0004 | Loss: 0.5025\n",
            "[Validation] | Epoch: 0187 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0187 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0187] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0188 / 1000 | Batch: 0001 / 0004 | Loss: 0.5078\n",
            "[Train] | Epoch: 0188 / 1000 | Batch: 0002 / 0004 | Loss: 0.4866\n",
            "[Train] | Epoch: 0188 / 1000 | Batch: 0003 / 0004 | Loss: 0.4940\n",
            "[Train] | Epoch: 0188 / 1000 | Batch: 0004 / 0004 | Loss: 0.4897\n",
            "[Validation] | Epoch: 0188 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0188 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0188] Training Avg Loss: 0.4945 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0189 / 1000 | Batch: 0001 / 0004 | Loss: 0.5022\n",
            "[Train] | Epoch: 0189 / 1000 | Batch: 0002 / 0004 | Loss: 0.4968\n",
            "[Train] | Epoch: 0189 / 1000 | Batch: 0003 / 0004 | Loss: 0.4892\n",
            "[Train] | Epoch: 0189 / 1000 | Batch: 0004 / 0004 | Loss: 0.4967\n",
            "[Validation] | Epoch: 0189 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0189 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0189] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0190 / 1000 | Batch: 0001 / 0004 | Loss: 0.5072\n",
            "[Train] | Epoch: 0190 / 1000 | Batch: 0002 / 0004 | Loss: 0.4935\n",
            "[Train] | Epoch: 0190 / 1000 | Batch: 0003 / 0004 | Loss: 0.4899\n",
            "[Train] | Epoch: 0190 / 1000 | Batch: 0004 / 0004 | Loss: 0.4911\n",
            "[Validation] | Epoch: 0190 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0190 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0190] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0191 / 1000 | Batch: 0001 / 0004 | Loss: 0.4926\n",
            "[Train] | Epoch: 0191 / 1000 | Batch: 0002 / 0004 | Loss: 0.4924\n",
            "[Train] | Epoch: 0191 / 1000 | Batch: 0003 / 0004 | Loss: 0.4925\n",
            "[Train] | Epoch: 0191 / 1000 | Batch: 0004 / 0004 | Loss: 0.5078\n",
            "[Validation] | Epoch: 0191 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0191 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0191] Training Avg Loss: 0.4963 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0192 / 1000 | Batch: 0001 / 0004 | Loss: 0.4948\n",
            "[Train] | Epoch: 0192 / 1000 | Batch: 0002 / 0004 | Loss: 0.4888\n",
            "[Train] | Epoch: 0192 / 1000 | Batch: 0003 / 0004 | Loss: 0.5014\n",
            "[Train] | Epoch: 0192 / 1000 | Batch: 0004 / 0004 | Loss: 0.4970\n",
            "[Validation] | Epoch: 0192 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0192 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0192] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0193 / 1000 | Batch: 0001 / 0004 | Loss: 0.4862\n",
            "[Train] | Epoch: 0193 / 1000 | Batch: 0002 / 0004 | Loss: 0.5010\n",
            "[Train] | Epoch: 0193 / 1000 | Batch: 0003 / 0004 | Loss: 0.4954\n",
            "[Train] | Epoch: 0193 / 1000 | Batch: 0004 / 0004 | Loss: 0.5034\n",
            "[Validation] | Epoch: 0193 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0193 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0193] Training Avg Loss: 0.4965 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0194 / 1000 | Batch: 0001 / 0004 | Loss: 0.5019\n",
            "[Train] | Epoch: 0194 / 1000 | Batch: 0002 / 0004 | Loss: 0.4914\n",
            "[Train] | Epoch: 0194 / 1000 | Batch: 0003 / 0004 | Loss: 0.4928\n",
            "[Train] | Epoch: 0194 / 1000 | Batch: 0004 / 0004 | Loss: 0.4969\n",
            "[Validation] | Epoch: 0194 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0194 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0194] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0195 / 1000 | Batch: 0001 / 0004 | Loss: 0.4967\n",
            "[Train] | Epoch: 0195 / 1000 | Batch: 0002 / 0004 | Loss: 0.4974\n",
            "[Train] | Epoch: 0195 / 1000 | Batch: 0003 / 0004 | Loss: 0.4915\n",
            "[Train] | Epoch: 0195 / 1000 | Batch: 0004 / 0004 | Loss: 0.4955\n",
            "[Validation] | Epoch: 0195 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0195 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0195] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0196 / 1000 | Batch: 0001 / 0004 | Loss: 0.4946\n",
            "[Train] | Epoch: 0196 / 1000 | Batch: 0002 / 0004 | Loss: 0.4884\n",
            "[Train] | Epoch: 0196 / 1000 | Batch: 0003 / 0004 | Loss: 0.5031\n",
            "[Train] | Epoch: 0196 / 1000 | Batch: 0004 / 0004 | Loss: 0.4958\n",
            "[Validation] | Epoch: 0196 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0196 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0196] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0197 / 1000 | Batch: 0001 / 0004 | Loss: 0.4908\n",
            "[Train] | Epoch: 0197 / 1000 | Batch: 0002 / 0004 | Loss: 0.5022\n",
            "[Train] | Epoch: 0197 / 1000 | Batch: 0003 / 0004 | Loss: 0.4980\n",
            "[Train] | Epoch: 0197 / 1000 | Batch: 0004 / 0004 | Loss: 0.4902\n",
            "[Validation] | Epoch: 0197 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0197 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0197] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0198 / 1000 | Batch: 0001 / 0004 | Loss: 0.4980\n",
            "[Train] | Epoch: 0198 / 1000 | Batch: 0002 / 0004 | Loss: 0.4941\n",
            "[Train] | Epoch: 0198 / 1000 | Batch: 0003 / 0004 | Loss: 0.4900\n",
            "[Train] | Epoch: 0198 / 1000 | Batch: 0004 / 0004 | Loss: 0.5040\n",
            "[Validation] | Epoch: 0198 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0198 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0198] Training Avg Loss: 0.4965 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0199 / 1000 | Batch: 0001 / 0004 | Loss: 0.4960\n",
            "[Train] | Epoch: 0199 / 1000 | Batch: 0002 / 0004 | Loss: 0.4967\n",
            "[Train] | Epoch: 0199 / 1000 | Batch: 0003 / 0004 | Loss: 0.4880\n",
            "[Train] | Epoch: 0199 / 1000 | Batch: 0004 / 0004 | Loss: 0.5052\n",
            "[Validation] | Epoch: 0199 / 1000 | Batch: 0001 / 0002 | Loss: 0.5071\n",
            "[Validation] | Epoch: 0199 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0199] Training Avg Loss: 0.4965 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0200 / 1000 | Batch: 0001 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0200 / 1000 | Batch: 0002 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0200 / 1000 | Batch: 0003 / 0004 | Loss: 0.4943\n",
            "[Train] | Epoch: 0200 / 1000 | Batch: 0004 / 0004 | Loss: 0.5010\n",
            "[Validation] | Epoch: 0200 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0200 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0200] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0201 / 1000 | Batch: 0001 / 0004 | Loss: 0.4968\n",
            "[Train] | Epoch: 0201 / 1000 | Batch: 0002 / 0004 | Loss: 0.4910\n",
            "[Train] | Epoch: 0201 / 1000 | Batch: 0003 / 0004 | Loss: 0.4982\n",
            "[Train] | Epoch: 0201 / 1000 | Batch: 0004 / 0004 | Loss: 0.4960\n",
            "[Validation] | Epoch: 0201 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0201 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0201] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0202 / 1000 | Batch: 0001 / 0004 | Loss: 0.5065\n",
            "[Train] | Epoch: 0202 / 1000 | Batch: 0002 / 0004 | Loss: 0.4929\n",
            "[Train] | Epoch: 0202 / 1000 | Batch: 0003 / 0004 | Loss: 0.4947\n",
            "[Train] | Epoch: 0202 / 1000 | Batch: 0004 / 0004 | Loss: 0.4852\n",
            "[Validation] | Epoch: 0202 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0202 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0202] Training Avg Loss: 0.4948 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0203 / 1000 | Batch: 0001 / 0004 | Loss: 0.4949\n",
            "[Train] | Epoch: 0203 / 1000 | Batch: 0002 / 0004 | Loss: 0.4932\n",
            "[Train] | Epoch: 0203 / 1000 | Batch: 0003 / 0004 | Loss: 0.5015\n",
            "[Train] | Epoch: 0203 / 1000 | Batch: 0004 / 0004 | Loss: 0.4934\n",
            "[Validation] | Epoch: 0203 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0203 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0203] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0204 / 1000 | Batch: 0001 / 0004 | Loss: 0.4953\n",
            "[Train] | Epoch: 0204 / 1000 | Batch: 0002 / 0004 | Loss: 0.4967\n",
            "[Train] | Epoch: 0204 / 1000 | Batch: 0003 / 0004 | Loss: 0.4950\n",
            "[Train] | Epoch: 0204 / 1000 | Batch: 0004 / 0004 | Loss: 0.4917\n",
            "[Validation] | Epoch: 0204 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0204 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0204] Training Avg Loss: 0.4947 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0205 / 1000 | Batch: 0001 / 0004 | Loss: 0.4939\n",
            "[Train] | Epoch: 0205 / 1000 | Batch: 0002 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0205 / 1000 | Batch: 0003 / 0004 | Loss: 0.4977\n",
            "[Train] | Epoch: 0205 / 1000 | Batch: 0004 / 0004 | Loss: 0.4937\n",
            "[Validation] | Epoch: 0205 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0205 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0205] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0206 / 1000 | Batch: 0001 / 0004 | Loss: 0.4949\n",
            "[Train] | Epoch: 0206 / 1000 | Batch: 0002 / 0004 | Loss: 0.4954\n",
            "[Train] | Epoch: 0206 / 1000 | Batch: 0003 / 0004 | Loss: 0.4970\n",
            "[Train] | Epoch: 0206 / 1000 | Batch: 0004 / 0004 | Loss: 0.4943\n",
            "[Validation] | Epoch: 0206 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0206 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0206] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0207 / 1000 | Batch: 0001 / 0004 | Loss: 0.4892\n",
            "[Train] | Epoch: 0207 / 1000 | Batch: 0002 / 0004 | Loss: 0.4884\n",
            "[Train] | Epoch: 0207 / 1000 | Batch: 0003 / 0004 | Loss: 0.5042\n",
            "[Train] | Epoch: 0207 / 1000 | Batch: 0004 / 0004 | Loss: 0.5003\n",
            "[Validation] | Epoch: 0207 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0207 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0207] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0208 / 1000 | Batch: 0001 / 0004 | Loss: 0.4930\n",
            "[Train] | Epoch: 0208 / 1000 | Batch: 0002 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0208 / 1000 | Batch: 0003 / 0004 | Loss: 0.5012\n",
            "[Train] | Epoch: 0208 / 1000 | Batch: 0004 / 0004 | Loss: 0.4898\n",
            "[Validation] | Epoch: 0208 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0208 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0208] Training Avg Loss: 0.4948 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0209 / 1000 | Batch: 0001 / 0004 | Loss: 0.4980\n",
            "[Train] | Epoch: 0209 / 1000 | Batch: 0002 / 0004 | Loss: 0.5046\n",
            "[Train] | Epoch: 0209 / 1000 | Batch: 0003 / 0004 | Loss: 0.4919\n",
            "[Train] | Epoch: 0209 / 1000 | Batch: 0004 / 0004 | Loss: 0.4858\n",
            "[Validation] | Epoch: 0209 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0209 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0209] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0210 / 1000 | Batch: 0001 / 0004 | Loss: 0.5010\n",
            "[Train] | Epoch: 0210 / 1000 | Batch: 0002 / 0004 | Loss: 0.4866\n",
            "[Train] | Epoch: 0210 / 1000 | Batch: 0003 / 0004 | Loss: 0.4955\n",
            "[Train] | Epoch: 0210 / 1000 | Batch: 0004 / 0004 | Loss: 0.5014\n",
            "[Validation] | Epoch: 0210 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0210 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0210] Training Avg Loss: 0.4961 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0211 / 1000 | Batch: 0001 / 0004 | Loss: 0.4893\n",
            "[Train] | Epoch: 0211 / 1000 | Batch: 0002 / 0004 | Loss: 0.4923\n",
            "[Train] | Epoch: 0211 / 1000 | Batch: 0003 / 0004 | Loss: 0.5020\n",
            "[Train] | Epoch: 0211 / 1000 | Batch: 0004 / 0004 | Loss: 0.4983\n",
            "[Validation] | Epoch: 0211 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0211 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0211] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0212 / 1000 | Batch: 0001 / 0004 | Loss: 0.4931\n",
            "[Train] | Epoch: 0212 / 1000 | Batch: 0002 / 0004 | Loss: 0.4987\n",
            "[Train] | Epoch: 0212 / 1000 | Batch: 0003 / 0004 | Loss: 0.4982\n",
            "[Train] | Epoch: 0212 / 1000 | Batch: 0004 / 0004 | Loss: 0.4924\n",
            "[Validation] | Epoch: 0212 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0212 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0212] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0213 / 1000 | Batch: 0001 / 0004 | Loss: 0.4936\n",
            "[Train] | Epoch: 0213 / 1000 | Batch: 0002 / 0004 | Loss: 0.4988\n",
            "[Train] | Epoch: 0213 / 1000 | Batch: 0003 / 0004 | Loss: 0.4952\n",
            "[Train] | Epoch: 0213 / 1000 | Batch: 0004 / 0004 | Loss: 0.4948\n",
            "[Validation] | Epoch: 0213 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0213 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0213] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0214 / 1000 | Batch: 0001 / 0004 | Loss: 0.4945\n",
            "[Train] | Epoch: 0214 / 1000 | Batch: 0002 / 0004 | Loss: 0.4998\n",
            "[Train] | Epoch: 0214 / 1000 | Batch: 0003 / 0004 | Loss: 0.4900\n",
            "[Train] | Epoch: 0214 / 1000 | Batch: 0004 / 0004 | Loss: 0.4979\n",
            "[Validation] | Epoch: 0214 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0214 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0214] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0215 / 1000 | Batch: 0001 / 0004 | Loss: 0.5027\n",
            "[Train] | Epoch: 0215 / 1000 | Batch: 0002 / 0004 | Loss: 0.4884\n",
            "[Train] | Epoch: 0215 / 1000 | Batch: 0003 / 0004 | Loss: 0.4943\n",
            "[Train] | Epoch: 0215 / 1000 | Batch: 0004 / 0004 | Loss: 0.4957\n",
            "[Validation] | Epoch: 0215 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0215 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0215] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0216 / 1000 | Batch: 0001 / 0004 | Loss: 0.4963\n",
            "[Train] | Epoch: 0216 / 1000 | Batch: 0002 / 0004 | Loss: 0.4987\n",
            "[Train] | Epoch: 0216 / 1000 | Batch: 0003 / 0004 | Loss: 0.4993\n",
            "[Train] | Epoch: 0216 / 1000 | Batch: 0004 / 0004 | Loss: 0.4856\n",
            "[Validation] | Epoch: 0216 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0216 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0216] Training Avg Loss: 0.4950 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0217 / 1000 | Batch: 0001 / 0004 | Loss: 0.4884\n",
            "[Train] | Epoch: 0217 / 1000 | Batch: 0002 / 0004 | Loss: 0.4868\n",
            "[Train] | Epoch: 0217 / 1000 | Batch: 0003 / 0004 | Loss: 0.5002\n",
            "[Train] | Epoch: 0217 / 1000 | Batch: 0004 / 0004 | Loss: 0.5112\n",
            "[Validation] | Epoch: 0217 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0217 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0217] Training Avg Loss: 0.4966 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0218 / 1000 | Batch: 0001 / 0004 | Loss: 0.4946\n",
            "[Train] | Epoch: 0218 / 1000 | Batch: 0002 / 0004 | Loss: 0.5038\n",
            "[Train] | Epoch: 0218 / 1000 | Batch: 0003 / 0004 | Loss: 0.4887\n",
            "[Train] | Epoch: 0218 / 1000 | Batch: 0004 / 0004 | Loss: 0.4960\n",
            "[Validation] | Epoch: 0218 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0218 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0218] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0219 / 1000 | Batch: 0001 / 0004 | Loss: 0.4988\n",
            "[Train] | Epoch: 0219 / 1000 | Batch: 0002 / 0004 | Loss: 0.4942\n",
            "[Train] | Epoch: 0219 / 1000 | Batch: 0003 / 0004 | Loss: 0.4942\n",
            "[Train] | Epoch: 0219 / 1000 | Batch: 0004 / 0004 | Loss: 0.4950\n",
            "[Validation] | Epoch: 0219 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0219 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0219] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0220 / 1000 | Batch: 0001 / 0004 | Loss: 0.4946\n",
            "[Train] | Epoch: 0220 / 1000 | Batch: 0002 / 0004 | Loss: 0.5015\n",
            "[Train] | Epoch: 0220 / 1000 | Batch: 0003 / 0004 | Loss: 0.4878\n",
            "[Train] | Epoch: 0220 / 1000 | Batch: 0004 / 0004 | Loss: 0.5011\n",
            "[Validation] | Epoch: 0220 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0220 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0220] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0221 / 1000 | Batch: 0001 / 0004 | Loss: 0.4892\n",
            "[Train] | Epoch: 0221 / 1000 | Batch: 0002 / 0004 | Loss: 0.4997\n",
            "[Train] | Epoch: 0221 / 1000 | Batch: 0003 / 0004 | Loss: 0.4974\n",
            "[Train] | Epoch: 0221 / 1000 | Batch: 0004 / 0004 | Loss: 0.4968\n",
            "[Validation] | Epoch: 0221 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0221 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0221] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0222 / 1000 | Batch: 0001 / 0004 | Loss: 0.4883\n",
            "[Train] | Epoch: 0222 / 1000 | Batch: 0002 / 0004 | Loss: 0.5035\n",
            "[Train] | Epoch: 0222 / 1000 | Batch: 0003 / 0004 | Loss: 0.4941\n",
            "[Train] | Epoch: 0222 / 1000 | Batch: 0004 / 0004 | Loss: 0.4957\n",
            "[Validation] | Epoch: 0222 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0222 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0222] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0223 / 1000 | Batch: 0001 / 0004 | Loss: 0.4971\n",
            "[Train] | Epoch: 0223 / 1000 | Batch: 0002 / 0004 | Loss: 0.5025\n",
            "[Train] | Epoch: 0223 / 1000 | Batch: 0003 / 0004 | Loss: 0.4901\n",
            "[Train] | Epoch: 0223 / 1000 | Batch: 0004 / 0004 | Loss: 0.4922\n",
            "[Validation] | Epoch: 0223 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0223 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0223] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0224 / 1000 | Batch: 0001 / 0004 | Loss: 0.4871\n",
            "[Train] | Epoch: 0224 / 1000 | Batch: 0002 / 0004 | Loss: 0.4939\n",
            "[Train] | Epoch: 0224 / 1000 | Batch: 0003 / 0004 | Loss: 0.4994\n",
            "[Train] | Epoch: 0224 / 1000 | Batch: 0004 / 0004 | Loss: 0.5050\n",
            "[Validation] | Epoch: 0224 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0224 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0224] Training Avg Loss: 0.4964 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0225 / 1000 | Batch: 0001 / 0004 | Loss: 0.4931\n",
            "[Train] | Epoch: 0225 / 1000 | Batch: 0002 / 0004 | Loss: 0.5024\n",
            "[Train] | Epoch: 0225 / 1000 | Batch: 0003 / 0004 | Loss: 0.4879\n",
            "[Train] | Epoch: 0225 / 1000 | Batch: 0004 / 0004 | Loss: 0.4999\n",
            "[Validation] | Epoch: 0225 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0225 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0225] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0226 / 1000 | Batch: 0001 / 0004 | Loss: 0.5007\n",
            "[Train] | Epoch: 0226 / 1000 | Batch: 0002 / 0004 | Loss: 0.4912\n",
            "[Train] | Epoch: 0226 / 1000 | Batch: 0003 / 0004 | Loss: 0.4928\n",
            "[Train] | Epoch: 0226 / 1000 | Batch: 0004 / 0004 | Loss: 0.4974\n",
            "[Validation] | Epoch: 0226 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0226 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0226] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0227 / 1000 | Batch: 0001 / 0004 | Loss: 0.4917\n",
            "[Train] | Epoch: 0227 / 1000 | Batch: 0002 / 0004 | Loss: 0.4916\n",
            "[Train] | Epoch: 0227 / 1000 | Batch: 0003 / 0004 | Loss: 0.5030\n",
            "[Train] | Epoch: 0227 / 1000 | Batch: 0004 / 0004 | Loss: 0.4955\n",
            "[Validation] | Epoch: 0227 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0227 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0227] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0228 / 1000 | Batch: 0001 / 0004 | Loss: 0.4987\n",
            "[Train] | Epoch: 0228 / 1000 | Batch: 0002 / 0004 | Loss: 0.5020\n",
            "[Train] | Epoch: 0228 / 1000 | Batch: 0003 / 0004 | Loss: 0.4930\n",
            "[Train] | Epoch: 0228 / 1000 | Batch: 0004 / 0004 | Loss: 0.4866\n",
            "[Validation] | Epoch: 0228 / 1000 | Batch: 0001 / 0002 | Loss: 0.5077\n",
            "[Validation] | Epoch: 0228 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0228] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4970\n",
            "[Train] | Epoch: 0229 / 1000 | Batch: 0001 / 0004 | Loss: 0.5022\n",
            "[Train] | Epoch: 0229 / 1000 | Batch: 0002 / 0004 | Loss: 0.4877\n",
            "[Train] | Epoch: 0229 / 1000 | Batch: 0003 / 0004 | Loss: 0.4890\n",
            "[Train] | Epoch: 0229 / 1000 | Batch: 0004 / 0004 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0229 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0229 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0229] Training Avg Loss: 0.4965 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0230 / 1000 | Batch: 0001 / 0004 | Loss: 0.4984\n",
            "[Train] | Epoch: 0230 / 1000 | Batch: 0002 / 0004 | Loss: 0.4894\n",
            "[Train] | Epoch: 0230 / 1000 | Batch: 0003 / 0004 | Loss: 0.5009\n",
            "[Train] | Epoch: 0230 / 1000 | Batch: 0004 / 0004 | Loss: 0.4932\n",
            "[Validation] | Epoch: 0230 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0230 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0230] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0231 / 1000 | Batch: 0001 / 0004 | Loss: 0.5036\n",
            "[Train] | Epoch: 0231 / 1000 | Batch: 0002 / 0004 | Loss: 0.4856\n",
            "[Train] | Epoch: 0231 / 1000 | Batch: 0003 / 0004 | Loss: 0.4934\n",
            "[Train] | Epoch: 0231 / 1000 | Batch: 0004 / 0004 | Loss: 0.5015\n",
            "[Validation] | Epoch: 0231 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0231 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0231] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0232 / 1000 | Batch: 0001 / 0004 | Loss: 0.5028\n",
            "[Train] | Epoch: 0232 / 1000 | Batch: 0002 / 0004 | Loss: 0.4929\n",
            "[Train] | Epoch: 0232 / 1000 | Batch: 0003 / 0004 | Loss: 0.4862\n",
            "[Train] | Epoch: 0232 / 1000 | Batch: 0004 / 0004 | Loss: 0.5031\n",
            "[Validation] | Epoch: 0232 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0232 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0232] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0233 / 1000 | Batch: 0001 / 0004 | Loss: 0.4999\n",
            "[Train] | Epoch: 0233 / 1000 | Batch: 0002 / 0004 | Loss: 0.4958\n",
            "[Train] | Epoch: 0233 / 1000 | Batch: 0003 / 0004 | Loss: 0.4858\n",
            "[Train] | Epoch: 0233 / 1000 | Batch: 0004 / 0004 | Loss: 0.5025\n",
            "[Validation] | Epoch: 0233 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0233 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0233] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0234 / 1000 | Batch: 0001 / 0004 | Loss: 0.4924\n",
            "[Train] | Epoch: 0234 / 1000 | Batch: 0002 / 0004 | Loss: 0.4971\n",
            "[Train] | Epoch: 0234 / 1000 | Batch: 0003 / 0004 | Loss: 0.4894\n",
            "[Train] | Epoch: 0234 / 1000 | Batch: 0004 / 0004 | Loss: 0.5050\n",
            "[Validation] | Epoch: 0234 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0234 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0234] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0235 / 1000 | Batch: 0001 / 0004 | Loss: 0.5030\n",
            "[Train] | Epoch: 0235 / 1000 | Batch: 0002 / 0004 | Loss: 0.4883\n",
            "[Train] | Epoch: 0235 / 1000 | Batch: 0003 / 0004 | Loss: 0.4918\n",
            "[Train] | Epoch: 0235 / 1000 | Batch: 0004 / 0004 | Loss: 0.5002\n",
            "[Validation] | Epoch: 0235 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0235 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0235] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0236 / 1000 | Batch: 0001 / 0004 | Loss: 0.4881\n",
            "[Train] | Epoch: 0236 / 1000 | Batch: 0002 / 0004 | Loss: 0.4943\n",
            "[Train] | Epoch: 0236 / 1000 | Batch: 0003 / 0004 | Loss: 0.5058\n",
            "[Train] | Epoch: 0236 / 1000 | Batch: 0004 / 0004 | Loss: 0.4930\n",
            "[Validation] | Epoch: 0236 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0236 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0236] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0237 / 1000 | Batch: 0001 / 0004 | Loss: 0.4895\n",
            "[Train] | Epoch: 0237 / 1000 | Batch: 0002 / 0004 | Loss: 0.5022\n",
            "[Train] | Epoch: 0237 / 1000 | Batch: 0003 / 0004 | Loss: 0.4946\n",
            "[Train] | Epoch: 0237 / 1000 | Batch: 0004 / 0004 | Loss: 0.4975\n",
            "[Validation] | Epoch: 0237 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0237 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0237] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0238 / 1000 | Batch: 0001 / 0004 | Loss: 0.4977\n",
            "[Train] | Epoch: 0238 / 1000 | Batch: 0002 / 0004 | Loss: 0.4948\n",
            "[Train] | Epoch: 0238 / 1000 | Batch: 0003 / 0004 | Loss: 0.4975\n",
            "[Train] | Epoch: 0238 / 1000 | Batch: 0004 / 0004 | Loss: 0.4906\n",
            "[Validation] | Epoch: 0238 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0238 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0238] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0239 / 1000 | Batch: 0001 / 0004 | Loss: 0.4916\n",
            "[Train] | Epoch: 0239 / 1000 | Batch: 0002 / 0004 | Loss: 0.4861\n",
            "[Train] | Epoch: 0239 / 1000 | Batch: 0003 / 0004 | Loss: 0.4936\n",
            "[Train] | Epoch: 0239 / 1000 | Batch: 0004 / 0004 | Loss: 0.5180\n",
            "[Validation] | Epoch: 0239 / 1000 | Batch: 0001 / 0002 | Loss: 0.5071\n",
            "[Validation] | Epoch: 0239 / 1000 | Batch: 0002 / 0002 | Loss: 0.4852\n",
            "[Epoch 0239] Training Avg Loss: 0.4973 | Validation Avg Loss: 0.4962\n",
            "[Train] | Epoch: 0240 / 1000 | Batch: 0001 / 0004 | Loss: 0.4938\n",
            "[Train] | Epoch: 0240 / 1000 | Batch: 0002 / 0004 | Loss: 0.4937\n",
            "[Train] | Epoch: 0240 / 1000 | Batch: 0003 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0240 / 1000 | Batch: 0004 / 0004 | Loss: 0.5025\n",
            "[Validation] | Epoch: 0240 / 1000 | Batch: 0001 / 0002 | Loss: 0.5070\n",
            "[Validation] | Epoch: 0240 / 1000 | Batch: 0002 / 0002 | Loss: 0.4851\n",
            "[Epoch 0240] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4961\n",
            "[Train] | Epoch: 0241 / 1000 | Batch: 0001 / 0004 | Loss: 0.4987\n",
            "[Train] | Epoch: 0241 / 1000 | Batch: 0002 / 0004 | Loss: 0.5017\n",
            "[Train] | Epoch: 0241 / 1000 | Batch: 0003 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0241 / 1000 | Batch: 0004 / 0004 | Loss: 0.4869\n",
            "[Validation] | Epoch: 0241 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0241 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0241] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0242 / 1000 | Batch: 0001 / 0004 | Loss: 0.4917\n",
            "[Train] | Epoch: 0242 / 1000 | Batch: 0002 / 0004 | Loss: 0.5054\n",
            "[Train] | Epoch: 0242 / 1000 | Batch: 0003 / 0004 | Loss: 0.4895\n",
            "[Train] | Epoch: 0242 / 1000 | Batch: 0004 / 0004 | Loss: 0.4982\n",
            "[Validation] | Epoch: 0242 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0242 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0242] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0243 / 1000 | Batch: 0001 / 0004 | Loss: 0.5070\n",
            "[Train] | Epoch: 0243 / 1000 | Batch: 0002 / 0004 | Loss: 0.4864\n",
            "[Train] | Epoch: 0243 / 1000 | Batch: 0003 / 0004 | Loss: 0.4892\n",
            "[Train] | Epoch: 0243 / 1000 | Batch: 0004 / 0004 | Loss: 0.5002\n",
            "[Validation] | Epoch: 0243 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0243 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0243] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0244 / 1000 | Batch: 0001 / 0004 | Loss: 0.4931\n",
            "[Train] | Epoch: 0244 / 1000 | Batch: 0002 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0244 / 1000 | Batch: 0003 / 0004 | Loss: 0.4937\n",
            "[Train] | Epoch: 0244 / 1000 | Batch: 0004 / 0004 | Loss: 0.5016\n",
            "[Validation] | Epoch: 0244 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0244 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0244] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0245 / 1000 | Batch: 0001 / 0004 | Loss: 0.5002\n",
            "[Train] | Epoch: 0245 / 1000 | Batch: 0002 / 0004 | Loss: 0.4974\n",
            "[Train] | Epoch: 0245 / 1000 | Batch: 0003 / 0004 | Loss: 0.4939\n",
            "[Train] | Epoch: 0245 / 1000 | Batch: 0004 / 0004 | Loss: 0.4893\n",
            "[Validation] | Epoch: 0245 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0245 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0245] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4969\n",
            "[Train] | Epoch: 0246 / 1000 | Batch: 0001 / 0004 | Loss: 0.4932\n",
            "[Train] | Epoch: 0246 / 1000 | Batch: 0002 / 0004 | Loss: 0.4926\n",
            "[Train] | Epoch: 0246 / 1000 | Batch: 0003 / 0004 | Loss: 0.4909\n",
            "[Train] | Epoch: 0246 / 1000 | Batch: 0004 / 0004 | Loss: 0.5088\n",
            "[Validation] | Epoch: 0246 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0246 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0246] Training Avg Loss: 0.4964 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0247 / 1000 | Batch: 0001 / 0004 | Loss: 0.5048\n",
            "[Train] | Epoch: 0247 / 1000 | Batch: 0002 / 0004 | Loss: 0.4871\n",
            "[Train] | Epoch: 0247 / 1000 | Batch: 0003 / 0004 | Loss: 0.4943\n",
            "[Train] | Epoch: 0247 / 1000 | Batch: 0004 / 0004 | Loss: 0.4957\n",
            "[Validation] | Epoch: 0247 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0247 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0247] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0248 / 1000 | Batch: 0001 / 0004 | Loss: 0.4969\n",
            "[Train] | Epoch: 0248 / 1000 | Batch: 0002 / 0004 | Loss: 0.4971\n",
            "[Train] | Epoch: 0248 / 1000 | Batch: 0003 / 0004 | Loss: 0.4860\n",
            "[Train] | Epoch: 0248 / 1000 | Batch: 0004 / 0004 | Loss: 0.5037\n",
            "[Validation] | Epoch: 0248 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0248 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0248] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0249 / 1000 | Batch: 0001 / 0004 | Loss: 0.4922\n",
            "[Train] | Epoch: 0249 / 1000 | Batch: 0002 / 0004 | Loss: 0.5035\n",
            "[Train] | Epoch: 0249 / 1000 | Batch: 0003 / 0004 | Loss: 0.4922\n",
            "[Train] | Epoch: 0249 / 1000 | Batch: 0004 / 0004 | Loss: 0.4943\n",
            "[Validation] | Epoch: 0249 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0249 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0249] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0250 / 1000 | Batch: 0001 / 0004 | Loss: 0.5059\n",
            "[Train] | Epoch: 0250 / 1000 | Batch: 0002 / 0004 | Loss: 0.4997\n",
            "[Train] | Epoch: 0250 / 1000 | Batch: 0003 / 0004 | Loss: 0.4839\n",
            "[Train] | Epoch: 0250 / 1000 | Batch: 0004 / 0004 | Loss: 0.4911\n",
            "[Validation] | Epoch: 0250 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0250 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0250] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0251 / 1000 | Batch: 0001 / 0004 | Loss: 0.4834\n",
            "[Train] | Epoch: 0251 / 1000 | Batch: 0002 / 0004 | Loss: 0.5041\n",
            "[Train] | Epoch: 0251 / 1000 | Batch: 0003 / 0004 | Loss: 0.4996\n",
            "[Train] | Epoch: 0251 / 1000 | Batch: 0004 / 0004 | Loss: 0.4946\n",
            "[Validation] | Epoch: 0251 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0251 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0251] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0252 / 1000 | Batch: 0001 / 0004 | Loss: 0.5004\n",
            "[Train] | Epoch: 0252 / 1000 | Batch: 0002 / 0004 | Loss: 0.5001\n",
            "[Train] | Epoch: 0252 / 1000 | Batch: 0003 / 0004 | Loss: 0.4952\n",
            "[Train] | Epoch: 0252 / 1000 | Batch: 0004 / 0004 | Loss: 0.4854\n",
            "[Validation] | Epoch: 0252 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0252 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0252] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0253 / 1000 | Batch: 0001 / 0004 | Loss: 0.4973\n",
            "[Train] | Epoch: 0253 / 1000 | Batch: 0002 / 0004 | Loss: 0.4992\n",
            "[Train] | Epoch: 0253 / 1000 | Batch: 0003 / 0004 | Loss: 0.4826\n",
            "[Train] | Epoch: 0253 / 1000 | Batch: 0004 / 0004 | Loss: 0.5042\n",
            "[Validation] | Epoch: 0253 / 1000 | Batch: 0001 / 0002 | Loss: 0.5071\n",
            "[Validation] | Epoch: 0253 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0253] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0254 / 1000 | Batch: 0001 / 0004 | Loss: 0.4906\n",
            "[Train] | Epoch: 0254 / 1000 | Batch: 0002 / 0004 | Loss: 0.4945\n",
            "[Train] | Epoch: 0254 / 1000 | Batch: 0003 / 0004 | Loss: 0.5011\n",
            "[Train] | Epoch: 0254 / 1000 | Batch: 0004 / 0004 | Loss: 0.4942\n",
            "[Validation] | Epoch: 0254 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0254 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0254] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0255 / 1000 | Batch: 0001 / 0004 | Loss: 0.4920\n",
            "[Train] | Epoch: 0255 / 1000 | Batch: 0002 / 0004 | Loss: 0.4989\n",
            "[Train] | Epoch: 0255 / 1000 | Batch: 0003 / 0004 | Loss: 0.4949\n",
            "[Train] | Epoch: 0255 / 1000 | Batch: 0004 / 0004 | Loss: 0.4957\n",
            "[Validation] | Epoch: 0255 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0255 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0255] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0256 / 1000 | Batch: 0001 / 0004 | Loss: 0.4956\n",
            "[Train] | Epoch: 0256 / 1000 | Batch: 0002 / 0004 | Loss: 0.4957\n",
            "[Train] | Epoch: 0256 / 1000 | Batch: 0003 / 0004 | Loss: 0.4927\n",
            "[Train] | Epoch: 0256 / 1000 | Batch: 0004 / 0004 | Loss: 0.4990\n",
            "[Validation] | Epoch: 0256 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0256 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0256] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0257 / 1000 | Batch: 0001 / 0004 | Loss: 0.4917\n",
            "[Train] | Epoch: 0257 / 1000 | Batch: 0002 / 0004 | Loss: 0.4927\n",
            "[Train] | Epoch: 0257 / 1000 | Batch: 0003 / 0004 | Loss: 0.4961\n",
            "[Train] | Epoch: 0257 / 1000 | Batch: 0004 / 0004 | Loss: 0.5053\n",
            "[Validation] | Epoch: 0257 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0257 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0257] Training Avg Loss: 0.4965 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0258 / 1000 | Batch: 0001 / 0004 | Loss: 0.5063\n",
            "[Train] | Epoch: 0258 / 1000 | Batch: 0002 / 0004 | Loss: 0.4863\n",
            "[Train] | Epoch: 0258 / 1000 | Batch: 0003 / 0004 | Loss: 0.4848\n",
            "[Train] | Epoch: 0258 / 1000 | Batch: 0004 / 0004 | Loss: 0.5125\n",
            "[Validation] | Epoch: 0258 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0258 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0258] Training Avg Loss: 0.4975 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0259 / 1000 | Batch: 0001 / 0004 | Loss: 0.4983\n",
            "[Train] | Epoch: 0259 / 1000 | Batch: 0002 / 0004 | Loss: 0.4958\n",
            "[Train] | Epoch: 0259 / 1000 | Batch: 0003 / 0004 | Loss: 0.4931\n",
            "[Train] | Epoch: 0259 / 1000 | Batch: 0004 / 0004 | Loss: 0.4945\n",
            "[Validation] | Epoch: 0259 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0259 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0259] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0260 / 1000 | Batch: 0001 / 0004 | Loss: 0.4872\n",
            "[Train] | Epoch: 0260 / 1000 | Batch: 0002 / 0004 | Loss: 0.5010\n",
            "[Train] | Epoch: 0260 / 1000 | Batch: 0003 / 0004 | Loss: 0.4990\n",
            "[Train] | Epoch: 0260 / 1000 | Batch: 0004 / 0004 | Loss: 0.4935\n",
            "[Validation] | Epoch: 0260 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0260 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0260] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0261 / 1000 | Batch: 0001 / 0004 | Loss: 0.4926\n",
            "[Train] | Epoch: 0261 / 1000 | Batch: 0002 / 0004 | Loss: 0.4957\n",
            "[Train] | Epoch: 0261 / 1000 | Batch: 0003 / 0004 | Loss: 0.4982\n",
            "[Train] | Epoch: 0261 / 1000 | Batch: 0004 / 0004 | Loss: 0.4953\n",
            "[Validation] | Epoch: 0261 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0261 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0261] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0262 / 1000 | Batch: 0001 / 0004 | Loss: 0.4930\n",
            "[Train] | Epoch: 0262 / 1000 | Batch: 0002 / 0004 | Loss: 0.4953\n",
            "[Train] | Epoch: 0262 / 1000 | Batch: 0003 / 0004 | Loss: 0.5006\n",
            "[Train] | Epoch: 0262 / 1000 | Batch: 0004 / 0004 | Loss: 0.4936\n",
            "[Validation] | Epoch: 0262 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0262 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0262] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0263 / 1000 | Batch: 0001 / 0004 | Loss: 0.4888\n",
            "[Train] | Epoch: 0263 / 1000 | Batch: 0002 / 0004 | Loss: 0.4887\n",
            "[Train] | Epoch: 0263 / 1000 | Batch: 0003 / 0004 | Loss: 0.4980\n",
            "[Train] | Epoch: 0263 / 1000 | Batch: 0004 / 0004 | Loss: 0.5139\n",
            "[Validation] | Epoch: 0263 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0263 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0263] Training Avg Loss: 0.4973 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0264 / 1000 | Batch: 0001 / 0004 | Loss: 0.5010\n",
            "[Train] | Epoch: 0264 / 1000 | Batch: 0002 / 0004 | Loss: 0.4887\n",
            "[Train] | Epoch: 0264 / 1000 | Batch: 0003 / 0004 | Loss: 0.5051\n",
            "[Train] | Epoch: 0264 / 1000 | Batch: 0004 / 0004 | Loss: 0.4860\n",
            "[Validation] | Epoch: 0264 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0264 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0264] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0265 / 1000 | Batch: 0001 / 0004 | Loss: 0.4898\n",
            "[Train] | Epoch: 0265 / 1000 | Batch: 0002 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0265 / 1000 | Batch: 0003 / 0004 | Loss: 0.4969\n",
            "[Train] | Epoch: 0265 / 1000 | Batch: 0004 / 0004 | Loss: 0.5021\n",
            "[Validation] | Epoch: 0265 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0265 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0265] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0266 / 1000 | Batch: 0001 / 0004 | Loss: 0.4930\n",
            "[Train] | Epoch: 0266 / 1000 | Batch: 0002 / 0004 | Loss: 0.4898\n",
            "[Train] | Epoch: 0266 / 1000 | Batch: 0003 / 0004 | Loss: 0.4939\n",
            "[Train] | Epoch: 0266 / 1000 | Batch: 0004 / 0004 | Loss: 0.5105\n",
            "[Validation] | Epoch: 0266 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0266 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0266] Training Avg Loss: 0.4968 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0267 / 1000 | Batch: 0001 / 0004 | Loss: 0.5009\n",
            "[Train] | Epoch: 0267 / 1000 | Batch: 0002 / 0004 | Loss: 0.4952\n",
            "[Train] | Epoch: 0267 / 1000 | Batch: 0003 / 0004 | Loss: 0.4958\n",
            "[Train] | Epoch: 0267 / 1000 | Batch: 0004 / 0004 | Loss: 0.4880\n",
            "[Validation] | Epoch: 0267 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0267 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0267] Training Avg Loss: 0.4950 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0268 / 1000 | Batch: 0001 / 0004 | Loss: 0.4924\n",
            "[Train] | Epoch: 0268 / 1000 | Batch: 0002 / 0004 | Loss: 0.4916\n",
            "[Train] | Epoch: 0268 / 1000 | Batch: 0003 / 0004 | Loss: 0.5000\n",
            "[Train] | Epoch: 0268 / 1000 | Batch: 0004 / 0004 | Loss: 0.4997\n",
            "[Validation] | Epoch: 0268 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0268 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0268] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0269 / 1000 | Batch: 0001 / 0004 | Loss: 0.4883\n",
            "[Train] | Epoch: 0269 / 1000 | Batch: 0002 / 0004 | Loss: 0.4998\n",
            "[Train] | Epoch: 0269 / 1000 | Batch: 0003 / 0004 | Loss: 0.5033\n",
            "[Train] | Epoch: 0269 / 1000 | Batch: 0004 / 0004 | Loss: 0.4884\n",
            "[Validation] | Epoch: 0269 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0269 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0269] Training Avg Loss: 0.4950 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0270 / 1000 | Batch: 0001 / 0004 | Loss: 0.4977\n",
            "[Train] | Epoch: 0270 / 1000 | Batch: 0002 / 0004 | Loss: 0.4896\n",
            "[Train] | Epoch: 0270 / 1000 | Batch: 0003 / 0004 | Loss: 0.4941\n",
            "[Train] | Epoch: 0270 / 1000 | Batch: 0004 / 0004 | Loss: 0.5062\n",
            "[Validation] | Epoch: 0270 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0270 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0270] Training Avg Loss: 0.4969 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0271 / 1000 | Batch: 0001 / 0004 | Loss: 0.5028\n",
            "[Train] | Epoch: 0271 / 1000 | Batch: 0002 / 0004 | Loss: 0.4958\n",
            "[Train] | Epoch: 0271 / 1000 | Batch: 0003 / 0004 | Loss: 0.4923\n",
            "[Train] | Epoch: 0271 / 1000 | Batch: 0004 / 0004 | Loss: 0.4888\n",
            "[Validation] | Epoch: 0271 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0271 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0271] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0272 / 1000 | Batch: 0001 / 0004 | Loss: 0.4953\n",
            "[Train] | Epoch: 0272 / 1000 | Batch: 0002 / 0004 | Loss: 0.4889\n",
            "[Train] | Epoch: 0272 / 1000 | Batch: 0003 / 0004 | Loss: 0.5026\n",
            "[Train] | Epoch: 0272 / 1000 | Batch: 0004 / 0004 | Loss: 0.4947\n",
            "[Validation] | Epoch: 0272 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0272 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0272] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0273 / 1000 | Batch: 0001 / 0004 | Loss: 0.4856\n",
            "[Train] | Epoch: 0273 / 1000 | Batch: 0002 / 0004 | Loss: 0.5040\n",
            "[Train] | Epoch: 0273 / 1000 | Batch: 0003 / 0004 | Loss: 0.4920\n",
            "[Train] | Epoch: 0273 / 1000 | Batch: 0004 / 0004 | Loss: 0.4992\n",
            "[Validation] | Epoch: 0273 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0273 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0273] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0274 / 1000 | Batch: 0001 / 0004 | Loss: 0.4936\n",
            "[Train] | Epoch: 0274 / 1000 | Batch: 0002 / 0004 | Loss: 0.4927\n",
            "[Train] | Epoch: 0274 / 1000 | Batch: 0003 / 0004 | Loss: 0.5042\n",
            "[Train] | Epoch: 0274 / 1000 | Batch: 0004 / 0004 | Loss: 0.4910\n",
            "[Validation] | Epoch: 0274 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0274 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0274] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0275 / 1000 | Batch: 0001 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0275 / 1000 | Batch: 0002 / 0004 | Loss: 0.4918\n",
            "[Train] | Epoch: 0275 / 1000 | Batch: 0003 / 0004 | Loss: 0.5021\n",
            "[Train] | Epoch: 0275 / 1000 | Batch: 0004 / 0004 | Loss: 0.4926\n",
            "[Validation] | Epoch: 0275 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0275 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0275] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0276 / 1000 | Batch: 0001 / 0004 | Loss: 0.4884\n",
            "[Train] | Epoch: 0276 / 1000 | Batch: 0002 / 0004 | Loss: 0.4988\n",
            "[Train] | Epoch: 0276 / 1000 | Batch: 0003 / 0004 | Loss: 0.4946\n",
            "[Train] | Epoch: 0276 / 1000 | Batch: 0004 / 0004 | Loss: 0.5030\n",
            "[Validation] | Epoch: 0276 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0276 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0276] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0277 / 1000 | Batch: 0001 / 0004 | Loss: 0.4981\n",
            "[Train] | Epoch: 0277 / 1000 | Batch: 0002 / 0004 | Loss: 0.4922\n",
            "[Train] | Epoch: 0277 / 1000 | Batch: 0003 / 0004 | Loss: 0.5008\n",
            "[Train] | Epoch: 0277 / 1000 | Batch: 0004 / 0004 | Loss: 0.4882\n",
            "[Validation] | Epoch: 0277 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0277 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0277] Training Avg Loss: 0.4948 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0278 / 1000 | Batch: 0001 / 0004 | Loss: 0.4988\n",
            "[Train] | Epoch: 0278 / 1000 | Batch: 0002 / 0004 | Loss: 0.4946\n",
            "[Train] | Epoch: 0278 / 1000 | Batch: 0003 / 0004 | Loss: 0.4920\n",
            "[Train] | Epoch: 0278 / 1000 | Batch: 0004 / 0004 | Loss: 0.4957\n",
            "[Validation] | Epoch: 0278 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0278 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0278] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0279 / 1000 | Batch: 0001 / 0004 | Loss: 0.4976\n",
            "[Train] | Epoch: 0279 / 1000 | Batch: 0002 / 0004 | Loss: 0.4940\n",
            "[Train] | Epoch: 0279 / 1000 | Batch: 0003 / 0004 | Loss: 0.4941\n",
            "[Train] | Epoch: 0279 / 1000 | Batch: 0004 / 0004 | Loss: 0.4972\n",
            "[Validation] | Epoch: 0279 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0279 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0279] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0280 / 1000 | Batch: 0001 / 0004 | Loss: 0.5005\n",
            "[Train] | Epoch: 0280 / 1000 | Batch: 0002 / 0004 | Loss: 0.5000\n",
            "[Train] | Epoch: 0280 / 1000 | Batch: 0003 / 0004 | Loss: 0.4940\n",
            "[Train] | Epoch: 0280 / 1000 | Batch: 0004 / 0004 | Loss: 0.4862\n",
            "[Validation] | Epoch: 0280 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0280 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0280] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0281 / 1000 | Batch: 0001 / 0004 | Loss: 0.4970\n",
            "[Train] | Epoch: 0281 / 1000 | Batch: 0002 / 0004 | Loss: 0.4961\n",
            "[Train] | Epoch: 0281 / 1000 | Batch: 0003 / 0004 | Loss: 0.4933\n",
            "[Train] | Epoch: 0281 / 1000 | Batch: 0004 / 0004 | Loss: 0.4955\n",
            "[Validation] | Epoch: 0281 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0281 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0281] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0282 / 1000 | Batch: 0001 / 0004 | Loss: 0.4981\n",
            "[Train] | Epoch: 0282 / 1000 | Batch: 0002 / 0004 | Loss: 0.5031\n",
            "[Train] | Epoch: 0282 / 1000 | Batch: 0003 / 0004 | Loss: 0.4918\n",
            "[Train] | Epoch: 0282 / 1000 | Batch: 0004 / 0004 | Loss: 0.4872\n",
            "[Validation] | Epoch: 0282 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0282 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0282] Training Avg Loss: 0.4950 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0283 / 1000 | Batch: 0001 / 0004 | Loss: 0.4920\n",
            "[Train] | Epoch: 0283 / 1000 | Batch: 0002 / 0004 | Loss: 0.4971\n",
            "[Train] | Epoch: 0283 / 1000 | Batch: 0003 / 0004 | Loss: 0.5005\n",
            "[Train] | Epoch: 0283 / 1000 | Batch: 0004 / 0004 | Loss: 0.4914\n",
            "[Validation] | Epoch: 0283 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0283 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0283] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0284 / 1000 | Batch: 0001 / 0004 | Loss: 0.4917\n",
            "[Train] | Epoch: 0284 / 1000 | Batch: 0002 / 0004 | Loss: 0.5005\n",
            "[Train] | Epoch: 0284 / 1000 | Batch: 0003 / 0004 | Loss: 0.5012\n",
            "[Train] | Epoch: 0284 / 1000 | Batch: 0004 / 0004 | Loss: 0.4864\n",
            "[Validation] | Epoch: 0284 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0284 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0284] Training Avg Loss: 0.4950 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0285 / 1000 | Batch: 0001 / 0004 | Loss: 0.4943\n",
            "[Train] | Epoch: 0285 / 1000 | Batch: 0002 / 0004 | Loss: 0.5034\n",
            "[Train] | Epoch: 0285 / 1000 | Batch: 0003 / 0004 | Loss: 0.4914\n",
            "[Train] | Epoch: 0285 / 1000 | Batch: 0004 / 0004 | Loss: 0.4926\n",
            "[Validation] | Epoch: 0285 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0285 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0285] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0286 / 1000 | Batch: 0001 / 0004 | Loss: 0.4937\n",
            "[Train] | Epoch: 0286 / 1000 | Batch: 0002 / 0004 | Loss: 0.5008\n",
            "[Train] | Epoch: 0286 / 1000 | Batch: 0003 / 0004 | Loss: 0.4925\n",
            "[Train] | Epoch: 0286 / 1000 | Batch: 0004 / 0004 | Loss: 0.4957\n",
            "[Validation] | Epoch: 0286 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0286 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0286] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0287 / 1000 | Batch: 0001 / 0004 | Loss: 0.4993\n",
            "[Train] | Epoch: 0287 / 1000 | Batch: 0002 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0287 / 1000 | Batch: 0003 / 0004 | Loss: 0.4935\n",
            "[Train] | Epoch: 0287 / 1000 | Batch: 0004 / 0004 | Loss: 0.4951\n",
            "[Validation] | Epoch: 0287 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0287 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0287] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0288 / 1000 | Batch: 0001 / 0004 | Loss: 0.5027\n",
            "[Train] | Epoch: 0288 / 1000 | Batch: 0002 / 0004 | Loss: 0.4995\n",
            "[Train] | Epoch: 0288 / 1000 | Batch: 0003 / 0004 | Loss: 0.4868\n",
            "[Train] | Epoch: 0288 / 1000 | Batch: 0004 / 0004 | Loss: 0.4917\n",
            "[Validation] | Epoch: 0288 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0288 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0288] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0289 / 1000 | Batch: 0001 / 0004 | Loss: 0.4999\n",
            "[Train] | Epoch: 0289 / 1000 | Batch: 0002 / 0004 | Loss: 0.4890\n",
            "[Train] | Epoch: 0289 / 1000 | Batch: 0003 / 0004 | Loss: 0.5045\n",
            "[Train] | Epoch: 0289 / 1000 | Batch: 0004 / 0004 | Loss: 0.4884\n",
            "[Validation] | Epoch: 0289 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0289 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0289] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4969\n",
            "[Train] | Epoch: 0290 / 1000 | Batch: 0001 / 0004 | Loss: 0.4948\n",
            "[Train] | Epoch: 0290 / 1000 | Batch: 0002 / 0004 | Loss: 0.4940\n",
            "[Train] | Epoch: 0290 / 1000 | Batch: 0003 / 0004 | Loss: 0.4977\n",
            "[Train] | Epoch: 0290 / 1000 | Batch: 0004 / 0004 | Loss: 0.4948\n",
            "[Validation] | Epoch: 0290 / 1000 | Batch: 0001 / 0002 | Loss: 0.5077\n",
            "[Validation] | Epoch: 0290 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0290] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4970\n",
            "[Train] | Epoch: 0291 / 1000 | Batch: 0001 / 0004 | Loss: 0.5037\n",
            "[Train] | Epoch: 0291 / 1000 | Batch: 0002 / 0004 | Loss: 0.4979\n",
            "[Train] | Epoch: 0291 / 1000 | Batch: 0003 / 0004 | Loss: 0.4925\n",
            "[Train] | Epoch: 0291 / 1000 | Batch: 0004 / 0004 | Loss: 0.4877\n",
            "[Validation] | Epoch: 0291 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0291 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0291] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4969\n",
            "[Train] | Epoch: 0292 / 1000 | Batch: 0001 / 0004 | Loss: 0.4937\n",
            "[Train] | Epoch: 0292 / 1000 | Batch: 0002 / 0004 | Loss: 0.5002\n",
            "[Train] | Epoch: 0292 / 1000 | Batch: 0003 / 0004 | Loss: 0.4933\n",
            "[Train] | Epoch: 0292 / 1000 | Batch: 0004 / 0004 | Loss: 0.4960\n",
            "[Validation] | Epoch: 0292 / 1000 | Batch: 0001 / 0002 | Loss: 0.5077\n",
            "[Validation] | Epoch: 0292 / 1000 | Batch: 0002 / 0002 | Loss: 0.4863\n",
            "[Epoch 0292] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4970\n",
            "[Train] | Epoch: 0293 / 1000 | Batch: 0001 / 0004 | Loss: 0.4989\n",
            "[Train] | Epoch: 0293 / 1000 | Batch: 0002 / 0004 | Loss: 0.4886\n",
            "[Train] | Epoch: 0293 / 1000 | Batch: 0003 / 0004 | Loss: 0.4936\n",
            "[Train] | Epoch: 0293 / 1000 | Batch: 0004 / 0004 | Loss: 0.5037\n",
            "[Validation] | Epoch: 0293 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0293 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0293] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0294 / 1000 | Batch: 0001 / 0004 | Loss: 0.4891\n",
            "[Train] | Epoch: 0294 / 1000 | Batch: 0002 / 0004 | Loss: 0.4892\n",
            "[Train] | Epoch: 0294 / 1000 | Batch: 0003 / 0004 | Loss: 0.4984\n",
            "[Train] | Epoch: 0294 / 1000 | Batch: 0004 / 0004 | Loss: 0.5094\n",
            "[Validation] | Epoch: 0294 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0294 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0294] Training Avg Loss: 0.4965 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0295 / 1000 | Batch: 0001 / 0004 | Loss: 0.5015\n",
            "[Train] | Epoch: 0295 / 1000 | Batch: 0002 / 0004 | Loss: 0.4938\n",
            "[Train] | Epoch: 0295 / 1000 | Batch: 0003 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0295 / 1000 | Batch: 0004 / 0004 | Loss: 0.4918\n",
            "[Validation] | Epoch: 0295 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0295 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0295] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0296 / 1000 | Batch: 0001 / 0004 | Loss: 0.4995\n",
            "[Train] | Epoch: 0296 / 1000 | Batch: 0002 / 0004 | Loss: 0.4909\n",
            "[Train] | Epoch: 0296 / 1000 | Batch: 0003 / 0004 | Loss: 0.5010\n",
            "[Train] | Epoch: 0296 / 1000 | Batch: 0004 / 0004 | Loss: 0.4908\n",
            "[Validation] | Epoch: 0296 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0296 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0296] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0297 / 1000 | Batch: 0001 / 0004 | Loss: 0.4872\n",
            "[Train] | Epoch: 0297 / 1000 | Batch: 0002 / 0004 | Loss: 0.4937\n",
            "[Train] | Epoch: 0297 / 1000 | Batch: 0003 / 0004 | Loss: 0.4938\n",
            "[Train] | Epoch: 0297 / 1000 | Batch: 0004 / 0004 | Loss: 0.5129\n",
            "[Validation] | Epoch: 0297 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0297 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0297] Training Avg Loss: 0.4969 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0298 / 1000 | Batch: 0001 / 0004 | Loss: 0.5045\n",
            "[Train] | Epoch: 0298 / 1000 | Batch: 0002 / 0004 | Loss: 0.4982\n",
            "[Train] | Epoch: 0298 / 1000 | Batch: 0003 / 0004 | Loss: 0.4903\n",
            "[Train] | Epoch: 0298 / 1000 | Batch: 0004 / 0004 | Loss: 0.4874\n",
            "[Validation] | Epoch: 0298 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0298 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0298] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0299 / 1000 | Batch: 0001 / 0004 | Loss: 0.5007\n",
            "[Train] | Epoch: 0299 / 1000 | Batch: 0002 / 0004 | Loss: 0.4891\n",
            "[Train] | Epoch: 0299 / 1000 | Batch: 0003 / 0004 | Loss: 0.4924\n",
            "[Train] | Epoch: 0299 / 1000 | Batch: 0004 / 0004 | Loss: 0.5026\n",
            "[Validation] | Epoch: 0299 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0299 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0299] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0300 / 1000 | Batch: 0001 / 0004 | Loss: 0.4976\n",
            "[Train] | Epoch: 0300 / 1000 | Batch: 0002 / 0004 | Loss: 0.4932\n",
            "[Train] | Epoch: 0300 / 1000 | Batch: 0003 / 0004 | Loss: 0.4953\n",
            "[Train] | Epoch: 0300 / 1000 | Batch: 0004 / 0004 | Loss: 0.4988\n",
            "[Validation] | Epoch: 0300 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0300 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0300] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0301 / 1000 | Batch: 0001 / 0004 | Loss: 0.4973\n",
            "[Train] | Epoch: 0301 / 1000 | Batch: 0002 / 0004 | Loss: 0.4943\n",
            "[Train] | Epoch: 0301 / 1000 | Batch: 0003 / 0004 | Loss: 0.4912\n",
            "[Train] | Epoch: 0301 / 1000 | Batch: 0004 / 0004 | Loss: 0.4999\n",
            "[Validation] | Epoch: 0301 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0301 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0301] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0302 / 1000 | Batch: 0001 / 0004 | Loss: 0.4865\n",
            "[Train] | Epoch: 0302 / 1000 | Batch: 0002 / 0004 | Loss: 0.5071\n",
            "[Train] | Epoch: 0302 / 1000 | Batch: 0003 / 0004 | Loss: 0.4830\n",
            "[Train] | Epoch: 0302 / 1000 | Batch: 0004 / 0004 | Loss: 0.5097\n",
            "[Validation] | Epoch: 0302 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0302 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0302] Training Avg Loss: 0.4966 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0303 / 1000 | Batch: 0001 / 0004 | Loss: 0.5002\n",
            "[Train] | Epoch: 0303 / 1000 | Batch: 0002 / 0004 | Loss: 0.4902\n",
            "[Train] | Epoch: 0303 / 1000 | Batch: 0003 / 0004 | Loss: 0.5035\n",
            "[Train] | Epoch: 0303 / 1000 | Batch: 0004 / 0004 | Loss: 0.4856\n",
            "[Validation] | Epoch: 0303 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0303 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0303] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0304 / 1000 | Batch: 0001 / 0004 | Loss: 0.5038\n",
            "[Train] | Epoch: 0304 / 1000 | Batch: 0002 / 0004 | Loss: 0.4923\n",
            "[Train] | Epoch: 0304 / 1000 | Batch: 0003 / 0004 | Loss: 0.4986\n",
            "[Train] | Epoch: 0304 / 1000 | Batch: 0004 / 0004 | Loss: 0.4861\n",
            "[Validation] | Epoch: 0304 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0304 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0304] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0305 / 1000 | Batch: 0001 / 0004 | Loss: 0.4891\n",
            "[Train] | Epoch: 0305 / 1000 | Batch: 0002 / 0004 | Loss: 0.4942\n",
            "[Train] | Epoch: 0305 / 1000 | Batch: 0003 / 0004 | Loss: 0.4953\n",
            "[Train] | Epoch: 0305 / 1000 | Batch: 0004 / 0004 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0305 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0305 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0305] Training Avg Loss: 0.4965 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0306 / 1000 | Batch: 0001 / 0004 | Loss: 0.4996\n",
            "[Train] | Epoch: 0306 / 1000 | Batch: 0002 / 0004 | Loss: 0.4956\n",
            "[Train] | Epoch: 0306 / 1000 | Batch: 0003 / 0004 | Loss: 0.4980\n",
            "[Train] | Epoch: 0306 / 1000 | Batch: 0004 / 0004 | Loss: 0.4869\n",
            "[Validation] | Epoch: 0306 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0306 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0306] Training Avg Loss: 0.4950 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0307 / 1000 | Batch: 0001 / 0004 | Loss: 0.4868\n",
            "[Train] | Epoch: 0307 / 1000 | Batch: 0002 / 0004 | Loss: 0.4965\n",
            "[Train] | Epoch: 0307 / 1000 | Batch: 0003 / 0004 | Loss: 0.4955\n",
            "[Train] | Epoch: 0307 / 1000 | Batch: 0004 / 0004 | Loss: 0.5102\n",
            "[Validation] | Epoch: 0307 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0307 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0307] Training Avg Loss: 0.4973 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0308 / 1000 | Batch: 0001 / 0004 | Loss: 0.4991\n",
            "[Train] | Epoch: 0308 / 1000 | Batch: 0002 / 0004 | Loss: 0.4993\n",
            "[Train] | Epoch: 0308 / 1000 | Batch: 0003 / 0004 | Loss: 0.4900\n",
            "[Train] | Epoch: 0308 / 1000 | Batch: 0004 / 0004 | Loss: 0.4921\n",
            "[Validation] | Epoch: 0308 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0308 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0308] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0309 / 1000 | Batch: 0001 / 0004 | Loss: 0.5042\n",
            "[Train] | Epoch: 0309 / 1000 | Batch: 0002 / 0004 | Loss: 0.4904\n",
            "[Train] | Epoch: 0309 / 1000 | Batch: 0003 / 0004 | Loss: 0.4996\n",
            "[Train] | Epoch: 0309 / 1000 | Batch: 0004 / 0004 | Loss: 0.4874\n",
            "[Validation] | Epoch: 0309 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0309 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0309] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0310 / 1000 | Batch: 0001 / 0004 | Loss: 0.4922\n",
            "[Train] | Epoch: 0310 / 1000 | Batch: 0002 / 0004 | Loss: 0.4929\n",
            "[Train] | Epoch: 0310 / 1000 | Batch: 0003 / 0004 | Loss: 0.5008\n",
            "[Train] | Epoch: 0310 / 1000 | Batch: 0004 / 0004 | Loss: 0.4965\n",
            "[Validation] | Epoch: 0310 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0310 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0310] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0311 / 1000 | Batch: 0001 / 0004 | Loss: 0.5046\n",
            "[Train] | Epoch: 0311 / 1000 | Batch: 0002 / 0004 | Loss: 0.4931\n",
            "[Train] | Epoch: 0311 / 1000 | Batch: 0003 / 0004 | Loss: 0.4878\n",
            "[Train] | Epoch: 0311 / 1000 | Batch: 0004 / 0004 | Loss: 0.4973\n",
            "[Validation] | Epoch: 0311 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0311 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0311] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0312 / 1000 | Batch: 0001 / 0004 | Loss: 0.4934\n",
            "[Train] | Epoch: 0312 / 1000 | Batch: 0002 / 0004 | Loss: 0.4962\n",
            "[Train] | Epoch: 0312 / 1000 | Batch: 0003 / 0004 | Loss: 0.4916\n",
            "[Train] | Epoch: 0312 / 1000 | Batch: 0004 / 0004 | Loss: 0.5029\n",
            "[Validation] | Epoch: 0312 / 1000 | Batch: 0001 / 0002 | Loss: 0.5071\n",
            "[Validation] | Epoch: 0312 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0312] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4962\n",
            "[Train] | Epoch: 0313 / 1000 | Batch: 0001 / 0004 | Loss: 0.5070\n",
            "[Train] | Epoch: 0313 / 1000 | Batch: 0002 / 0004 | Loss: 0.4872\n",
            "[Train] | Epoch: 0313 / 1000 | Batch: 0003 / 0004 | Loss: 0.4913\n",
            "[Train] | Epoch: 0313 / 1000 | Batch: 0004 / 0004 | Loss: 0.4959\n",
            "[Validation] | Epoch: 0313 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0313 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0313] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0314 / 1000 | Batch: 0001 / 0004 | Loss: 0.5006\n",
            "[Train] | Epoch: 0314 / 1000 | Batch: 0002 / 0004 | Loss: 0.4899\n",
            "[Train] | Epoch: 0314 / 1000 | Batch: 0003 / 0004 | Loss: 0.4922\n",
            "[Train] | Epoch: 0314 / 1000 | Batch: 0004 / 0004 | Loss: 0.5028\n",
            "[Validation] | Epoch: 0314 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0314 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0314] Training Avg Loss: 0.4963 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0315 / 1000 | Batch: 0001 / 0004 | Loss: 0.4920\n",
            "[Train] | Epoch: 0315 / 1000 | Batch: 0002 / 0004 | Loss: 0.4932\n",
            "[Train] | Epoch: 0315 / 1000 | Batch: 0003 / 0004 | Loss: 0.5082\n",
            "[Train] | Epoch: 0315 / 1000 | Batch: 0004 / 0004 | Loss: 0.4860\n",
            "[Validation] | Epoch: 0315 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0315 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0315] Training Avg Loss: 0.4948 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0316 / 1000 | Batch: 0001 / 0004 | Loss: 0.4965\n",
            "[Train] | Epoch: 0316 / 1000 | Batch: 0002 / 0004 | Loss: 0.4879\n",
            "[Train] | Epoch: 0316 / 1000 | Batch: 0003 / 0004 | Loss: 0.4984\n",
            "[Train] | Epoch: 0316 / 1000 | Batch: 0004 / 0004 | Loss: 0.4993\n",
            "[Validation] | Epoch: 0316 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0316 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0316] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0317 / 1000 | Batch: 0001 / 0004 | Loss: 0.4973\n",
            "[Train] | Epoch: 0317 / 1000 | Batch: 0002 / 0004 | Loss: 0.4932\n",
            "[Train] | Epoch: 0317 / 1000 | Batch: 0003 / 0004 | Loss: 0.4922\n",
            "[Train] | Epoch: 0317 / 1000 | Batch: 0004 / 0004 | Loss: 0.5011\n",
            "[Validation] | Epoch: 0317 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0317 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0317] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0318 / 1000 | Batch: 0001 / 0004 | Loss: 0.4904\n",
            "[Train] | Epoch: 0318 / 1000 | Batch: 0002 / 0004 | Loss: 0.4997\n",
            "[Train] | Epoch: 0318 / 1000 | Batch: 0003 / 0004 | Loss: 0.4906\n",
            "[Train] | Epoch: 0318 / 1000 | Batch: 0004 / 0004 | Loss: 0.5035\n",
            "[Validation] | Epoch: 0318 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0318 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0318] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0319 / 1000 | Batch: 0001 / 0004 | Loss: 0.5016\n",
            "[Train] | Epoch: 0319 / 1000 | Batch: 0002 / 0004 | Loss: 0.4955\n",
            "[Train] | Epoch: 0319 / 1000 | Batch: 0003 / 0004 | Loss: 0.4918\n",
            "[Train] | Epoch: 0319 / 1000 | Batch: 0004 / 0004 | Loss: 0.4933\n",
            "[Validation] | Epoch: 0319 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0319 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0319] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0320 / 1000 | Batch: 0001 / 0004 | Loss: 0.4978\n",
            "[Train] | Epoch: 0320 / 1000 | Batch: 0002 / 0004 | Loss: 0.4958\n",
            "[Train] | Epoch: 0320 / 1000 | Batch: 0003 / 0004 | Loss: 0.4950\n",
            "[Train] | Epoch: 0320 / 1000 | Batch: 0004 / 0004 | Loss: 0.4922\n",
            "[Validation] | Epoch: 0320 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0320 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0320] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0321 / 1000 | Batch: 0001 / 0004 | Loss: 0.4950\n",
            "[Train] | Epoch: 0321 / 1000 | Batch: 0002 / 0004 | Loss: 0.4930\n",
            "[Train] | Epoch: 0321 / 1000 | Batch: 0003 / 0004 | Loss: 0.5027\n",
            "[Train] | Epoch: 0321 / 1000 | Batch: 0004 / 0004 | Loss: 0.4902\n",
            "[Validation] | Epoch: 0321 / 1000 | Batch: 0001 / 0002 | Loss: 0.5077\n",
            "[Validation] | Epoch: 0321 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0321] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4970\n",
            "[Train] | Epoch: 0322 / 1000 | Batch: 0001 / 0004 | Loss: 0.4925\n",
            "[Train] | Epoch: 0322 / 1000 | Batch: 0002 / 0004 | Loss: 0.5036\n",
            "[Train] | Epoch: 0322 / 1000 | Batch: 0003 / 0004 | Loss: 0.4990\n",
            "[Train] | Epoch: 0322 / 1000 | Batch: 0004 / 0004 | Loss: 0.4834\n",
            "[Validation] | Epoch: 0322 / 1000 | Batch: 0001 / 0002 | Loss: 0.5078\n",
            "[Validation] | Epoch: 0322 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0322] Training Avg Loss: 0.4946 | Validation Avg Loss: 0.4970\n",
            "[Train] | Epoch: 0323 / 1000 | Batch: 0001 / 0004 | Loss: 0.4913\n",
            "[Train] | Epoch: 0323 / 1000 | Batch: 0002 / 0004 | Loss: 0.4962\n",
            "[Train] | Epoch: 0323 / 1000 | Batch: 0003 / 0004 | Loss: 0.5037\n",
            "[Train] | Epoch: 0323 / 1000 | Batch: 0004 / 0004 | Loss: 0.4928\n",
            "[Validation] | Epoch: 0323 / 1000 | Batch: 0001 / 0002 | Loss: 0.5077\n",
            "[Validation] | Epoch: 0323 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0323] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4969\n",
            "[Train] | Epoch: 0324 / 1000 | Batch: 0001 / 0004 | Loss: 0.4956\n",
            "[Train] | Epoch: 0324 / 1000 | Batch: 0002 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0324 / 1000 | Batch: 0003 / 0004 | Loss: 0.4953\n",
            "[Train] | Epoch: 0324 / 1000 | Batch: 0004 / 0004 | Loss: 0.4974\n",
            "[Validation] | Epoch: 0324 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0324 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0324] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0325 / 1000 | Batch: 0001 / 0004 | Loss: 0.4926\n",
            "[Train] | Epoch: 0325 / 1000 | Batch: 0002 / 0004 | Loss: 0.4997\n",
            "[Train] | Epoch: 0325 / 1000 | Batch: 0003 / 0004 | Loss: 0.4958\n",
            "[Train] | Epoch: 0325 / 1000 | Batch: 0004 / 0004 | Loss: 0.4936\n",
            "[Validation] | Epoch: 0325 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0325 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0325] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0326 / 1000 | Batch: 0001 / 0004 | Loss: 0.4989\n",
            "[Train] | Epoch: 0326 / 1000 | Batch: 0002 / 0004 | Loss: 0.4980\n",
            "[Train] | Epoch: 0326 / 1000 | Batch: 0003 / 0004 | Loss: 0.4880\n",
            "[Train] | Epoch: 0326 / 1000 | Batch: 0004 / 0004 | Loss: 0.4995\n",
            "[Validation] | Epoch: 0326 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0326 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0326] Training Avg Loss: 0.4961 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0327 / 1000 | Batch: 0001 / 0004 | Loss: 0.4960\n",
            "[Train] | Epoch: 0327 / 1000 | Batch: 0002 / 0004 | Loss: 0.4975\n",
            "[Train] | Epoch: 0327 / 1000 | Batch: 0003 / 0004 | Loss: 0.4992\n",
            "[Train] | Epoch: 0327 / 1000 | Batch: 0004 / 0004 | Loss: 0.4904\n",
            "[Validation] | Epoch: 0327 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0327 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0327] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0328 / 1000 | Batch: 0001 / 0004 | Loss: 0.4986\n",
            "[Train] | Epoch: 0328 / 1000 | Batch: 0002 / 0004 | Loss: 0.4914\n",
            "[Train] | Epoch: 0328 / 1000 | Batch: 0003 / 0004 | Loss: 0.4947\n",
            "[Train] | Epoch: 0328 / 1000 | Batch: 0004 / 0004 | Loss: 0.4971\n",
            "[Validation] | Epoch: 0328 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0328 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0328] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0329 / 1000 | Batch: 0001 / 0004 | Loss: 0.5009\n",
            "[Train] | Epoch: 0329 / 1000 | Batch: 0002 / 0004 | Loss: 0.4887\n",
            "[Train] | Epoch: 0329 / 1000 | Batch: 0003 / 0004 | Loss: 0.4958\n",
            "[Train] | Epoch: 0329 / 1000 | Batch: 0004 / 0004 | Loss: 0.4964\n",
            "[Validation] | Epoch: 0329 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0329 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0329] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0330 / 1000 | Batch: 0001 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0330 / 1000 | Batch: 0002 / 0004 | Loss: 0.5001\n",
            "[Train] | Epoch: 0330 / 1000 | Batch: 0003 / 0004 | Loss: 0.4823\n",
            "[Train] | Epoch: 0330 / 1000 | Batch: 0004 / 0004 | Loss: 0.5087\n",
            "[Validation] | Epoch: 0330 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0330 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0330] Training Avg Loss: 0.4965 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0331 / 1000 | Batch: 0001 / 0004 | Loss: 0.4965\n",
            "[Train] | Epoch: 0331 / 1000 | Batch: 0002 / 0004 | Loss: 0.4991\n",
            "[Train] | Epoch: 0331 / 1000 | Batch: 0003 / 0004 | Loss: 0.4863\n",
            "[Train] | Epoch: 0331 / 1000 | Batch: 0004 / 0004 | Loss: 0.5016\n",
            "[Validation] | Epoch: 0331 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0331 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0331] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0332 / 1000 | Batch: 0001 / 0004 | Loss: 0.4935\n",
            "[Train] | Epoch: 0332 / 1000 | Batch: 0002 / 0004 | Loss: 0.4961\n",
            "[Train] | Epoch: 0332 / 1000 | Batch: 0003 / 0004 | Loss: 0.4915\n",
            "[Train] | Epoch: 0332 / 1000 | Batch: 0004 / 0004 | Loss: 0.5039\n",
            "[Validation] | Epoch: 0332 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0332 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0332] Training Avg Loss: 0.4963 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0333 / 1000 | Batch: 0001 / 0004 | Loss: 0.4935\n",
            "[Train] | Epoch: 0333 / 1000 | Batch: 0002 / 0004 | Loss: 0.4973\n",
            "[Train] | Epoch: 0333 / 1000 | Batch: 0003 / 0004 | Loss: 0.5024\n",
            "[Train] | Epoch: 0333 / 1000 | Batch: 0004 / 0004 | Loss: 0.4868\n",
            "[Validation] | Epoch: 0333 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0333 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0333] Training Avg Loss: 0.4950 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0334 / 1000 | Batch: 0001 / 0004 | Loss: 0.4993\n",
            "[Train] | Epoch: 0334 / 1000 | Batch: 0002 / 0004 | Loss: 0.4954\n",
            "[Train] | Epoch: 0334 / 1000 | Batch: 0003 / 0004 | Loss: 0.5016\n",
            "[Train] | Epoch: 0334 / 1000 | Batch: 0004 / 0004 | Loss: 0.4831\n",
            "[Validation] | Epoch: 0334 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0334 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0334] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0335 / 1000 | Batch: 0001 / 0004 | Loss: 0.4949\n",
            "[Train] | Epoch: 0335 / 1000 | Batch: 0002 / 0004 | Loss: 0.5011\n",
            "[Train] | Epoch: 0335 / 1000 | Batch: 0003 / 0004 | Loss: 0.4904\n",
            "[Train] | Epoch: 0335 / 1000 | Batch: 0004 / 0004 | Loss: 0.4959\n",
            "[Validation] | Epoch: 0335 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0335 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0335] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0336 / 1000 | Batch: 0001 / 0004 | Loss: 0.4902\n",
            "[Train] | Epoch: 0336 / 1000 | Batch: 0002 / 0004 | Loss: 0.4925\n",
            "[Train] | Epoch: 0336 / 1000 | Batch: 0003 / 0004 | Loss: 0.5048\n",
            "[Train] | Epoch: 0336 / 1000 | Batch: 0004 / 0004 | Loss: 0.4940\n",
            "[Validation] | Epoch: 0336 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0336 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0336] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0337 / 1000 | Batch: 0001 / 0004 | Loss: 0.4945\n",
            "[Train] | Epoch: 0337 / 1000 | Batch: 0002 / 0004 | Loss: 0.4993\n",
            "[Train] | Epoch: 0337 / 1000 | Batch: 0003 / 0004 | Loss: 0.4928\n",
            "[Train] | Epoch: 0337 / 1000 | Batch: 0004 / 0004 | Loss: 0.4932\n",
            "[Validation] | Epoch: 0337 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0337 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0337] Training Avg Loss: 0.4950 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0338 / 1000 | Batch: 0001 / 0004 | Loss: 0.4968\n",
            "[Train] | Epoch: 0338 / 1000 | Batch: 0002 / 0004 | Loss: 0.4961\n",
            "[Train] | Epoch: 0338 / 1000 | Batch: 0003 / 0004 | Loss: 0.4936\n",
            "[Train] | Epoch: 0338 / 1000 | Batch: 0004 / 0004 | Loss: 0.4923\n",
            "[Validation] | Epoch: 0338 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0338 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0338] Training Avg Loss: 0.4947 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0339 / 1000 | Batch: 0001 / 0004 | Loss: 0.4837\n",
            "[Train] | Epoch: 0339 / 1000 | Batch: 0002 / 0004 | Loss: 0.4980\n",
            "[Train] | Epoch: 0339 / 1000 | Batch: 0003 / 0004 | Loss: 0.5001\n",
            "[Train] | Epoch: 0339 / 1000 | Batch: 0004 / 0004 | Loss: 0.5000\n",
            "[Validation] | Epoch: 0339 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0339 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0339] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0340 / 1000 | Batch: 0001 / 0004 | Loss: 0.4917\n",
            "[Train] | Epoch: 0340 / 1000 | Batch: 0002 / 0004 | Loss: 0.4998\n",
            "[Train] | Epoch: 0340 / 1000 | Batch: 0003 / 0004 | Loss: 0.4900\n",
            "[Train] | Epoch: 0340 / 1000 | Batch: 0004 / 0004 | Loss: 0.4999\n",
            "[Validation] | Epoch: 0340 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0340 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0340] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0341 / 1000 | Batch: 0001 / 0004 | Loss: 0.4859\n",
            "[Train] | Epoch: 0341 / 1000 | Batch: 0002 / 0004 | Loss: 0.4939\n",
            "[Train] | Epoch: 0341 / 1000 | Batch: 0003 / 0004 | Loss: 0.5031\n",
            "[Train] | Epoch: 0341 / 1000 | Batch: 0004 / 0004 | Loss: 0.4994\n",
            "[Validation] | Epoch: 0341 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0341 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0341] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0342 / 1000 | Batch: 0001 / 0004 | Loss: 0.4898\n",
            "[Train] | Epoch: 0342 / 1000 | Batch: 0002 / 0004 | Loss: 0.4955\n",
            "[Train] | Epoch: 0342 / 1000 | Batch: 0003 / 0004 | Loss: 0.5022\n",
            "[Train] | Epoch: 0342 / 1000 | Batch: 0004 / 0004 | Loss: 0.4936\n",
            "[Validation] | Epoch: 0342 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0342 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0342] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0343 / 1000 | Batch: 0001 / 0004 | Loss: 0.4900\n",
            "[Train] | Epoch: 0343 / 1000 | Batch: 0002 / 0004 | Loss: 0.4949\n",
            "[Train] | Epoch: 0343 / 1000 | Batch: 0003 / 0004 | Loss: 0.4988\n",
            "[Train] | Epoch: 0343 / 1000 | Batch: 0004 / 0004 | Loss: 0.5001\n",
            "[Validation] | Epoch: 0343 / 1000 | Batch: 0001 / 0002 | Loss: 0.5071\n",
            "[Validation] | Epoch: 0343 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0343] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0344 / 1000 | Batch: 0001 / 0004 | Loss: 0.4939\n",
            "[Train] | Epoch: 0344 / 1000 | Batch: 0002 / 0004 | Loss: 0.4901\n",
            "[Train] | Epoch: 0344 / 1000 | Batch: 0003 / 0004 | Loss: 0.4974\n",
            "[Train] | Epoch: 0344 / 1000 | Batch: 0004 / 0004 | Loss: 0.5004\n",
            "[Validation] | Epoch: 0344 / 1000 | Batch: 0001 / 0002 | Loss: 0.5070\n",
            "[Validation] | Epoch: 0344 / 1000 | Batch: 0002 / 0002 | Loss: 0.4853\n",
            "[Epoch 0344] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4961\n",
            "[Train] | Epoch: 0345 / 1000 | Batch: 0001 / 0004 | Loss: 0.5015\n",
            "[Train] | Epoch: 0345 / 1000 | Batch: 0002 / 0004 | Loss: 0.4903\n",
            "[Train] | Epoch: 0345 / 1000 | Batch: 0003 / 0004 | Loss: 0.4875\n",
            "[Train] | Epoch: 0345 / 1000 | Batch: 0004 / 0004 | Loss: 0.5061\n",
            "[Validation] | Epoch: 0345 / 1000 | Batch: 0001 / 0002 | Loss: 0.5069\n",
            "[Validation] | Epoch: 0345 / 1000 | Batch: 0002 / 0002 | Loss: 0.4852\n",
            "[Epoch 0345] Training Avg Loss: 0.4964 | Validation Avg Loss: 0.4960\n",
            "[Train] | Epoch: 0346 / 1000 | Batch: 0001 / 0004 | Loss: 0.4908\n",
            "[Train] | Epoch: 0346 / 1000 | Batch: 0002 / 0004 | Loss: 0.4920\n",
            "[Train] | Epoch: 0346 / 1000 | Batch: 0003 / 0004 | Loss: 0.5039\n",
            "[Train] | Epoch: 0346 / 1000 | Batch: 0004 / 0004 | Loss: 0.4973\n",
            "[Validation] | Epoch: 0346 / 1000 | Batch: 0001 / 0002 | Loss: 0.5070\n",
            "[Validation] | Epoch: 0346 / 1000 | Batch: 0002 / 0002 | Loss: 0.4853\n",
            "[Epoch 0346] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4961\n",
            "[Train] | Epoch: 0347 / 1000 | Batch: 0001 / 0004 | Loss: 0.5000\n",
            "[Train] | Epoch: 0347 / 1000 | Batch: 0002 / 0004 | Loss: 0.4930\n",
            "[Train] | Epoch: 0347 / 1000 | Batch: 0003 / 0004 | Loss: 0.4987\n",
            "[Train] | Epoch: 0347 / 1000 | Batch: 0004 / 0004 | Loss: 0.4894\n",
            "[Validation] | Epoch: 0347 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0347 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0347] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0348 / 1000 | Batch: 0001 / 0004 | Loss: 0.4920\n",
            "[Train] | Epoch: 0348 / 1000 | Batch: 0002 / 0004 | Loss: 0.4961\n",
            "[Train] | Epoch: 0348 / 1000 | Batch: 0003 / 0004 | Loss: 0.4860\n",
            "[Train] | Epoch: 0348 / 1000 | Batch: 0004 / 0004 | Loss: 0.5111\n",
            "[Validation] | Epoch: 0348 / 1000 | Batch: 0001 / 0002 | Loss: 0.5070\n",
            "[Validation] | Epoch: 0348 / 1000 | Batch: 0002 / 0002 | Loss: 0.4853\n",
            "[Epoch 0348] Training Avg Loss: 0.4963 | Validation Avg Loss: 0.4962\n",
            "[Train] | Epoch: 0349 / 1000 | Batch: 0001 / 0004 | Loss: 0.5057\n",
            "[Train] | Epoch: 0349 / 1000 | Batch: 0002 / 0004 | Loss: 0.4914\n",
            "[Train] | Epoch: 0349 / 1000 | Batch: 0003 / 0004 | Loss: 0.4907\n",
            "[Train] | Epoch: 0349 / 1000 | Batch: 0004 / 0004 | Loss: 0.4936\n",
            "[Validation] | Epoch: 0349 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0349 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0349] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0350 / 1000 | Batch: 0001 / 0004 | Loss: 0.4881\n",
            "[Train] | Epoch: 0350 / 1000 | Batch: 0002 / 0004 | Loss: 0.4887\n",
            "[Train] | Epoch: 0350 / 1000 | Batch: 0003 / 0004 | Loss: 0.5047\n",
            "[Train] | Epoch: 0350 / 1000 | Batch: 0004 / 0004 | Loss: 0.5023\n",
            "[Validation] | Epoch: 0350 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0350 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0350] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0351 / 1000 | Batch: 0001 / 0004 | Loss: 0.4902\n",
            "[Train] | Epoch: 0351 / 1000 | Batch: 0002 / 0004 | Loss: 0.4918\n",
            "[Train] | Epoch: 0351 / 1000 | Batch: 0003 / 0004 | Loss: 0.4958\n",
            "[Train] | Epoch: 0351 / 1000 | Batch: 0004 / 0004 | Loss: 0.5079\n",
            "[Validation] | Epoch: 0351 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0351 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0351] Training Avg Loss: 0.4965 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0352 / 1000 | Batch: 0001 / 0004 | Loss: 0.5004\n",
            "[Train] | Epoch: 0352 / 1000 | Batch: 0002 / 0004 | Loss: 0.4973\n",
            "[Train] | Epoch: 0352 / 1000 | Batch: 0003 / 0004 | Loss: 0.4946\n",
            "[Train] | Epoch: 0352 / 1000 | Batch: 0004 / 0004 | Loss: 0.4885\n",
            "[Validation] | Epoch: 0352 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0352 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0352] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0353 / 1000 | Batch: 0001 / 0004 | Loss: 0.4929\n",
            "[Train] | Epoch: 0353 / 1000 | Batch: 0002 / 0004 | Loss: 0.4967\n",
            "[Train] | Epoch: 0353 / 1000 | Batch: 0003 / 0004 | Loss: 0.5006\n",
            "[Train] | Epoch: 0353 / 1000 | Batch: 0004 / 0004 | Loss: 0.4913\n",
            "[Validation] | Epoch: 0353 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0353 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0353] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0354 / 1000 | Batch: 0001 / 0004 | Loss: 0.4960\n",
            "[Train] | Epoch: 0354 / 1000 | Batch: 0002 / 0004 | Loss: 0.4913\n",
            "[Train] | Epoch: 0354 / 1000 | Batch: 0003 / 0004 | Loss: 0.5003\n",
            "[Train] | Epoch: 0354 / 1000 | Batch: 0004 / 0004 | Loss: 0.4959\n",
            "[Validation] | Epoch: 0354 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0354 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0354] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0355 / 1000 | Batch: 0001 / 0004 | Loss: 0.4965\n",
            "[Train] | Epoch: 0355 / 1000 | Batch: 0002 / 0004 | Loss: 0.4946\n",
            "[Train] | Epoch: 0355 / 1000 | Batch: 0003 / 0004 | Loss: 0.4865\n",
            "[Train] | Epoch: 0355 / 1000 | Batch: 0004 / 0004 | Loss: 0.5085\n",
            "[Validation] | Epoch: 0355 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0355 / 1000 | Batch: 0002 / 0002 | Loss: 0.4853\n",
            "[Epoch 0355] Training Avg Loss: 0.4965 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0356 / 1000 | Batch: 0001 / 0004 | Loss: 0.5004\n",
            "[Train] | Epoch: 0356 / 1000 | Batch: 0002 / 0004 | Loss: 0.4947\n",
            "[Train] | Epoch: 0356 / 1000 | Batch: 0003 / 0004 | Loss: 0.4922\n",
            "[Train] | Epoch: 0356 / 1000 | Batch: 0004 / 0004 | Loss: 0.4937\n",
            "[Validation] | Epoch: 0356 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0356 / 1000 | Batch: 0002 / 0002 | Loss: 0.4853\n",
            "[Epoch 0356] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0357 / 1000 | Batch: 0001 / 0004 | Loss: 0.4877\n",
            "[Train] | Epoch: 0357 / 1000 | Batch: 0002 / 0004 | Loss: 0.5039\n",
            "[Train] | Epoch: 0357 / 1000 | Batch: 0003 / 0004 | Loss: 0.4916\n",
            "[Train] | Epoch: 0357 / 1000 | Batch: 0004 / 0004 | Loss: 0.4992\n",
            "[Validation] | Epoch: 0357 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0357 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0357] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0358 / 1000 | Batch: 0001 / 0004 | Loss: 0.4882\n",
            "[Train] | Epoch: 0358 / 1000 | Batch: 0002 / 0004 | Loss: 0.4985\n",
            "[Train] | Epoch: 0358 / 1000 | Batch: 0003 / 0004 | Loss: 0.4988\n",
            "[Train] | Epoch: 0358 / 1000 | Batch: 0004 / 0004 | Loss: 0.4973\n",
            "[Validation] | Epoch: 0358 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0358 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0358] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0359 / 1000 | Batch: 0001 / 0004 | Loss: 0.4958\n",
            "[Train] | Epoch: 0359 / 1000 | Batch: 0002 / 0004 | Loss: 0.4978\n",
            "[Train] | Epoch: 0359 / 1000 | Batch: 0003 / 0004 | Loss: 0.4995\n",
            "[Train] | Epoch: 0359 / 1000 | Batch: 0004 / 0004 | Loss: 0.4866\n",
            "[Validation] | Epoch: 0359 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0359 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0359] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0360 / 1000 | Batch: 0001 / 0004 | Loss: 0.4969\n",
            "[Train] | Epoch: 0360 / 1000 | Batch: 0002 / 0004 | Loss: 0.4978\n",
            "[Train] | Epoch: 0360 / 1000 | Batch: 0003 / 0004 | Loss: 0.4905\n",
            "[Train] | Epoch: 0360 / 1000 | Batch: 0004 / 0004 | Loss: 0.4964\n",
            "[Validation] | Epoch: 0360 / 1000 | Batch: 0001 / 0002 | Loss: 0.5077\n",
            "[Validation] | Epoch: 0360 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0360] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0361 / 1000 | Batch: 0001 / 0004 | Loss: 0.4925\n",
            "[Train] | Epoch: 0361 / 1000 | Batch: 0002 / 0004 | Loss: 0.4926\n",
            "[Train] | Epoch: 0361 / 1000 | Batch: 0003 / 0004 | Loss: 0.5031\n",
            "[Train] | Epoch: 0361 / 1000 | Batch: 0004 / 0004 | Loss: 0.4917\n",
            "[Validation] | Epoch: 0361 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0361 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0361] Training Avg Loss: 0.4950 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0362 / 1000 | Batch: 0001 / 0004 | Loss: 0.4892\n",
            "[Train] | Epoch: 0362 / 1000 | Batch: 0002 / 0004 | Loss: 0.5101\n",
            "[Train] | Epoch: 0362 / 1000 | Batch: 0003 / 0004 | Loss: 0.4905\n",
            "[Train] | Epoch: 0362 / 1000 | Batch: 0004 / 0004 | Loss: 0.4897\n",
            "[Validation] | Epoch: 0362 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0362 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0362] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0363 / 1000 | Batch: 0001 / 0004 | Loss: 0.4886\n",
            "[Train] | Epoch: 0363 / 1000 | Batch: 0002 / 0004 | Loss: 0.4977\n",
            "[Train] | Epoch: 0363 / 1000 | Batch: 0003 / 0004 | Loss: 0.5001\n",
            "[Train] | Epoch: 0363 / 1000 | Batch: 0004 / 0004 | Loss: 0.4945\n",
            "[Validation] | Epoch: 0363 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0363 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0363] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0364 / 1000 | Batch: 0001 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0364 / 1000 | Batch: 0002 / 0004 | Loss: 0.4963\n",
            "[Train] | Epoch: 0364 / 1000 | Batch: 0003 / 0004 | Loss: 0.4905\n",
            "[Train] | Epoch: 0364 / 1000 | Batch: 0004 / 0004 | Loss: 0.5025\n",
            "[Validation] | Epoch: 0364 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0364 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0364] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0365 / 1000 | Batch: 0001 / 0004 | Loss: 0.4961\n",
            "[Train] | Epoch: 0365 / 1000 | Batch: 0002 / 0004 | Loss: 0.4928\n",
            "[Train] | Epoch: 0365 / 1000 | Batch: 0003 / 0004 | Loss: 0.4897\n",
            "[Train] | Epoch: 0365 / 1000 | Batch: 0004 / 0004 | Loss: 0.5052\n",
            "[Validation] | Epoch: 0365 / 1000 | Batch: 0001 / 0002 | Loss: 0.5071\n",
            "[Validation] | Epoch: 0365 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0365] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0366 / 1000 | Batch: 0001 / 0004 | Loss: 0.4955\n",
            "[Train] | Epoch: 0366 / 1000 | Batch: 0002 / 0004 | Loss: 0.5047\n",
            "[Train] | Epoch: 0366 / 1000 | Batch: 0003 / 0004 | Loss: 0.4910\n",
            "[Train] | Epoch: 0366 / 1000 | Batch: 0004 / 0004 | Loss: 0.4882\n",
            "[Validation] | Epoch: 0366 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0366 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0366] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0367 / 1000 | Batch: 0001 / 0004 | Loss: 0.4900\n",
            "[Train] | Epoch: 0367 / 1000 | Batch: 0002 / 0004 | Loss: 0.5052\n",
            "[Train] | Epoch: 0367 / 1000 | Batch: 0003 / 0004 | Loss: 0.4927\n",
            "[Train] | Epoch: 0367 / 1000 | Batch: 0004 / 0004 | Loss: 0.4940\n",
            "[Validation] | Epoch: 0367 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0367 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0367] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0368 / 1000 | Batch: 0001 / 0004 | Loss: 0.4958\n",
            "[Train] | Epoch: 0368 / 1000 | Batch: 0002 / 0004 | Loss: 0.4974\n",
            "[Train] | Epoch: 0368 / 1000 | Batch: 0003 / 0004 | Loss: 0.4974\n",
            "[Train] | Epoch: 0368 / 1000 | Batch: 0004 / 0004 | Loss: 0.4919\n",
            "[Validation] | Epoch: 0368 / 1000 | Batch: 0001 / 0002 | Loss: 0.5080\n",
            "[Validation] | Epoch: 0368 / 1000 | Batch: 0002 / 0002 | Loss: 0.4867\n",
            "[Epoch 0368] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4974\n",
            "[Train] | Epoch: 0369 / 1000 | Batch: 0001 / 0004 | Loss: 0.4866\n",
            "[Train] | Epoch: 0369 / 1000 | Batch: 0002 / 0004 | Loss: 0.4939\n",
            "[Train] | Epoch: 0369 / 1000 | Batch: 0003 / 0004 | Loss: 0.5045\n",
            "[Train] | Epoch: 0369 / 1000 | Batch: 0004 / 0004 | Loss: 0.4954\n",
            "[Validation] | Epoch: 0369 / 1000 | Batch: 0001 / 0002 | Loss: 0.5078\n",
            "[Validation] | Epoch: 0369 / 1000 | Batch: 0002 / 0002 | Loss: 0.4866\n",
            "[Epoch 0369] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4972\n",
            "[Train] | Epoch: 0370 / 1000 | Batch: 0001 / 0004 | Loss: 0.4899\n",
            "[Train] | Epoch: 0370 / 1000 | Batch: 0002 / 0004 | Loss: 0.4979\n",
            "[Train] | Epoch: 0370 / 1000 | Batch: 0003 / 0004 | Loss: 0.5061\n",
            "[Train] | Epoch: 0370 / 1000 | Batch: 0004 / 0004 | Loss: 0.4846\n",
            "[Validation] | Epoch: 0370 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0370 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0370] Training Avg Loss: 0.4946 | Validation Avg Loss: 0.4969\n",
            "[Train] | Epoch: 0371 / 1000 | Batch: 0001 / 0004 | Loss: 0.4947\n",
            "[Train] | Epoch: 0371 / 1000 | Batch: 0002 / 0004 | Loss: 0.4971\n",
            "[Train] | Epoch: 0371 / 1000 | Batch: 0003 / 0004 | Loss: 0.4976\n",
            "[Train] | Epoch: 0371 / 1000 | Batch: 0004 / 0004 | Loss: 0.4903\n",
            "[Validation] | Epoch: 0371 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0371 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0371] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0372 / 1000 | Batch: 0001 / 0004 | Loss: 0.5027\n",
            "[Train] | Epoch: 0372 / 1000 | Batch: 0002 / 0004 | Loss: 0.5049\n",
            "[Train] | Epoch: 0372 / 1000 | Batch: 0003 / 0004 | Loss: 0.4834\n",
            "[Train] | Epoch: 0372 / 1000 | Batch: 0004 / 0004 | Loss: 0.4896\n",
            "[Validation] | Epoch: 0372 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0372 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0372] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0373 / 1000 | Batch: 0001 / 0004 | Loss: 0.4920\n",
            "[Train] | Epoch: 0373 / 1000 | Batch: 0002 / 0004 | Loss: 0.4915\n",
            "[Train] | Epoch: 0373 / 1000 | Batch: 0003 / 0004 | Loss: 0.4996\n",
            "[Train] | Epoch: 0373 / 1000 | Batch: 0004 / 0004 | Loss: 0.4991\n",
            "[Validation] | Epoch: 0373 / 1000 | Batch: 0001 / 0002 | Loss: 0.5071\n",
            "[Validation] | Epoch: 0373 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0373] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0374 / 1000 | Batch: 0001 / 0004 | Loss: 0.5020\n",
            "[Train] | Epoch: 0374 / 1000 | Batch: 0002 / 0004 | Loss: 0.4950\n",
            "[Train] | Epoch: 0374 / 1000 | Batch: 0003 / 0004 | Loss: 0.4919\n",
            "[Train] | Epoch: 0374 / 1000 | Batch: 0004 / 0004 | Loss: 0.4934\n",
            "[Validation] | Epoch: 0374 / 1000 | Batch: 0001 / 0002 | Loss: 0.5071\n",
            "[Validation] | Epoch: 0374 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0374] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0375 / 1000 | Batch: 0001 / 0004 | Loss: 0.4914\n",
            "[Train] | Epoch: 0375 / 1000 | Batch: 0002 / 0004 | Loss: 0.5021\n",
            "[Train] | Epoch: 0375 / 1000 | Batch: 0003 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0375 / 1000 | Batch: 0004 / 0004 | Loss: 0.4956\n",
            "[Validation] | Epoch: 0375 / 1000 | Batch: 0001 / 0002 | Loss: 0.5071\n",
            "[Validation] | Epoch: 0375 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0375] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0376 / 1000 | Batch: 0001 / 0004 | Loss: 0.5008\n",
            "[Train] | Epoch: 0376 / 1000 | Batch: 0002 / 0004 | Loss: 0.4926\n",
            "[Train] | Epoch: 0376 / 1000 | Batch: 0003 / 0004 | Loss: 0.4874\n",
            "[Train] | Epoch: 0376 / 1000 | Batch: 0004 / 0004 | Loss: 0.5034\n",
            "[Validation] | Epoch: 0376 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0376 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0376] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0377 / 1000 | Batch: 0001 / 0004 | Loss: 0.4889\n",
            "[Train] | Epoch: 0377 / 1000 | Batch: 0002 / 0004 | Loss: 0.5006\n",
            "[Train] | Epoch: 0377 / 1000 | Batch: 0003 / 0004 | Loss: 0.4963\n",
            "[Train] | Epoch: 0377 / 1000 | Batch: 0004 / 0004 | Loss: 0.4970\n",
            "[Validation] | Epoch: 0377 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0377 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0377] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0378 / 1000 | Batch: 0001 / 0004 | Loss: 0.5033\n",
            "[Train] | Epoch: 0378 / 1000 | Batch: 0002 / 0004 | Loss: 0.4900\n",
            "[Train] | Epoch: 0378 / 1000 | Batch: 0003 / 0004 | Loss: 0.4966\n",
            "[Train] | Epoch: 0378 / 1000 | Batch: 0004 / 0004 | Loss: 0.4907\n",
            "[Validation] | Epoch: 0378 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0378 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0378] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0379 / 1000 | Batch: 0001 / 0004 | Loss: 0.4911\n",
            "[Train] | Epoch: 0379 / 1000 | Batch: 0002 / 0004 | Loss: 0.5034\n",
            "[Train] | Epoch: 0379 / 1000 | Batch: 0003 / 0004 | Loss: 0.4916\n",
            "[Train] | Epoch: 0379 / 1000 | Batch: 0004 / 0004 | Loss: 0.4979\n",
            "[Validation] | Epoch: 0379 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0379 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0379] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0380 / 1000 | Batch: 0001 / 0004 | Loss: 0.5020\n",
            "[Train] | Epoch: 0380 / 1000 | Batch: 0002 / 0004 | Loss: 0.5001\n",
            "[Train] | Epoch: 0380 / 1000 | Batch: 0003 / 0004 | Loss: 0.4846\n",
            "[Train] | Epoch: 0380 / 1000 | Batch: 0004 / 0004 | Loss: 0.4956\n",
            "[Validation] | Epoch: 0380 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0380 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0380] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0381 / 1000 | Batch: 0001 / 0004 | Loss: 0.4934\n",
            "[Train] | Epoch: 0381 / 1000 | Batch: 0002 / 0004 | Loss: 0.4859\n",
            "[Train] | Epoch: 0381 / 1000 | Batch: 0003 / 0004 | Loss: 0.4953\n",
            "[Train] | Epoch: 0381 / 1000 | Batch: 0004 / 0004 | Loss: 0.5130\n",
            "[Validation] | Epoch: 0381 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0381 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0381] Training Avg Loss: 0.4969 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0382 / 1000 | Batch: 0001 / 0004 | Loss: 0.5015\n",
            "[Train] | Epoch: 0382 / 1000 | Batch: 0002 / 0004 | Loss: 0.5053\n",
            "[Train] | Epoch: 0382 / 1000 | Batch: 0003 / 0004 | Loss: 0.4873\n",
            "[Train] | Epoch: 0382 / 1000 | Batch: 0004 / 0004 | Loss: 0.4879\n",
            "[Validation] | Epoch: 0382 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0382 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0382] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0383 / 1000 | Batch: 0001 / 0004 | Loss: 0.4946\n",
            "[Train] | Epoch: 0383 / 1000 | Batch: 0002 / 0004 | Loss: 0.4893\n",
            "[Train] | Epoch: 0383 / 1000 | Batch: 0003 / 0004 | Loss: 0.5050\n",
            "[Train] | Epoch: 0383 / 1000 | Batch: 0004 / 0004 | Loss: 0.4936\n",
            "[Validation] | Epoch: 0383 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0383 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0383] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0384 / 1000 | Batch: 0001 / 0004 | Loss: 0.4879\n",
            "[Train] | Epoch: 0384 / 1000 | Batch: 0002 / 0004 | Loss: 0.4963\n",
            "[Train] | Epoch: 0384 / 1000 | Batch: 0003 / 0004 | Loss: 0.4956\n",
            "[Train] | Epoch: 0384 / 1000 | Batch: 0004 / 0004 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0384 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0384 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0384] Training Avg Loss: 0.4968 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0385 / 1000 | Batch: 0001 / 0004 | Loss: 0.5002\n",
            "[Train] | Epoch: 0385 / 1000 | Batch: 0002 / 0004 | Loss: 0.4953\n",
            "[Train] | Epoch: 0385 / 1000 | Batch: 0003 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0385 / 1000 | Batch: 0004 / 0004 | Loss: 0.4941\n",
            "[Validation] | Epoch: 0385 / 1000 | Batch: 0001 / 0002 | Loss: 0.5078\n",
            "[Validation] | Epoch: 0385 / 1000 | Batch: 0002 / 0002 | Loss: 0.4864\n",
            "[Epoch 0385] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4971\n",
            "[Train] | Epoch: 0386 / 1000 | Batch: 0001 / 0004 | Loss: 0.4914\n",
            "[Train] | Epoch: 0386 / 1000 | Batch: 0002 / 0004 | Loss: 0.4989\n",
            "[Train] | Epoch: 0386 / 1000 | Batch: 0003 / 0004 | Loss: 0.4949\n",
            "[Train] | Epoch: 0386 / 1000 | Batch: 0004 / 0004 | Loss: 0.4998\n",
            "[Validation] | Epoch: 0386 / 1000 | Batch: 0001 / 0002 | Loss: 0.5078\n",
            "[Validation] | Epoch: 0386 / 1000 | Batch: 0002 / 0002 | Loss: 0.4863\n",
            "[Epoch 0386] Training Avg Loss: 0.4963 | Validation Avg Loss: 0.4971\n",
            "[Train] | Epoch: 0387 / 1000 | Batch: 0001 / 0004 | Loss: 0.4943\n",
            "[Train] | Epoch: 0387 / 1000 | Batch: 0002 / 0004 | Loss: 0.4963\n",
            "[Train] | Epoch: 0387 / 1000 | Batch: 0003 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0387 / 1000 | Batch: 0004 / 0004 | Loss: 0.4972\n",
            "[Validation] | Epoch: 0387 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0387 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0387] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4969\n",
            "[Train] | Epoch: 0388 / 1000 | Batch: 0001 / 0004 | Loss: 0.4908\n",
            "[Train] | Epoch: 0388 / 1000 | Batch: 0002 / 0004 | Loss: 0.4913\n",
            "[Train] | Epoch: 0388 / 1000 | Batch: 0003 / 0004 | Loss: 0.4870\n",
            "[Train] | Epoch: 0388 / 1000 | Batch: 0004 / 0004 | Loss: 0.5171\n",
            "[Validation] | Epoch: 0388 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0388 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0388] Training Avg Loss: 0.4966 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0389 / 1000 | Batch: 0001 / 0004 | Loss: 0.4830\n",
            "[Train] | Epoch: 0389 / 1000 | Batch: 0002 / 0004 | Loss: 0.5192\n",
            "[Train] | Epoch: 0389 / 1000 | Batch: 0003 / 0004 | Loss: 0.4899\n",
            "[Train] | Epoch: 0389 / 1000 | Batch: 0004 / 0004 | Loss: 0.4883\n",
            "[Validation] | Epoch: 0389 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0389 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0389] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0390 / 1000 | Batch: 0001 / 0004 | Loss: 0.4904\n",
            "[Train] | Epoch: 0390 / 1000 | Batch: 0002 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0390 / 1000 | Batch: 0003 / 0004 | Loss: 0.4972\n",
            "[Train] | Epoch: 0390 / 1000 | Batch: 0004 / 0004 | Loss: 0.4988\n",
            "[Validation] | Epoch: 0390 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0390 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0390] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0391 / 1000 | Batch: 0001 / 0004 | Loss: 0.4912\n",
            "[Train] | Epoch: 0391 / 1000 | Batch: 0002 / 0004 | Loss: 0.4975\n",
            "[Train] | Epoch: 0391 / 1000 | Batch: 0003 / 0004 | Loss: 0.4949\n",
            "[Train] | Epoch: 0391 / 1000 | Batch: 0004 / 0004 | Loss: 0.5012\n",
            "[Validation] | Epoch: 0391 / 1000 | Batch: 0001 / 0002 | Loss: 0.5070\n",
            "[Validation] | Epoch: 0391 / 1000 | Batch: 0002 / 0002 | Loss: 0.4853\n",
            "[Epoch 0391] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4962\n",
            "[Train] | Epoch: 0392 / 1000 | Batch: 0001 / 0004 | Loss: 0.4957\n",
            "[Train] | Epoch: 0392 / 1000 | Batch: 0002 / 0004 | Loss: 0.5007\n",
            "[Train] | Epoch: 0392 / 1000 | Batch: 0003 / 0004 | Loss: 0.4855\n",
            "[Train] | Epoch: 0392 / 1000 | Batch: 0004 / 0004 | Loss: 0.5038\n",
            "[Validation] | Epoch: 0392 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0392 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0392] Training Avg Loss: 0.4964 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0393 / 1000 | Batch: 0001 / 0004 | Loss: 0.4902\n",
            "[Train] | Epoch: 0393 / 1000 | Batch: 0002 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0393 / 1000 | Batch: 0003 / 0004 | Loss: 0.4990\n",
            "[Train] | Epoch: 0393 / 1000 | Batch: 0004 / 0004 | Loss: 0.5033\n",
            "[Validation] | Epoch: 0393 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0393 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0393] Training Avg Loss: 0.4969 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0394 / 1000 | Batch: 0001 / 0004 | Loss: 0.5051\n",
            "[Train] | Epoch: 0394 / 1000 | Batch: 0002 / 0004 | Loss: 0.4911\n",
            "[Train] | Epoch: 0394 / 1000 | Batch: 0003 / 0004 | Loss: 0.4896\n",
            "[Train] | Epoch: 0394 / 1000 | Batch: 0004 / 0004 | Loss: 0.4964\n",
            "[Validation] | Epoch: 0394 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0394 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0394] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0395 / 1000 | Batch: 0001 / 0004 | Loss: 0.4915\n",
            "[Train] | Epoch: 0395 / 1000 | Batch: 0002 / 0004 | Loss: 0.5015\n",
            "[Train] | Epoch: 0395 / 1000 | Batch: 0003 / 0004 | Loss: 0.4906\n",
            "[Train] | Epoch: 0395 / 1000 | Batch: 0004 / 0004 | Loss: 0.4986\n",
            "[Validation] | Epoch: 0395 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0395 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0395] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0396 / 1000 | Batch: 0001 / 0004 | Loss: 0.4968\n",
            "[Train] | Epoch: 0396 / 1000 | Batch: 0002 / 0004 | Loss: 0.4995\n",
            "[Train] | Epoch: 0396 / 1000 | Batch: 0003 / 0004 | Loss: 0.4950\n",
            "[Train] | Epoch: 0396 / 1000 | Batch: 0004 / 0004 | Loss: 0.4896\n",
            "[Validation] | Epoch: 0396 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0396 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0396] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0397 / 1000 | Batch: 0001 / 0004 | Loss: 0.5056\n",
            "[Train] | Epoch: 0397 / 1000 | Batch: 0002 / 0004 | Loss: 0.4964\n",
            "[Train] | Epoch: 0397 / 1000 | Batch: 0003 / 0004 | Loss: 0.4868\n",
            "[Train] | Epoch: 0397 / 1000 | Batch: 0004 / 0004 | Loss: 0.4940\n",
            "[Validation] | Epoch: 0397 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0397 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0397] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0398 / 1000 | Batch: 0001 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0398 / 1000 | Batch: 0002 / 0004 | Loss: 0.5028\n",
            "[Train] | Epoch: 0398 / 1000 | Batch: 0003 / 0004 | Loss: 0.4932\n",
            "[Train] | Epoch: 0398 / 1000 | Batch: 0004 / 0004 | Loss: 0.4899\n",
            "[Validation] | Epoch: 0398 / 1000 | Batch: 0001 / 0002 | Loss: 0.5077\n",
            "[Validation] | Epoch: 0398 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0398] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4969\n",
            "[Train] | Epoch: 0399 / 1000 | Batch: 0001 / 0004 | Loss: 0.4911\n",
            "[Train] | Epoch: 0399 / 1000 | Batch: 0002 / 0004 | Loss: 0.5098\n",
            "[Train] | Epoch: 0399 / 1000 | Batch: 0003 / 0004 | Loss: 0.4892\n",
            "[Train] | Epoch: 0399 / 1000 | Batch: 0004 / 0004 | Loss: 0.4895\n",
            "[Validation] | Epoch: 0399 / 1000 | Batch: 0001 / 0002 | Loss: 0.5077\n",
            "[Validation] | Epoch: 0399 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0399] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0400 / 1000 | Batch: 0001 / 0004 | Loss: 0.4996\n",
            "[Train] | Epoch: 0400 / 1000 | Batch: 0002 / 0004 | Loss: 0.4987\n",
            "[Train] | Epoch: 0400 / 1000 | Batch: 0003 / 0004 | Loss: 0.4908\n",
            "[Train] | Epoch: 0400 / 1000 | Batch: 0004 / 0004 | Loss: 0.4928\n",
            "[Validation] | Epoch: 0400 / 1000 | Batch: 0001 / 0002 | Loss: 0.5078\n",
            "[Validation] | Epoch: 0400 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0400] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4970\n",
            "[Train] | Epoch: 0401 / 1000 | Batch: 0001 / 0004 | Loss: 0.4977\n",
            "[Train] | Epoch: 0401 / 1000 | Batch: 0002 / 0004 | Loss: 0.4959\n",
            "[Train] | Epoch: 0401 / 1000 | Batch: 0003 / 0004 | Loss: 0.4916\n",
            "[Train] | Epoch: 0401 / 1000 | Batch: 0004 / 0004 | Loss: 0.4994\n",
            "[Validation] | Epoch: 0401 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0401 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0401] Training Avg Loss: 0.4961 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0402 / 1000 | Batch: 0001 / 0004 | Loss: 0.4995\n",
            "[Train] | Epoch: 0402 / 1000 | Batch: 0002 / 0004 | Loss: 0.4915\n",
            "[Train] | Epoch: 0402 / 1000 | Batch: 0003 / 0004 | Loss: 0.4984\n",
            "[Train] | Epoch: 0402 / 1000 | Batch: 0004 / 0004 | Loss: 0.4909\n",
            "[Validation] | Epoch: 0402 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0402 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0402] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0403 / 1000 | Batch: 0001 / 0004 | Loss: 0.4900\n",
            "[Train] | Epoch: 0403 / 1000 | Batch: 0002 / 0004 | Loss: 0.5001\n",
            "[Train] | Epoch: 0403 / 1000 | Batch: 0003 / 0004 | Loss: 0.4950\n",
            "[Train] | Epoch: 0403 / 1000 | Batch: 0004 / 0004 | Loss: 0.4988\n",
            "[Validation] | Epoch: 0403 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0403 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0403] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0404 / 1000 | Batch: 0001 / 0004 | Loss: 0.4850\n",
            "[Train] | Epoch: 0404 / 1000 | Batch: 0002 / 0004 | Loss: 0.5059\n",
            "[Train] | Epoch: 0404 / 1000 | Batch: 0003 / 0004 | Loss: 0.4979\n",
            "[Train] | Epoch: 0404 / 1000 | Batch: 0004 / 0004 | Loss: 0.4940\n",
            "[Validation] | Epoch: 0404 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0404 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0404] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0405 / 1000 | Batch: 0001 / 0004 | Loss: 0.4940\n",
            "[Train] | Epoch: 0405 / 1000 | Batch: 0002 / 0004 | Loss: 0.4893\n",
            "[Train] | Epoch: 0405 / 1000 | Batch: 0003 / 0004 | Loss: 0.5034\n",
            "[Train] | Epoch: 0405 / 1000 | Batch: 0004 / 0004 | Loss: 0.4966\n",
            "[Validation] | Epoch: 0405 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0405 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0405] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0406 / 1000 | Batch: 0001 / 0004 | Loss: 0.4897\n",
            "[Train] | Epoch: 0406 / 1000 | Batch: 0002 / 0004 | Loss: 0.4962\n",
            "[Train] | Epoch: 0406 / 1000 | Batch: 0003 / 0004 | Loss: 0.5004\n",
            "[Train] | Epoch: 0406 / 1000 | Batch: 0004 / 0004 | Loss: 0.4946\n",
            "[Validation] | Epoch: 0406 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0406 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0406] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0407 / 1000 | Batch: 0001 / 0004 | Loss: 0.4922\n",
            "[Train] | Epoch: 0407 / 1000 | Batch: 0002 / 0004 | Loss: 0.5010\n",
            "[Train] | Epoch: 0407 / 1000 | Batch: 0003 / 0004 | Loss: 0.4940\n",
            "[Train] | Epoch: 0407 / 1000 | Batch: 0004 / 0004 | Loss: 0.4957\n",
            "[Validation] | Epoch: 0407 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0407 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0407] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0408 / 1000 | Batch: 0001 / 0004 | Loss: 0.4915\n",
            "[Train] | Epoch: 0408 / 1000 | Batch: 0002 / 0004 | Loss: 0.4957\n",
            "[Train] | Epoch: 0408 / 1000 | Batch: 0003 / 0004 | Loss: 0.4903\n",
            "[Train] | Epoch: 0408 / 1000 | Batch: 0004 / 0004 | Loss: 0.5064\n",
            "[Validation] | Epoch: 0408 / 1000 | Batch: 0001 / 0002 | Loss: 0.5071\n",
            "[Validation] | Epoch: 0408 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0408] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0409 / 1000 | Batch: 0001 / 0004 | Loss: 0.5028\n",
            "[Train] | Epoch: 0409 / 1000 | Batch: 0002 / 0004 | Loss: 0.4888\n",
            "[Train] | Epoch: 0409 / 1000 | Batch: 0003 / 0004 | Loss: 0.4950\n",
            "[Train] | Epoch: 0409 / 1000 | Batch: 0004 / 0004 | Loss: 0.4988\n",
            "[Validation] | Epoch: 0409 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0409 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0409] Training Avg Loss: 0.4964 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0410 / 1000 | Batch: 0001 / 0004 | Loss: 0.4882\n",
            "[Train] | Epoch: 0410 / 1000 | Batch: 0002 / 0004 | Loss: 0.4978\n",
            "[Train] | Epoch: 0410 / 1000 | Batch: 0003 / 0004 | Loss: 0.4919\n",
            "[Train] | Epoch: 0410 / 1000 | Batch: 0004 / 0004 | Loss: 0.5064\n",
            "[Validation] | Epoch: 0410 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0410 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0410] Training Avg Loss: 0.4961 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0411 / 1000 | Batch: 0001 / 0004 | Loss: 0.4875\n",
            "[Train] | Epoch: 0411 / 1000 | Batch: 0002 / 0004 | Loss: 0.5023\n",
            "[Train] | Epoch: 0411 / 1000 | Batch: 0003 / 0004 | Loss: 0.4959\n",
            "[Train] | Epoch: 0411 / 1000 | Batch: 0004 / 0004 | Loss: 0.5001\n",
            "[Validation] | Epoch: 0411 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0411 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0411] Training Avg Loss: 0.4965 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0412 / 1000 | Batch: 0001 / 0004 | Loss: 0.5019\n",
            "[Train] | Epoch: 0412 / 1000 | Batch: 0002 / 0004 | Loss: 0.4956\n",
            "[Train] | Epoch: 0412 / 1000 | Batch: 0003 / 0004 | Loss: 0.4860\n",
            "[Train] | Epoch: 0412 / 1000 | Batch: 0004 / 0004 | Loss: 0.4991\n",
            "[Validation] | Epoch: 0412 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0412 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0412] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0413 / 1000 | Batch: 0001 / 0004 | Loss: 0.4893\n",
            "[Train] | Epoch: 0413 / 1000 | Batch: 0002 / 0004 | Loss: 0.5000\n",
            "[Train] | Epoch: 0413 / 1000 | Batch: 0003 / 0004 | Loss: 0.4955\n",
            "[Train] | Epoch: 0413 / 1000 | Batch: 0004 / 0004 | Loss: 0.4964\n",
            "[Validation] | Epoch: 0413 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0413 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0413] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0414 / 1000 | Batch: 0001 / 0004 | Loss: 0.4979\n",
            "[Train] | Epoch: 0414 / 1000 | Batch: 0002 / 0004 | Loss: 0.4959\n",
            "[Train] | Epoch: 0414 / 1000 | Batch: 0003 / 0004 | Loss: 0.4964\n",
            "[Train] | Epoch: 0414 / 1000 | Batch: 0004 / 0004 | Loss: 0.4908\n",
            "[Validation] | Epoch: 0414 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0414 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0414] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4969\n",
            "[Train] | Epoch: 0415 / 1000 | Batch: 0001 / 0004 | Loss: 0.5080\n",
            "[Train] | Epoch: 0415 / 1000 | Batch: 0002 / 0004 | Loss: 0.4979\n",
            "[Train] | Epoch: 0415 / 1000 | Batch: 0003 / 0004 | Loss: 0.4838\n",
            "[Train] | Epoch: 0415 / 1000 | Batch: 0004 / 0004 | Loss: 0.4914\n",
            "[Validation] | Epoch: 0415 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0415 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0415] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0416 / 1000 | Batch: 0001 / 0004 | Loss: 0.4925\n",
            "[Train] | Epoch: 0416 / 1000 | Batch: 0002 / 0004 | Loss: 0.4879\n",
            "[Train] | Epoch: 0416 / 1000 | Batch: 0003 / 0004 | Loss: 0.5003\n",
            "[Train] | Epoch: 0416 / 1000 | Batch: 0004 / 0004 | Loss: 0.5032\n",
            "[Validation] | Epoch: 0416 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0416 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0416] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0417 / 1000 | Batch: 0001 / 0004 | Loss: 0.4881\n",
            "[Train] | Epoch: 0417 / 1000 | Batch: 0002 / 0004 | Loss: 0.4932\n",
            "[Train] | Epoch: 0417 / 1000 | Batch: 0003 / 0004 | Loss: 0.5073\n",
            "[Train] | Epoch: 0417 / 1000 | Batch: 0004 / 0004 | Loss: 0.4903\n",
            "[Validation] | Epoch: 0417 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0417 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0417] Training Avg Loss: 0.4947 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0418 / 1000 | Batch: 0001 / 0004 | Loss: 0.5034\n",
            "[Train] | Epoch: 0418 / 1000 | Batch: 0002 / 0004 | Loss: 0.4958\n",
            "[Train] | Epoch: 0418 / 1000 | Batch: 0003 / 0004 | Loss: 0.4931\n",
            "[Train] | Epoch: 0418 / 1000 | Batch: 0004 / 0004 | Loss: 0.4881\n",
            "[Validation] | Epoch: 0418 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0418 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0418] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0419 / 1000 | Batch: 0001 / 0004 | Loss: 0.5051\n",
            "[Train] | Epoch: 0419 / 1000 | Batch: 0002 / 0004 | Loss: 0.4875\n",
            "[Train] | Epoch: 0419 / 1000 | Batch: 0003 / 0004 | Loss: 0.4977\n",
            "[Train] | Epoch: 0419 / 1000 | Batch: 0004 / 0004 | Loss: 0.4899\n",
            "[Validation] | Epoch: 0419 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0419 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0419] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0420 / 1000 | Batch: 0001 / 0004 | Loss: 0.4899\n",
            "[Train] | Epoch: 0420 / 1000 | Batch: 0002 / 0004 | Loss: 0.4956\n",
            "[Train] | Epoch: 0420 / 1000 | Batch: 0003 / 0004 | Loss: 0.4962\n",
            "[Train] | Epoch: 0420 / 1000 | Batch: 0004 / 0004 | Loss: 0.5026\n",
            "[Validation] | Epoch: 0420 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0420 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0420] Training Avg Loss: 0.4961 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0421 / 1000 | Batch: 0001 / 0004 | Loss: 0.5009\n",
            "[Train] | Epoch: 0421 / 1000 | Batch: 0002 / 0004 | Loss: 0.4976\n",
            "[Train] | Epoch: 0421 / 1000 | Batch: 0003 / 0004 | Loss: 0.4896\n",
            "[Train] | Epoch: 0421 / 1000 | Batch: 0004 / 0004 | Loss: 0.4928\n",
            "[Validation] | Epoch: 0421 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0421 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0421] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0422 / 1000 | Batch: 0001 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0422 / 1000 | Batch: 0002 / 0004 | Loss: 0.4979\n",
            "[Train] | Epoch: 0422 / 1000 | Batch: 0003 / 0004 | Loss: 0.4950\n",
            "[Train] | Epoch: 0422 / 1000 | Batch: 0004 / 0004 | Loss: 0.4950\n",
            "[Validation] | Epoch: 0422 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0422 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0422] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0423 / 1000 | Batch: 0001 / 0004 | Loss: 0.5031\n",
            "[Train] | Epoch: 0423 / 1000 | Batch: 0002 / 0004 | Loss: 0.4899\n",
            "[Train] | Epoch: 0423 / 1000 | Batch: 0003 / 0004 | Loss: 0.4991\n",
            "[Train] | Epoch: 0423 / 1000 | Batch: 0004 / 0004 | Loss: 0.4888\n",
            "[Validation] | Epoch: 0423 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0423 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0423] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0424 / 1000 | Batch: 0001 / 0004 | Loss: 0.5032\n",
            "[Train] | Epoch: 0424 / 1000 | Batch: 0002 / 0004 | Loss: 0.4906\n",
            "[Train] | Epoch: 0424 / 1000 | Batch: 0003 / 0004 | Loss: 0.5029\n",
            "[Train] | Epoch: 0424 / 1000 | Batch: 0004 / 0004 | Loss: 0.4815\n",
            "[Validation] | Epoch: 0424 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0424 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0424] Training Avg Loss: 0.4946 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0425 / 1000 | Batch: 0001 / 0004 | Loss: 0.4995\n",
            "[Train] | Epoch: 0425 / 1000 | Batch: 0002 / 0004 | Loss: 0.4972\n",
            "[Train] | Epoch: 0425 / 1000 | Batch: 0003 / 0004 | Loss: 0.4948\n",
            "[Train] | Epoch: 0425 / 1000 | Batch: 0004 / 0004 | Loss: 0.4894\n",
            "[Validation] | Epoch: 0425 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0425 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0425] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0426 / 1000 | Batch: 0001 / 0004 | Loss: 0.4912\n",
            "[Train] | Epoch: 0426 / 1000 | Batch: 0002 / 0004 | Loss: 0.4978\n",
            "[Train] | Epoch: 0426 / 1000 | Batch: 0003 / 0004 | Loss: 0.4934\n",
            "[Train] | Epoch: 0426 / 1000 | Batch: 0004 / 0004 | Loss: 0.5026\n",
            "[Validation] | Epoch: 0426 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0426 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0426] Training Avg Loss: 0.4963 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0427 / 1000 | Batch: 0001 / 0004 | Loss: 0.4922\n",
            "[Train] | Epoch: 0427 / 1000 | Batch: 0002 / 0004 | Loss: 0.5094\n",
            "[Train] | Epoch: 0427 / 1000 | Batch: 0003 / 0004 | Loss: 0.4819\n",
            "[Train] | Epoch: 0427 / 1000 | Batch: 0004 / 0004 | Loss: 0.4983\n",
            "[Validation] | Epoch: 0427 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0427 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0427] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0428 / 1000 | Batch: 0001 / 0004 | Loss: 0.5058\n",
            "[Train] | Epoch: 0428 / 1000 | Batch: 0002 / 0004 | Loss: 0.4979\n",
            "[Train] | Epoch: 0428 / 1000 | Batch: 0003 / 0004 | Loss: 0.4930\n",
            "[Train] | Epoch: 0428 / 1000 | Batch: 0004 / 0004 | Loss: 0.4829\n",
            "[Validation] | Epoch: 0428 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0428 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0428] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0429 / 1000 | Batch: 0001 / 0004 | Loss: 0.4902\n",
            "[Train] | Epoch: 0429 / 1000 | Batch: 0002 / 0004 | Loss: 0.4965\n",
            "[Train] | Epoch: 0429 / 1000 | Batch: 0003 / 0004 | Loss: 0.5025\n",
            "[Train] | Epoch: 0429 / 1000 | Batch: 0004 / 0004 | Loss: 0.4924\n",
            "[Validation] | Epoch: 0429 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0429 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0429] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0430 / 1000 | Batch: 0001 / 0004 | Loss: 0.5072\n",
            "[Train] | Epoch: 0430 / 1000 | Batch: 0002 / 0004 | Loss: 0.4973\n",
            "[Train] | Epoch: 0430 / 1000 | Batch: 0003 / 0004 | Loss: 0.4880\n",
            "[Train] | Epoch: 0430 / 1000 | Batch: 0004 / 0004 | Loss: 0.4873\n",
            "[Validation] | Epoch: 0430 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0430 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0430] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0431 / 1000 | Batch: 0001 / 0004 | Loss: 0.4970\n",
            "[Train] | Epoch: 0431 / 1000 | Batch: 0002 / 0004 | Loss: 0.5026\n",
            "[Train] | Epoch: 0431 / 1000 | Batch: 0003 / 0004 | Loss: 0.4890\n",
            "[Train] | Epoch: 0431 / 1000 | Batch: 0004 / 0004 | Loss: 0.4929\n",
            "[Validation] | Epoch: 0431 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0431 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0431] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0432 / 1000 | Batch: 0001 / 0004 | Loss: 0.4919\n",
            "[Train] | Epoch: 0432 / 1000 | Batch: 0002 / 0004 | Loss: 0.4942\n",
            "[Train] | Epoch: 0432 / 1000 | Batch: 0003 / 0004 | Loss: 0.4995\n",
            "[Train] | Epoch: 0432 / 1000 | Batch: 0004 / 0004 | Loss: 0.4945\n",
            "[Validation] | Epoch: 0432 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0432 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0432] Training Avg Loss: 0.4950 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0433 / 1000 | Batch: 0001 / 0004 | Loss: 0.4981\n",
            "[Train] | Epoch: 0433 / 1000 | Batch: 0002 / 0004 | Loss: 0.4913\n",
            "[Train] | Epoch: 0433 / 1000 | Batch: 0003 / 0004 | Loss: 0.4899\n",
            "[Train] | Epoch: 0433 / 1000 | Batch: 0004 / 0004 | Loss: 0.5049\n",
            "[Validation] | Epoch: 0433 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0433 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0433] Training Avg Loss: 0.4961 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0434 / 1000 | Batch: 0001 / 0004 | Loss: 0.4957\n",
            "[Train] | Epoch: 0434 / 1000 | Batch: 0002 / 0004 | Loss: 0.4919\n",
            "[Train] | Epoch: 0434 / 1000 | Batch: 0003 / 0004 | Loss: 0.4992\n",
            "[Train] | Epoch: 0434 / 1000 | Batch: 0004 / 0004 | Loss: 0.4973\n",
            "[Validation] | Epoch: 0434 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0434 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0434] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0435 / 1000 | Batch: 0001 / 0004 | Loss: 0.5017\n",
            "[Train] | Epoch: 0435 / 1000 | Batch: 0002 / 0004 | Loss: 0.4933\n",
            "[Train] | Epoch: 0435 / 1000 | Batch: 0003 / 0004 | Loss: 0.4980\n",
            "[Train] | Epoch: 0435 / 1000 | Batch: 0004 / 0004 | Loss: 0.4856\n",
            "[Validation] | Epoch: 0435 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0435 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0435] Training Avg Loss: 0.4947 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0436 / 1000 | Batch: 0001 / 0004 | Loss: 0.4909\n",
            "[Train] | Epoch: 0436 / 1000 | Batch: 0002 / 0004 | Loss: 0.5094\n",
            "[Train] | Epoch: 0436 / 1000 | Batch: 0003 / 0004 | Loss: 0.4932\n",
            "[Train] | Epoch: 0436 / 1000 | Batch: 0004 / 0004 | Loss: 0.4850\n",
            "[Validation] | Epoch: 0436 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0436 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0436] Training Avg Loss: 0.4946 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0437 / 1000 | Batch: 0001 / 0004 | Loss: 0.4927\n",
            "[Train] | Epoch: 0437 / 1000 | Batch: 0002 / 0004 | Loss: 0.4902\n",
            "[Train] | Epoch: 0437 / 1000 | Batch: 0003 / 0004 | Loss: 0.5033\n",
            "[Train] | Epoch: 0437 / 1000 | Batch: 0004 / 0004 | Loss: 0.4956\n",
            "[Validation] | Epoch: 0437 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0437 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0437] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0438 / 1000 | Batch: 0001 / 0004 | Loss: 0.4923\n",
            "[Train] | Epoch: 0438 / 1000 | Batch: 0002 / 0004 | Loss: 0.4896\n",
            "[Train] | Epoch: 0438 / 1000 | Batch: 0003 / 0004 | Loss: 0.5027\n",
            "[Train] | Epoch: 0438 / 1000 | Batch: 0004 / 0004 | Loss: 0.4969\n",
            "[Validation] | Epoch: 0438 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0438 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0438] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0439 / 1000 | Batch: 0001 / 0004 | Loss: 0.4912\n",
            "[Train] | Epoch: 0439 / 1000 | Batch: 0002 / 0004 | Loss: 0.4972\n",
            "[Train] | Epoch: 0439 / 1000 | Batch: 0003 / 0004 | Loss: 0.4988\n",
            "[Train] | Epoch: 0439 / 1000 | Batch: 0004 / 0004 | Loss: 0.4960\n",
            "[Validation] | Epoch: 0439 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0439 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0439] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0440 / 1000 | Batch: 0001 / 0004 | Loss: 0.4858\n",
            "[Train] | Epoch: 0440 / 1000 | Batch: 0002 / 0004 | Loss: 0.4986\n",
            "[Train] | Epoch: 0440 / 1000 | Batch: 0003 / 0004 | Loss: 0.4960\n",
            "[Train] | Epoch: 0440 / 1000 | Batch: 0004 / 0004 | Loss: 0.5038\n",
            "[Validation] | Epoch: 0440 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0440 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0440] Training Avg Loss: 0.4961 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0441 / 1000 | Batch: 0001 / 0004 | Loss: 0.4961\n",
            "[Train] | Epoch: 0441 / 1000 | Batch: 0002 / 0004 | Loss: 0.4921\n",
            "[Train] | Epoch: 0441 / 1000 | Batch: 0003 / 0004 | Loss: 0.4996\n",
            "[Train] | Epoch: 0441 / 1000 | Batch: 0004 / 0004 | Loss: 0.4939\n",
            "[Validation] | Epoch: 0441 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0441 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0441] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0442 / 1000 | Batch: 0001 / 0004 | Loss: 0.4930\n",
            "[Train] | Epoch: 0442 / 1000 | Batch: 0002 / 0004 | Loss: 0.4966\n",
            "[Train] | Epoch: 0442 / 1000 | Batch: 0003 / 0004 | Loss: 0.4918\n",
            "[Train] | Epoch: 0442 / 1000 | Batch: 0004 / 0004 | Loss: 0.5020\n",
            "[Validation] | Epoch: 0442 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0442 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0442] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0443 / 1000 | Batch: 0001 / 0004 | Loss: 0.4996\n",
            "[Train] | Epoch: 0443 / 1000 | Batch: 0002 / 0004 | Loss: 0.5018\n",
            "[Train] | Epoch: 0443 / 1000 | Batch: 0003 / 0004 | Loss: 0.4884\n",
            "[Train] | Epoch: 0443 / 1000 | Batch: 0004 / 0004 | Loss: 0.4903\n",
            "[Validation] | Epoch: 0443 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0443 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0443] Training Avg Loss: 0.4950 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0444 / 1000 | Batch: 0001 / 0004 | Loss: 0.4942\n",
            "[Train] | Epoch: 0444 / 1000 | Batch: 0002 / 0004 | Loss: 0.4958\n",
            "[Train] | Epoch: 0444 / 1000 | Batch: 0003 / 0004 | Loss: 0.4953\n",
            "[Train] | Epoch: 0444 / 1000 | Batch: 0004 / 0004 | Loss: 0.5002\n",
            "[Validation] | Epoch: 0444 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0444 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0444] Training Avg Loss: 0.4963 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0445 / 1000 | Batch: 0001 / 0004 | Loss: 0.5006\n",
            "[Train] | Epoch: 0445 / 1000 | Batch: 0002 / 0004 | Loss: 0.4972\n",
            "[Train] | Epoch: 0445 / 1000 | Batch: 0003 / 0004 | Loss: 0.4912\n",
            "[Train] | Epoch: 0445 / 1000 | Batch: 0004 / 0004 | Loss: 0.4928\n",
            "[Validation] | Epoch: 0445 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0445 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0445] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0446 / 1000 | Batch: 0001 / 0004 | Loss: 0.4991\n",
            "[Train] | Epoch: 0446 / 1000 | Batch: 0002 / 0004 | Loss: 0.4994\n",
            "[Train] | Epoch: 0446 / 1000 | Batch: 0003 / 0004 | Loss: 0.4890\n",
            "[Train] | Epoch: 0446 / 1000 | Batch: 0004 / 0004 | Loss: 0.4926\n",
            "[Validation] | Epoch: 0446 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0446 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0446] Training Avg Loss: 0.4950 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0447 / 1000 | Batch: 0001 / 0004 | Loss: 0.5062\n",
            "[Train] | Epoch: 0447 / 1000 | Batch: 0002 / 0004 | Loss: 0.4874\n",
            "[Train] | Epoch: 0447 / 1000 | Batch: 0003 / 0004 | Loss: 0.4895\n",
            "[Train] | Epoch: 0447 / 1000 | Batch: 0004 / 0004 | Loss: 0.5022\n",
            "[Validation] | Epoch: 0447 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0447 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0447] Training Avg Loss: 0.4963 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0448 / 1000 | Batch: 0001 / 0004 | Loss: 0.4888\n",
            "[Train] | Epoch: 0448 / 1000 | Batch: 0002 / 0004 | Loss: 0.4915\n",
            "[Train] | Epoch: 0448 / 1000 | Batch: 0003 / 0004 | Loss: 0.5077\n",
            "[Train] | Epoch: 0448 / 1000 | Batch: 0004 / 0004 | Loss: 0.4926\n",
            "[Validation] | Epoch: 0448 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0448 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0448] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0449 / 1000 | Batch: 0001 / 0004 | Loss: 0.4970\n",
            "[Train] | Epoch: 0449 / 1000 | Batch: 0002 / 0004 | Loss: 0.4982\n",
            "[Train] | Epoch: 0449 / 1000 | Batch: 0003 / 0004 | Loss: 0.4999\n",
            "[Train] | Epoch: 0449 / 1000 | Batch: 0004 / 0004 | Loss: 0.4844\n",
            "[Validation] | Epoch: 0449 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0449 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0449] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0450 / 1000 | Batch: 0001 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0450 / 1000 | Batch: 0002 / 0004 | Loss: 0.4966\n",
            "[Train] | Epoch: 0450 / 1000 | Batch: 0003 / 0004 | Loss: 0.5016\n",
            "[Train] | Epoch: 0450 / 1000 | Batch: 0004 / 0004 | Loss: 0.4870\n",
            "[Validation] | Epoch: 0450 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0450 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0450] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0451 / 1000 | Batch: 0001 / 0004 | Loss: 0.4936\n",
            "[Train] | Epoch: 0451 / 1000 | Batch: 0002 / 0004 | Loss: 0.4992\n",
            "[Train] | Epoch: 0451 / 1000 | Batch: 0003 / 0004 | Loss: 0.4937\n",
            "[Train] | Epoch: 0451 / 1000 | Batch: 0004 / 0004 | Loss: 0.4953\n",
            "[Validation] | Epoch: 0451 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0451 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0451] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0452 / 1000 | Batch: 0001 / 0004 | Loss: 0.4896\n",
            "[Train] | Epoch: 0452 / 1000 | Batch: 0002 / 0004 | Loss: 0.4961\n",
            "[Train] | Epoch: 0452 / 1000 | Batch: 0003 / 0004 | Loss: 0.5031\n",
            "[Train] | Epoch: 0452 / 1000 | Batch: 0004 / 0004 | Loss: 0.4920\n",
            "[Validation] | Epoch: 0452 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0452 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0452] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0453 / 1000 | Batch: 0001 / 0004 | Loss: 0.4930\n",
            "[Train] | Epoch: 0453 / 1000 | Batch: 0002 / 0004 | Loss: 0.4978\n",
            "[Train] | Epoch: 0453 / 1000 | Batch: 0003 / 0004 | Loss: 0.4939\n",
            "[Train] | Epoch: 0453 / 1000 | Batch: 0004 / 0004 | Loss: 0.5018\n",
            "[Validation] | Epoch: 0453 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0453 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0453] Training Avg Loss: 0.4966 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0454 / 1000 | Batch: 0001 / 0004 | Loss: 0.4961\n",
            "[Train] | Epoch: 0454 / 1000 | Batch: 0002 / 0004 | Loss: 0.4961\n",
            "[Train] | Epoch: 0454 / 1000 | Batch: 0003 / 0004 | Loss: 0.4963\n",
            "[Train] | Epoch: 0454 / 1000 | Batch: 0004 / 0004 | Loss: 0.4927\n",
            "[Validation] | Epoch: 0454 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0454 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0454] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0455 / 1000 | Batch: 0001 / 0004 | Loss: 0.4999\n",
            "[Train] | Epoch: 0455 / 1000 | Batch: 0002 / 0004 | Loss: 0.4954\n",
            "[Train] | Epoch: 0455 / 1000 | Batch: 0003 / 0004 | Loss: 0.4942\n",
            "[Train] | Epoch: 0455 / 1000 | Batch: 0004 / 0004 | Loss: 0.4921\n",
            "[Validation] | Epoch: 0455 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0455 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0455] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0456 / 1000 | Batch: 0001 / 0004 | Loss: 0.4955\n",
            "[Train] | Epoch: 0456 / 1000 | Batch: 0002 / 0004 | Loss: 0.5016\n",
            "[Train] | Epoch: 0456 / 1000 | Batch: 0003 / 0004 | Loss: 0.5041\n",
            "[Train] | Epoch: 0456 / 1000 | Batch: 0004 / 0004 | Loss: 0.4772\n",
            "[Validation] | Epoch: 0456 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0456 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0456] Training Avg Loss: 0.4946 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0457 / 1000 | Batch: 0001 / 0004 | Loss: 0.4928\n",
            "[Train] | Epoch: 0457 / 1000 | Batch: 0002 / 0004 | Loss: 0.4977\n",
            "[Train] | Epoch: 0457 / 1000 | Batch: 0003 / 0004 | Loss: 0.4963\n",
            "[Train] | Epoch: 0457 / 1000 | Batch: 0004 / 0004 | Loss: 0.4951\n",
            "[Validation] | Epoch: 0457 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0457 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0457] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0458 / 1000 | Batch: 0001 / 0004 | Loss: 0.5012\n",
            "[Train] | Epoch: 0458 / 1000 | Batch: 0002 / 0004 | Loss: 0.4945\n",
            "[Train] | Epoch: 0458 / 1000 | Batch: 0003 / 0004 | Loss: 0.4957\n",
            "[Train] | Epoch: 0458 / 1000 | Batch: 0004 / 0004 | Loss: 0.4901\n",
            "[Validation] | Epoch: 0458 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0458 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0458] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0459 / 1000 | Batch: 0001 / 0004 | Loss: 0.4892\n",
            "[Train] | Epoch: 0459 / 1000 | Batch: 0002 / 0004 | Loss: 0.5107\n",
            "[Train] | Epoch: 0459 / 1000 | Batch: 0003 / 0004 | Loss: 0.4937\n",
            "[Train] | Epoch: 0459 / 1000 | Batch: 0004 / 0004 | Loss: 0.4852\n",
            "[Validation] | Epoch: 0459 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0459 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0459] Training Avg Loss: 0.4947 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0460 / 1000 | Batch: 0001 / 0004 | Loss: 0.4981\n",
            "[Train] | Epoch: 0460 / 1000 | Batch: 0002 / 0004 | Loss: 0.4899\n",
            "[Train] | Epoch: 0460 / 1000 | Batch: 0003 / 0004 | Loss: 0.4976\n",
            "[Train] | Epoch: 0460 / 1000 | Batch: 0004 / 0004 | Loss: 0.4972\n",
            "[Validation] | Epoch: 0460 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0460 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0460] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0461 / 1000 | Batch: 0001 / 0004 | Loss: 0.4989\n",
            "[Train] | Epoch: 0461 / 1000 | Batch: 0002 / 0004 | Loss: 0.5012\n",
            "[Train] | Epoch: 0461 / 1000 | Batch: 0003 / 0004 | Loss: 0.4856\n",
            "[Train] | Epoch: 0461 / 1000 | Batch: 0004 / 0004 | Loss: 0.4967\n",
            "[Validation] | Epoch: 0461 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0461 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0461] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0462 / 1000 | Batch: 0001 / 0004 | Loss: 0.4980\n",
            "[Train] | Epoch: 0462 / 1000 | Batch: 0002 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0462 / 1000 | Batch: 0003 / 0004 | Loss: 0.4925\n",
            "[Train] | Epoch: 0462 / 1000 | Batch: 0004 / 0004 | Loss: 0.4975\n",
            "[Validation] | Epoch: 0462 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0462 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0462] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0463 / 1000 | Batch: 0001 / 0004 | Loss: 0.5027\n",
            "[Train] | Epoch: 0463 / 1000 | Batch: 0002 / 0004 | Loss: 0.4992\n",
            "[Train] | Epoch: 0463 / 1000 | Batch: 0003 / 0004 | Loss: 0.4862\n",
            "[Train] | Epoch: 0463 / 1000 | Batch: 0004 / 0004 | Loss: 0.4911\n",
            "[Validation] | Epoch: 0463 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0463 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0463] Training Avg Loss: 0.4948 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0464 / 1000 | Batch: 0001 / 0004 | Loss: 0.4986\n",
            "[Train] | Epoch: 0464 / 1000 | Batch: 0002 / 0004 | Loss: 0.4998\n",
            "[Train] | Epoch: 0464 / 1000 | Batch: 0003 / 0004 | Loss: 0.4858\n",
            "[Train] | Epoch: 0464 / 1000 | Batch: 0004 / 0004 | Loss: 0.5003\n",
            "[Validation] | Epoch: 0464 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0464 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0464] Training Avg Loss: 0.4961 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0465 / 1000 | Batch: 0001 / 0004 | Loss: 0.4987\n",
            "[Train] | Epoch: 0465 / 1000 | Batch: 0002 / 0004 | Loss: 0.4970\n",
            "[Train] | Epoch: 0465 / 1000 | Batch: 0003 / 0004 | Loss: 0.4973\n",
            "[Train] | Epoch: 0465 / 1000 | Batch: 0004 / 0004 | Loss: 0.4890\n",
            "[Validation] | Epoch: 0465 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0465 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0465] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0466 / 1000 | Batch: 0001 / 0004 | Loss: 0.4866\n",
            "[Train] | Epoch: 0466 / 1000 | Batch: 0002 / 0004 | Loss: 0.5137\n",
            "[Train] | Epoch: 0466 / 1000 | Batch: 0003 / 0004 | Loss: 0.4947\n",
            "[Train] | Epoch: 0466 / 1000 | Batch: 0004 / 0004 | Loss: 0.4866\n",
            "[Validation] | Epoch: 0466 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0466 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0466] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0467 / 1000 | Batch: 0001 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0467 / 1000 | Batch: 0002 / 0004 | Loss: 0.4923\n",
            "[Train] | Epoch: 0467 / 1000 | Batch: 0003 / 0004 | Loss: 0.4999\n",
            "[Train] | Epoch: 0467 / 1000 | Batch: 0004 / 0004 | Loss: 0.4958\n",
            "[Validation] | Epoch: 0467 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0467 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0467] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0468 / 1000 | Batch: 0001 / 0004 | Loss: 0.4954\n",
            "[Train] | Epoch: 0468 / 1000 | Batch: 0002 / 0004 | Loss: 0.4856\n",
            "[Train] | Epoch: 0468 / 1000 | Batch: 0003 / 0004 | Loss: 0.5037\n",
            "[Train] | Epoch: 0468 / 1000 | Batch: 0004 / 0004 | Loss: 0.5006\n",
            "[Validation] | Epoch: 0468 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0468 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0468] Training Avg Loss: 0.4963 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0469 / 1000 | Batch: 0001 / 0004 | Loss: 0.4892\n",
            "[Train] | Epoch: 0469 / 1000 | Batch: 0002 / 0004 | Loss: 0.4962\n",
            "[Train] | Epoch: 0469 / 1000 | Batch: 0003 / 0004 | Loss: 0.5043\n",
            "[Train] | Epoch: 0469 / 1000 | Batch: 0004 / 0004 | Loss: 0.4911\n",
            "[Validation] | Epoch: 0469 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0469 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0469] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0470 / 1000 | Batch: 0001 / 0004 | Loss: 0.4946\n",
            "[Train] | Epoch: 0470 / 1000 | Batch: 0002 / 0004 | Loss: 0.4959\n",
            "[Train] | Epoch: 0470 / 1000 | Batch: 0003 / 0004 | Loss: 0.4962\n",
            "[Train] | Epoch: 0470 / 1000 | Batch: 0004 / 0004 | Loss: 0.4959\n",
            "[Validation] | Epoch: 0470 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0470 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0470] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0471 / 1000 | Batch: 0001 / 0004 | Loss: 0.5060\n",
            "[Train] | Epoch: 0471 / 1000 | Batch: 0002 / 0004 | Loss: 0.4873\n",
            "[Train] | Epoch: 0471 / 1000 | Batch: 0003 / 0004 | Loss: 0.4945\n",
            "[Train] | Epoch: 0471 / 1000 | Batch: 0004 / 0004 | Loss: 0.4943\n",
            "[Validation] | Epoch: 0471 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0471 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0471] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0472 / 1000 | Batch: 0001 / 0004 | Loss: 0.4970\n",
            "[Train] | Epoch: 0472 / 1000 | Batch: 0002 / 0004 | Loss: 0.4897\n",
            "[Train] | Epoch: 0472 / 1000 | Batch: 0003 / 0004 | Loss: 0.5008\n",
            "[Train] | Epoch: 0472 / 1000 | Batch: 0004 / 0004 | Loss: 0.4956\n",
            "[Validation] | Epoch: 0472 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0472 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0472] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4969\n",
            "[Train] | Epoch: 0473 / 1000 | Batch: 0001 / 0004 | Loss: 0.5049\n",
            "[Train] | Epoch: 0473 / 1000 | Batch: 0002 / 0004 | Loss: 0.4906\n",
            "[Train] | Epoch: 0473 / 1000 | Batch: 0003 / 0004 | Loss: 0.5000\n",
            "[Train] | Epoch: 0473 / 1000 | Batch: 0004 / 0004 | Loss: 0.4816\n",
            "[Validation] | Epoch: 0473 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0473 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0473] Training Avg Loss: 0.4943 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0474 / 1000 | Batch: 0001 / 0004 | Loss: 0.4979\n",
            "[Train] | Epoch: 0474 / 1000 | Batch: 0002 / 0004 | Loss: 0.4930\n",
            "[Train] | Epoch: 0474 / 1000 | Batch: 0003 / 0004 | Loss: 0.5031\n",
            "[Train] | Epoch: 0474 / 1000 | Batch: 0004 / 0004 | Loss: 0.4873\n",
            "[Validation] | Epoch: 0474 / 1000 | Batch: 0001 / 0002 | Loss: 0.5077\n",
            "[Validation] | Epoch: 0474 / 1000 | Batch: 0002 / 0002 | Loss: 0.4863\n",
            "[Epoch 0474] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4970\n",
            "[Train] | Epoch: 0475 / 1000 | Batch: 0001 / 0004 | Loss: 0.4871\n",
            "[Train] | Epoch: 0475 / 1000 | Batch: 0002 / 0004 | Loss: 0.4978\n",
            "[Train] | Epoch: 0475 / 1000 | Batch: 0003 / 0004 | Loss: 0.5001\n",
            "[Train] | Epoch: 0475 / 1000 | Batch: 0004 / 0004 | Loss: 0.4992\n",
            "[Validation] | Epoch: 0475 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0475 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0475] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0476 / 1000 | Batch: 0001 / 0004 | Loss: 0.4978\n",
            "[Train] | Epoch: 0476 / 1000 | Batch: 0002 / 0004 | Loss: 0.4987\n",
            "[Train] | Epoch: 0476 / 1000 | Batch: 0003 / 0004 | Loss: 0.4878\n",
            "[Train] | Epoch: 0476 / 1000 | Batch: 0004 / 0004 | Loss: 0.4965\n",
            "[Validation] | Epoch: 0476 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0476 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0476] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0477 / 1000 | Batch: 0001 / 0004 | Loss: 0.4878\n",
            "[Train] | Epoch: 0477 / 1000 | Batch: 0002 / 0004 | Loss: 0.4978\n",
            "[Train] | Epoch: 0477 / 1000 | Batch: 0003 / 0004 | Loss: 0.5026\n",
            "[Train] | Epoch: 0477 / 1000 | Batch: 0004 / 0004 | Loss: 0.4937\n",
            "[Validation] | Epoch: 0477 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0477 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0477] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0478 / 1000 | Batch: 0001 / 0004 | Loss: 0.4975\n",
            "[Train] | Epoch: 0478 / 1000 | Batch: 0002 / 0004 | Loss: 0.4966\n",
            "[Train] | Epoch: 0478 / 1000 | Batch: 0003 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0478 / 1000 | Batch: 0004 / 0004 | Loss: 0.4920\n",
            "[Validation] | Epoch: 0478 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0478 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0478] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0479 / 1000 | Batch: 0001 / 0004 | Loss: 0.4945\n",
            "[Train] | Epoch: 0479 / 1000 | Batch: 0002 / 0004 | Loss: 0.4974\n",
            "[Train] | Epoch: 0479 / 1000 | Batch: 0003 / 0004 | Loss: 0.4943\n",
            "[Train] | Epoch: 0479 / 1000 | Batch: 0004 / 0004 | Loss: 0.4971\n",
            "[Validation] | Epoch: 0479 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0479 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0479] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0480 / 1000 | Batch: 0001 / 0004 | Loss: 0.4894\n",
            "[Train] | Epoch: 0480 / 1000 | Batch: 0002 / 0004 | Loss: 0.5001\n",
            "[Train] | Epoch: 0480 / 1000 | Batch: 0003 / 0004 | Loss: 0.5036\n",
            "[Train] | Epoch: 0480 / 1000 | Batch: 0004 / 0004 | Loss: 0.4869\n",
            "[Validation] | Epoch: 0480 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0480 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0480] Training Avg Loss: 0.4950 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0481 / 1000 | Batch: 0001 / 0004 | Loss: 0.4981\n",
            "[Train] | Epoch: 0481 / 1000 | Batch: 0002 / 0004 | Loss: 0.4990\n",
            "[Train] | Epoch: 0481 / 1000 | Batch: 0003 / 0004 | Loss: 0.4923\n",
            "[Train] | Epoch: 0481 / 1000 | Batch: 0004 / 0004 | Loss: 0.4919\n",
            "[Validation] | Epoch: 0481 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0481 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0481] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0482 / 1000 | Batch: 0001 / 0004 | Loss: 0.4986\n",
            "[Train] | Epoch: 0482 / 1000 | Batch: 0002 / 0004 | Loss: 0.4939\n",
            "[Train] | Epoch: 0482 / 1000 | Batch: 0003 / 0004 | Loss: 0.4953\n",
            "[Train] | Epoch: 0482 / 1000 | Batch: 0004 / 0004 | Loss: 0.4964\n",
            "[Validation] | Epoch: 0482 / 1000 | Batch: 0001 / 0002 | Loss: 0.5077\n",
            "[Validation] | Epoch: 0482 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0482] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4969\n",
            "[Train] | Epoch: 0483 / 1000 | Batch: 0001 / 0004 | Loss: 0.4962\n",
            "[Train] | Epoch: 0483 / 1000 | Batch: 0002 / 0004 | Loss: 0.4945\n",
            "[Train] | Epoch: 0483 / 1000 | Batch: 0003 / 0004 | Loss: 0.5010\n",
            "[Train] | Epoch: 0483 / 1000 | Batch: 0004 / 0004 | Loss: 0.4912\n",
            "[Validation] | Epoch: 0483 / 1000 | Batch: 0001 / 0002 | Loss: 0.5078\n",
            "[Validation] | Epoch: 0483 / 1000 | Batch: 0002 / 0002 | Loss: 0.4863\n",
            "[Epoch 0483] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4971\n",
            "[Train] | Epoch: 0484 / 1000 | Batch: 0001 / 0004 | Loss: 0.4984\n",
            "[Train] | Epoch: 0484 / 1000 | Batch: 0002 / 0004 | Loss: 0.5086\n",
            "[Train] | Epoch: 0484 / 1000 | Batch: 0003 / 0004 | Loss: 0.4884\n",
            "[Train] | Epoch: 0484 / 1000 | Batch: 0004 / 0004 | Loss: 0.4836\n",
            "[Validation] | Epoch: 0484 / 1000 | Batch: 0001 / 0002 | Loss: 0.5078\n",
            "[Validation] | Epoch: 0484 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0484] Training Avg Loss: 0.4947 | Validation Avg Loss: 0.4970\n",
            "[Train] | Epoch: 0485 / 1000 | Batch: 0001 / 0004 | Loss: 0.4981\n",
            "[Train] | Epoch: 0485 / 1000 | Batch: 0002 / 0004 | Loss: 0.4917\n",
            "[Train] | Epoch: 0485 / 1000 | Batch: 0003 / 0004 | Loss: 0.4901\n",
            "[Train] | Epoch: 0485 / 1000 | Batch: 0004 / 0004 | Loss: 0.5050\n",
            "[Validation] | Epoch: 0485 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0485 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0485] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0486 / 1000 | Batch: 0001 / 0004 | Loss: 0.5034\n",
            "[Train] | Epoch: 0486 / 1000 | Batch: 0002 / 0004 | Loss: 0.4888\n",
            "[Train] | Epoch: 0486 / 1000 | Batch: 0003 / 0004 | Loss: 0.5008\n",
            "[Train] | Epoch: 0486 / 1000 | Batch: 0004 / 0004 | Loss: 0.4905\n",
            "[Validation] | Epoch: 0486 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0486 / 1000 | Batch: 0002 / 0002 | Loss: 0.4862\n",
            "[Epoch 0486] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4969\n",
            "[Train] | Epoch: 0487 / 1000 | Batch: 0001 / 0004 | Loss: 0.4914\n",
            "[Train] | Epoch: 0487 / 1000 | Batch: 0002 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0487 / 1000 | Batch: 0003 / 0004 | Loss: 0.5056\n",
            "[Train] | Epoch: 0487 / 1000 | Batch: 0004 / 0004 | Loss: 0.4896\n",
            "[Validation] | Epoch: 0487 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0487 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0487] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0488 / 1000 | Batch: 0001 / 0004 | Loss: 0.4975\n",
            "[Train] | Epoch: 0488 / 1000 | Batch: 0002 / 0004 | Loss: 0.4974\n",
            "[Train] | Epoch: 0488 / 1000 | Batch: 0003 / 0004 | Loss: 0.4899\n",
            "[Train] | Epoch: 0488 / 1000 | Batch: 0004 / 0004 | Loss: 0.4950\n",
            "[Validation] | Epoch: 0488 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0488 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0488] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0489 / 1000 | Batch: 0001 / 0004 | Loss: 0.4942\n",
            "[Train] | Epoch: 0489 / 1000 | Batch: 0002 / 0004 | Loss: 0.4852\n",
            "[Train] | Epoch: 0489 / 1000 | Batch: 0003 / 0004 | Loss: 0.5050\n",
            "[Train] | Epoch: 0489 / 1000 | Batch: 0004 / 0004 | Loss: 0.4990\n",
            "[Validation] | Epoch: 0489 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0489 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0489] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0490 / 1000 | Batch: 0001 / 0004 | Loss: 0.5040\n",
            "[Train] | Epoch: 0490 / 1000 | Batch: 0002 / 0004 | Loss: 0.4939\n",
            "[Train] | Epoch: 0490 / 1000 | Batch: 0003 / 0004 | Loss: 0.4912\n",
            "[Train] | Epoch: 0490 / 1000 | Batch: 0004 / 0004 | Loss: 0.4926\n",
            "[Validation] | Epoch: 0490 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0490 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0490] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0491 / 1000 | Batch: 0001 / 0004 | Loss: 0.4952\n",
            "[Train] | Epoch: 0491 / 1000 | Batch: 0002 / 0004 | Loss: 0.4880\n",
            "[Train] | Epoch: 0491 / 1000 | Batch: 0003 / 0004 | Loss: 0.5026\n",
            "[Train] | Epoch: 0491 / 1000 | Batch: 0004 / 0004 | Loss: 0.4993\n",
            "[Validation] | Epoch: 0491 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0491 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0491] Training Avg Loss: 0.4963 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0492 / 1000 | Batch: 0001 / 0004 | Loss: 0.4909\n",
            "[Train] | Epoch: 0492 / 1000 | Batch: 0002 / 0004 | Loss: 0.4963\n",
            "[Train] | Epoch: 0492 / 1000 | Batch: 0003 / 0004 | Loss: 0.4977\n",
            "[Train] | Epoch: 0492 / 1000 | Batch: 0004 / 0004 | Loss: 0.4973\n",
            "[Validation] | Epoch: 0492 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0492 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0492] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0493 / 1000 | Batch: 0001 / 0004 | Loss: 0.5017\n",
            "[Train] | Epoch: 0493 / 1000 | Batch: 0002 / 0004 | Loss: 0.4960\n",
            "[Train] | Epoch: 0493 / 1000 | Batch: 0003 / 0004 | Loss: 0.4933\n",
            "[Train] | Epoch: 0493 / 1000 | Batch: 0004 / 0004 | Loss: 0.4887\n",
            "[Validation] | Epoch: 0493 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0493 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0493] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0494 / 1000 | Batch: 0001 / 0004 | Loss: 0.4905\n",
            "[Train] | Epoch: 0494 / 1000 | Batch: 0002 / 0004 | Loss: 0.4963\n",
            "[Train] | Epoch: 0494 / 1000 | Batch: 0003 / 0004 | Loss: 0.5030\n",
            "[Train] | Epoch: 0494 / 1000 | Batch: 0004 / 0004 | Loss: 0.4914\n",
            "[Validation] | Epoch: 0494 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0494 / 1000 | Batch: 0002 / 0002 | Loss: 0.4859\n",
            "[Epoch 0494] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0495 / 1000 | Batch: 0001 / 0004 | Loss: 0.4939\n",
            "[Train] | Epoch: 0495 / 1000 | Batch: 0002 / 0004 | Loss: 0.4910\n",
            "[Train] | Epoch: 0495 / 1000 | Batch: 0003 / 0004 | Loss: 0.5012\n",
            "[Train] | Epoch: 0495 / 1000 | Batch: 0004 / 0004 | Loss: 0.4961\n",
            "[Validation] | Epoch: 0495 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0495 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0495] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0496 / 1000 | Batch: 0001 / 0004 | Loss: 0.4957\n",
            "[Train] | Epoch: 0496 / 1000 | Batch: 0002 / 0004 | Loss: 0.4979\n",
            "[Train] | Epoch: 0496 / 1000 | Batch: 0003 / 0004 | Loss: 0.4919\n",
            "[Train] | Epoch: 0496 / 1000 | Batch: 0004 / 0004 | Loss: 0.4962\n",
            "[Validation] | Epoch: 0496 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0496 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0496] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0497 / 1000 | Batch: 0001 / 0004 | Loss: 0.4890\n",
            "[Train] | Epoch: 0497 / 1000 | Batch: 0002 / 0004 | Loss: 0.4995\n",
            "[Train] | Epoch: 0497 / 1000 | Batch: 0003 / 0004 | Loss: 0.5013\n",
            "[Train] | Epoch: 0497 / 1000 | Batch: 0004 / 0004 | Loss: 0.4900\n",
            "[Validation] | Epoch: 0497 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0497 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0497] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0498 / 1000 | Batch: 0001 / 0004 | Loss: 0.4905\n",
            "[Train] | Epoch: 0498 / 1000 | Batch: 0002 / 0004 | Loss: 0.4991\n",
            "[Train] | Epoch: 0498 / 1000 | Batch: 0003 / 0004 | Loss: 0.5028\n",
            "[Train] | Epoch: 0498 / 1000 | Batch: 0004 / 0004 | Loss: 0.4891\n",
            "[Validation] | Epoch: 0498 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0498 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0498] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0499 / 1000 | Batch: 0001 / 0004 | Loss: 0.4928\n",
            "[Train] | Epoch: 0499 / 1000 | Batch: 0002 / 0004 | Loss: 0.4947\n",
            "[Train] | Epoch: 0499 / 1000 | Batch: 0003 / 0004 | Loss: 0.4955\n",
            "[Train] | Epoch: 0499 / 1000 | Batch: 0004 / 0004 | Loss: 0.4988\n",
            "[Validation] | Epoch: 0499 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0499 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0499] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0500 / 1000 | Batch: 0001 / 0004 | Loss: 0.4874\n",
            "[Train] | Epoch: 0500 / 1000 | Batch: 0002 / 0004 | Loss: 0.5051\n",
            "[Train] | Epoch: 0500 / 1000 | Batch: 0003 / 0004 | Loss: 0.4974\n",
            "[Train] | Epoch: 0500 / 1000 | Batch: 0004 / 0004 | Loss: 0.4920\n",
            "[Validation] | Epoch: 0500 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0500 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0500] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0501 / 1000 | Batch: 0001 / 0004 | Loss: 0.4896\n",
            "[Train] | Epoch: 0501 / 1000 | Batch: 0002 / 0004 | Loss: 0.5016\n",
            "[Train] | Epoch: 0501 / 1000 | Batch: 0003 / 0004 | Loss: 0.4937\n",
            "[Train] | Epoch: 0501 / 1000 | Batch: 0004 / 0004 | Loss: 0.4978\n",
            "[Validation] | Epoch: 0501 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0501 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0501] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0502 / 1000 | Batch: 0001 / 0004 | Loss: 0.4958\n",
            "[Train] | Epoch: 0502 / 1000 | Batch: 0002 / 0004 | Loss: 0.5035\n",
            "[Train] | Epoch: 0502 / 1000 | Batch: 0003 / 0004 | Loss: 0.4934\n",
            "[Train] | Epoch: 0502 / 1000 | Batch: 0004 / 0004 | Loss: 0.4898\n",
            "[Validation] | Epoch: 0502 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0502 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0502] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0503 / 1000 | Batch: 0001 / 0004 | Loss: 0.5022\n",
            "[Train] | Epoch: 0503 / 1000 | Batch: 0002 / 0004 | Loss: 0.4854\n",
            "[Train] | Epoch: 0503 / 1000 | Batch: 0003 / 0004 | Loss: 0.5018\n",
            "[Train] | Epoch: 0503 / 1000 | Batch: 0004 / 0004 | Loss: 0.4928\n",
            "[Validation] | Epoch: 0503 / 1000 | Batch: 0001 / 0002 | Loss: 0.5071\n",
            "[Validation] | Epoch: 0503 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0503] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0504 / 1000 | Batch: 0001 / 0004 | Loss: 0.4948\n",
            "[Train] | Epoch: 0504 / 1000 | Batch: 0002 / 0004 | Loss: 0.4922\n",
            "[Train] | Epoch: 0504 / 1000 | Batch: 0003 / 0004 | Loss: 0.5010\n",
            "[Train] | Epoch: 0504 / 1000 | Batch: 0004 / 0004 | Loss: 0.4950\n",
            "[Validation] | Epoch: 0504 / 1000 | Batch: 0001 / 0002 | Loss: 0.5077\n",
            "[Validation] | Epoch: 0504 / 1000 | Batch: 0002 / 0002 | Loss: 0.4864\n",
            "[Epoch 0504] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4970\n",
            "[Train] | Epoch: 0505 / 1000 | Batch: 0001 / 0004 | Loss: 0.4999\n",
            "[Train] | Epoch: 0505 / 1000 | Batch: 0002 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0505 / 1000 | Batch: 0003 / 0004 | Loss: 0.4924\n",
            "[Train] | Epoch: 0505 / 1000 | Batch: 0004 / 0004 | Loss: 0.4938\n",
            "[Validation] | Epoch: 0505 / 1000 | Batch: 0001 / 0002 | Loss: 0.5077\n",
            "[Validation] | Epoch: 0505 / 1000 | Batch: 0002 / 0002 | Loss: 0.4864\n",
            "[Epoch 0505] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4971\n",
            "[Train] | Epoch: 0506 / 1000 | Batch: 0001 / 0004 | Loss: 0.4996\n",
            "[Train] | Epoch: 0506 / 1000 | Batch: 0002 / 0004 | Loss: 0.4857\n",
            "[Train] | Epoch: 0506 / 1000 | Batch: 0003 / 0004 | Loss: 0.4960\n",
            "[Train] | Epoch: 0506 / 1000 | Batch: 0004 / 0004 | Loss: 0.5033\n",
            "[Validation] | Epoch: 0506 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0506 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0506] Training Avg Loss: 0.4961 | Validation Avg Loss: 0.4968\n",
            "[Train] | Epoch: 0507 / 1000 | Batch: 0001 / 0004 | Loss: 0.4956\n",
            "[Train] | Epoch: 0507 / 1000 | Batch: 0002 / 0004 | Loss: 0.4989\n",
            "[Train] | Epoch: 0507 / 1000 | Batch: 0003 / 0004 | Loss: 0.4929\n",
            "[Train] | Epoch: 0507 / 1000 | Batch: 0004 / 0004 | Loss: 0.4944\n",
            "[Validation] | Epoch: 0507 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0507 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0507] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0508 / 1000 | Batch: 0001 / 0004 | Loss: 0.4947\n",
            "[Train] | Epoch: 0508 / 1000 | Batch: 0002 / 0004 | Loss: 0.4976\n",
            "[Train] | Epoch: 0508 / 1000 | Batch: 0003 / 0004 | Loss: 0.4984\n",
            "[Train] | Epoch: 0508 / 1000 | Batch: 0004 / 0004 | Loss: 0.4898\n",
            "[Validation] | Epoch: 0508 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0508 / 1000 | Batch: 0002 / 0002 | Loss: 0.4860\n",
            "[Epoch 0508] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0509 / 1000 | Batch: 0001 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0509 / 1000 | Batch: 0002 / 0004 | Loss: 0.5067\n",
            "[Train] | Epoch: 0509 / 1000 | Batch: 0003 / 0004 | Loss: 0.4923\n",
            "[Train] | Epoch: 0509 / 1000 | Batch: 0004 / 0004 | Loss: 0.4850\n",
            "[Validation] | Epoch: 0509 / 1000 | Batch: 0001 / 0002 | Loss: 0.5076\n",
            "[Validation] | Epoch: 0509 / 1000 | Batch: 0002 / 0002 | Loss: 0.4861\n",
            "[Epoch 0509] Training Avg Loss: 0.4948 | Validation Avg Loss: 0.4969\n",
            "[Train] | Epoch: 0510 / 1000 | Batch: 0001 / 0004 | Loss: 0.5005\n",
            "[Train] | Epoch: 0510 / 1000 | Batch: 0002 / 0004 | Loss: 0.4991\n",
            "[Train] | Epoch: 0510 / 1000 | Batch: 0003 / 0004 | Loss: 0.4904\n",
            "[Train] | Epoch: 0510 / 1000 | Batch: 0004 / 0004 | Loss: 0.4902\n",
            "[Validation] | Epoch: 0510 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0510 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0510] Training Avg Loss: 0.4951 | Validation Avg Loss: 0.4967\n",
            "[Train] | Epoch: 0511 / 1000 | Batch: 0001 / 0004 | Loss: 0.4909\n",
            "[Train] | Epoch: 0511 / 1000 | Batch: 0002 / 0004 | Loss: 0.4976\n",
            "[Train] | Epoch: 0511 / 1000 | Batch: 0003 / 0004 | Loss: 0.4931\n",
            "[Train] | Epoch: 0511 / 1000 | Batch: 0004 / 0004 | Loss: 0.5021\n",
            "[Validation] | Epoch: 0511 / 1000 | Batch: 0001 / 0002 | Loss: 0.5075\n",
            "[Validation] | Epoch: 0511 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0511] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0512 / 1000 | Batch: 0001 / 0004 | Loss: 0.4926\n",
            "[Train] | Epoch: 0512 / 1000 | Batch: 0002 / 0004 | Loss: 0.4982\n",
            "[Train] | Epoch: 0512 / 1000 | Batch: 0003 / 0004 | Loss: 0.4944\n",
            "[Train] | Epoch: 0512 / 1000 | Batch: 0004 / 0004 | Loss: 0.4998\n",
            "[Validation] | Epoch: 0512 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0512 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0512] Training Avg Loss: 0.4962 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0513 / 1000 | Batch: 0001 / 0004 | Loss: 0.4987\n",
            "[Train] | Epoch: 0513 / 1000 | Batch: 0002 / 0004 | Loss: 0.4952\n",
            "[Train] | Epoch: 0513 / 1000 | Batch: 0003 / 0004 | Loss: 0.4934\n",
            "[Train] | Epoch: 0513 / 1000 | Batch: 0004 / 0004 | Loss: 0.4943\n",
            "[Validation] | Epoch: 0513 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0513 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0513] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0514 / 1000 | Batch: 0001 / 0004 | Loss: 0.4984\n",
            "[Train] | Epoch: 0514 / 1000 | Batch: 0002 / 0004 | Loss: 0.4868\n",
            "[Train] | Epoch: 0514 / 1000 | Batch: 0003 / 0004 | Loss: 0.4967\n",
            "[Train] | Epoch: 0514 / 1000 | Batch: 0004 / 0004 | Loss: 0.5040\n",
            "[Validation] | Epoch: 0514 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0514 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0514] Training Avg Loss: 0.4965 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0515 / 1000 | Batch: 0001 / 0004 | Loss: 0.4917\n",
            "[Train] | Epoch: 0515 / 1000 | Batch: 0002 / 0004 | Loss: 0.5017\n",
            "[Train] | Epoch: 0515 / 1000 | Batch: 0003 / 0004 | Loss: 0.4955\n",
            "[Train] | Epoch: 0515 / 1000 | Batch: 0004 / 0004 | Loss: 0.4899\n",
            "[Validation] | Epoch: 0515 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0515 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0515] Training Avg Loss: 0.4947 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0516 / 1000 | Batch: 0001 / 0004 | Loss: 0.5016\n",
            "[Train] | Epoch: 0516 / 1000 | Batch: 0002 / 0004 | Loss: 0.4954\n",
            "[Train] | Epoch: 0516 / 1000 | Batch: 0003 / 0004 | Loss: 0.4890\n",
            "[Train] | Epoch: 0516 / 1000 | Batch: 0004 / 0004 | Loss: 0.4983\n",
            "[Validation] | Epoch: 0516 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0516 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0516] Training Avg Loss: 0.4961 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0517 / 1000 | Batch: 0001 / 0004 | Loss: 0.4901\n",
            "[Train] | Epoch: 0517 / 1000 | Batch: 0002 / 0004 | Loss: 0.4987\n",
            "[Train] | Epoch: 0517 / 1000 | Batch: 0003 / 0004 | Loss: 0.4954\n",
            "[Train] | Epoch: 0517 / 1000 | Batch: 0004 / 0004 | Loss: 0.4985\n",
            "[Validation] | Epoch: 0517 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0517 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0517] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0518 / 1000 | Batch: 0001 / 0004 | Loss: 0.4990\n",
            "[Train] | Epoch: 0518 / 1000 | Batch: 0002 / 0004 | Loss: 0.4934\n",
            "[Train] | Epoch: 0518 / 1000 | Batch: 0003 / 0004 | Loss: 0.4900\n",
            "[Train] | Epoch: 0518 / 1000 | Batch: 0004 / 0004 | Loss: 0.4999\n",
            "[Validation] | Epoch: 0518 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0518 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0518] Training Avg Loss: 0.4956 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0519 / 1000 | Batch: 0001 / 0004 | Loss: 0.4972\n",
            "[Train] | Epoch: 0519 / 1000 | Batch: 0002 / 0004 | Loss: 0.4964\n",
            "[Train] | Epoch: 0519 / 1000 | Batch: 0003 / 0004 | Loss: 0.4891\n",
            "[Train] | Epoch: 0519 / 1000 | Batch: 0004 / 0004 | Loss: 0.5015\n",
            "[Validation] | Epoch: 0519 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0519 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0519] Training Avg Loss: 0.4960 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0520 / 1000 | Batch: 0001 / 0004 | Loss: 0.4984\n",
            "[Train] | Epoch: 0520 / 1000 | Batch: 0002 / 0004 | Loss: 0.4922\n",
            "[Train] | Epoch: 0520 / 1000 | Batch: 0003 / 0004 | Loss: 0.4951\n",
            "[Train] | Epoch: 0520 / 1000 | Batch: 0004 / 0004 | Loss: 0.4973\n",
            "[Validation] | Epoch: 0520 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0520 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0520] Training Avg Loss: 0.4958 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0521 / 1000 | Batch: 0001 / 0004 | Loss: 0.5028\n",
            "[Train] | Epoch: 0521 / 1000 | Batch: 0002 / 0004 | Loss: 0.4947\n",
            "[Train] | Epoch: 0521 / 1000 | Batch: 0003 / 0004 | Loss: 0.4928\n",
            "[Train] | Epoch: 0521 / 1000 | Batch: 0004 / 0004 | Loss: 0.4907\n",
            "[Validation] | Epoch: 0521 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0521 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0521] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0522 / 1000 | Batch: 0001 / 0004 | Loss: 0.4847\n",
            "[Train] | Epoch: 0522 / 1000 | Batch: 0002 / 0004 | Loss: 0.5005\n",
            "[Train] | Epoch: 0522 / 1000 | Batch: 0003 / 0004 | Loss: 0.5043\n",
            "[Train] | Epoch: 0522 / 1000 | Batch: 0004 / 0004 | Loss: 0.4933\n",
            "[Validation] | Epoch: 0522 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0522 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0522] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0523 / 1000 | Batch: 0001 / 0004 | Loss: 0.4973\n",
            "[Train] | Epoch: 0523 / 1000 | Batch: 0002 / 0004 | Loss: 0.4903\n",
            "[Train] | Epoch: 0523 / 1000 | Batch: 0003 / 0004 | Loss: 0.4983\n",
            "[Train] | Epoch: 0523 / 1000 | Batch: 0004 / 0004 | Loss: 0.4956\n",
            "[Validation] | Epoch: 0523 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0523 / 1000 | Batch: 0002 / 0002 | Loss: 0.4858\n",
            "[Epoch 0523] Training Avg Loss: 0.4954 | Validation Avg Loss: 0.4966\n",
            "[Train] | Epoch: 0524 / 1000 | Batch: 0001 / 0004 | Loss: 0.4895\n",
            "[Train] | Epoch: 0524 / 1000 | Batch: 0002 / 0004 | Loss: 0.5016\n",
            "[Train] | Epoch: 0524 / 1000 | Batch: 0003 / 0004 | Loss: 0.4927\n",
            "[Train] | Epoch: 0524 / 1000 | Batch: 0004 / 0004 | Loss: 0.4988\n",
            "[Validation] | Epoch: 0524 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0524 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0524] Training Avg Loss: 0.4957 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0525 / 1000 | Batch: 0001 / 0004 | Loss: 0.4927\n",
            "[Train] | Epoch: 0525 / 1000 | Batch: 0002 / 0004 | Loss: 0.5044\n",
            "[Train] | Epoch: 0525 / 1000 | Batch: 0003 / 0004 | Loss: 0.4975\n",
            "[Train] | Epoch: 0525 / 1000 | Batch: 0004 / 0004 | Loss: 0.4843\n",
            "[Validation] | Epoch: 0525 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0525 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0525] Training Avg Loss: 0.4947 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0526 / 1000 | Batch: 0001 / 0004 | Loss: 0.4880\n",
            "[Train] | Epoch: 0526 / 1000 | Batch: 0002 / 0004 | Loss: 0.4989\n",
            "[Train] | Epoch: 0526 / 1000 | Batch: 0003 / 0004 | Loss: 0.5000\n",
            "[Train] | Epoch: 0526 / 1000 | Batch: 0004 / 0004 | Loss: 0.4952\n",
            "[Validation] | Epoch: 0526 / 1000 | Batch: 0001 / 0002 | Loss: 0.5072\n",
            "[Validation] | Epoch: 0526 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0526] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0527 / 1000 | Batch: 0001 / 0004 | Loss: 0.4940\n",
            "[Train] | Epoch: 0527 / 1000 | Batch: 0002 / 0004 | Loss: 0.5000\n",
            "[Train] | Epoch: 0527 / 1000 | Batch: 0003 / 0004 | Loss: 0.4976\n",
            "[Train] | Epoch: 0527 / 1000 | Batch: 0004 / 0004 | Loss: 0.4871\n",
            "[Validation] | Epoch: 0527 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0527 / 1000 | Batch: 0002 / 0002 | Loss: 0.4856\n",
            "[Epoch 0527] Training Avg Loss: 0.4946 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0528 / 1000 | Batch: 0001 / 0004 | Loss: 0.4946\n",
            "[Train] | Epoch: 0528 / 1000 | Batch: 0002 / 0004 | Loss: 0.5008\n",
            "[Train] | Epoch: 0528 / 1000 | Batch: 0003 / 0004 | Loss: 0.4913\n",
            "[Train] | Epoch: 0528 / 1000 | Batch: 0004 / 0004 | Loss: 0.4929\n",
            "[Validation] | Epoch: 0528 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0528 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0528] Training Avg Loss: 0.4949 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0529 / 1000 | Batch: 0001 / 0004 | Loss: 0.4911\n",
            "[Train] | Epoch: 0529 / 1000 | Batch: 0002 / 0004 | Loss: 0.5024\n",
            "[Train] | Epoch: 0529 / 1000 | Batch: 0003 / 0004 | Loss: 0.4947\n",
            "[Train] | Epoch: 0529 / 1000 | Batch: 0004 / 0004 | Loss: 0.4937\n",
            "[Validation] | Epoch: 0529 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0529 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0529] Training Avg Loss: 0.4955 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0530 / 1000 | Batch: 0001 / 0004 | Loss: 0.4957\n",
            "[Train] | Epoch: 0530 / 1000 | Batch: 0002 / 0004 | Loss: 0.4931\n",
            "[Train] | Epoch: 0530 / 1000 | Batch: 0003 / 0004 | Loss: 0.4993\n",
            "[Train] | Epoch: 0530 / 1000 | Batch: 0004 / 0004 | Loss: 0.4958\n",
            "[Validation] | Epoch: 0530 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0530 / 1000 | Batch: 0002 / 0002 | Loss: 0.4854\n",
            "[Epoch 0530] Training Avg Loss: 0.4959 | Validation Avg Loss: 0.4963\n",
            "[Train] | Epoch: 0531 / 1000 | Batch: 0001 / 0004 | Loss: 0.4980\n",
            "[Train] | Epoch: 0531 / 1000 | Batch: 0002 / 0004 | Loss: 0.4879\n",
            "[Train] | Epoch: 0531 / 1000 | Batch: 0003 / 0004 | Loss: 0.4966\n",
            "[Train] | Epoch: 0531 / 1000 | Batch: 0004 / 0004 | Loss: 0.4988\n",
            "[Validation] | Epoch: 0531 / 1000 | Batch: 0001 / 0002 | Loss: 0.5073\n",
            "[Validation] | Epoch: 0531 / 1000 | Batch: 0002 / 0002 | Loss: 0.4855\n",
            "[Epoch 0531] Training Avg Loss: 0.4953 | Validation Avg Loss: 0.4964\n",
            "[Train] | Epoch: 0532 / 1000 | Batch: 0001 / 0004 | Loss: 0.5012\n",
            "[Train] | Epoch: 0532 / 1000 | Batch: 0002 / 0004 | Loss: 0.4975\n",
            "[Train] | Epoch: 0532 / 1000 | Batch: 0003 / 0004 | Loss: 0.4937\n",
            "[Train] | Epoch: 0532 / 1000 | Batch: 0004 / 0004 | Loss: 0.4884\n",
            "[Validation] | Epoch: 0532 / 1000 | Batch: 0001 / 0002 | Loss: 0.5074\n",
            "[Validation] | Epoch: 0532 / 1000 | Batch: 0002 / 0002 | Loss: 0.4857\n",
            "[Epoch 0532] Training Avg Loss: 0.4952 | Validation Avg Loss: 0.4965\n",
            "[Train] | Epoch: 0533 / 1000 | Batch: 0001 / 0004 | Loss: 0.4858\n",
            "[Train] | Epoch: 0533 / 1000 | Batch: 0002 / 0004 | Loss: 0.5190\n",
            "[Train] | Epoch: 0533 / 1000 | Batch: 0003 / 0004 | Loss: 0.4908\n",
            "[Train] | Epoch: 0533 / 1000 | Batch: 0004 / 0004 | Loss: 0.4832\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation/train.py\", line 140, in <module>\n",
            "    for batch_idx, data in enumerate(val_loader, 1):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 757, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation/dataset.py\", line 23, in __getitem__\n",
            "    label = cv2.imread(self.labels[index], cv2.IMREAD_GRAYSCALE) / 255.\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inerQZJduuNd",
        "outputId": "5148c2c3-d523-4d7d-b715-e9ba4fc562c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  33% (1/3)\rUnpacking objects:  66% (2/3)\rUnpacking objects: 100% (3/3)\rUnpacking objects: 100% (3/3), 401 bytes | 16.00 KiB/s, done.\n",
            "From https://github.com/abreorussel/CS725-retinal-vessel-segmentation\n",
            "   ee66a49..0b2bb88  main       -> origin/main\n",
            "Updating ee66a49..0b2bb88\n",
            "Fast-forward\n",
            " train.py | 22 \u001b[32m+++++++++++\u001b[m\u001b[31m-----------\u001b[m\n",
            " 1 file changed, 11 insertions(+), 11 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation\n",
        "\n",
        "!python eval_new.py"
      ],
      "metadata": {
        "id": "_McwY8vpu4yB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f5dad9-b56a-4d18-c9f7-831af2be22df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation\n",
            "/content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation/utils.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_dict = torch.load(ckpt_path)\n",
            "* Load /content/drive/MyDrive/CS725_Project_FINAL/CS725-retinal-vessel-segmentation/checkpoints/model_epoch0650.pth\n",
            "[Test] | Batch: 0001 / 0002 | Loss: 0.3156 | Dice: 0.5380 | hd95: 9.5943\n",
            "[Test] | Batch: 0002 / 0002 | Loss: 0.3266 | Dice: 0.4959 | hd95: 10.4122\n",
            "[Result] | Avg Loss: 0.3211 | Avg Dice Coeff : 0.5170 | Avg hd95 : 10.0033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hA7jnFravbds"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}